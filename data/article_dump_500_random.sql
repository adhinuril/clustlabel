-- MySQL dump 10.13  Distrib 5.7.17, for Win64 (x86_64)
--
-- Host: localhost    Database: article500_random
-- ------------------------------------------------------
-- Server version	5.7.19-log

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `cluster_label`
--

DROP TABLE IF EXISTS `cluster_label`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `cluster_label` (
  `article_id` int(11) NOT NULL,
  `cluster_id` int(11) DEFAULT NULL,
  `silh_score` float DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `cluster_label`
--

LOCK TABLES `cluster_label` WRITE;
/*!40000 ALTER TABLE `cluster_label` DISABLE KEYS */;
/*!40000 ALTER TABLE `cluster_label` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `fg_m_article`
--

DROP TABLE IF EXISTS `fg_m_article`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `fg_m_article` (
  `article_id` bigint(20) NOT NULL,
  `article_publicationcategory` int(11) DEFAULT NULL,
  `article_year` char(4) DEFAULT NULL,
  `article_impact` float DEFAULT NULL,
  `article_title` text,
  `article_abstract` text,
  `article_publicationvenue` int(11) DEFAULT NULL,
  `article_publicationvenuetext` varchar(512) DEFAULT NULL,
  `article_cluster_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`article_id`),
  KEY `article_publicationvenue` (`article_publicationvenue`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `fg_m_article`
--

LOCK TABLES `fg_m_article` WRITE;
/*!40000 ALTER TABLE `fg_m_article` DISABLE KEYS */;
INSERT INTO `fg_m_article` VALUES (135,NULL,'1984',NULL,'A parallel pipelined relational query processor','This paper presents the design of a relational query processor. The query processor consists of only four processing PIPEs and a number of random-access memory modules. Each PIPE processes tuples of relations in a bit-serial, tuple-parallel manner for each of the primitive database operations which comprise a complex relational query. The design of the query processor meets three major objectives: the query processor must be manufacturable using existing and near-term LSI (VLSI) technology; it must support in a uniform manner both the numeric and nonnumeric processing requirements a high-level user interface like SQL presents; and it must support the query-processing strategy derived in the query optimizer to satisfy certain system-wide performance optimality criteria.',16320,'ACM Transactions on Database Systems (TODS)',5),(316,NULL,'1984',NULL,'A Formal Method for the Abstract Specification of Software','An intuitive presentation of the trace method for the abstractspecification of software contains sample specifications, syntacticand semantic definitions of consistency and totalness, methods forproving specifications consistent and total, and a comparison ofthe method with the algebraic approach to specification. Thisintuitive presentation is underpinned by a formal syntax,semantics, and derivation system for the method. Completeness andsoundness theorems establish the correctness of the derivationsystem with respect to the semantics, the coextensiveness of thesyntactic definitions of consistency and totalness with theirsemantic counterparts, and the correctness of the proof methodspresented. Areas for future research are discussed.',135870,'Journal of the ACM (JACM)',2),(319,NULL,'1984',NULL,'A Theory of Communicating Sequential Processes','A mathematical model for communicating sequential processes isgiven, and a number of its interesting and useful properties arestated and proved. The possibilities of nondetermimsm are fullytaken into account.',135870,'Journal of the ACM (JACM)',2),(321,NULL,'1984',NULL,'Multiple-access protocols and time-constrained communication','During the past ten years, the field of multiple-accesscommunication has developed into a major area of both practical andtheoretical interest within the field of computer communications.The multiple-access problem arises from the necessity of sharing asingle communication channel among a community of distributedusers. The distributed algorithm used by the stations to share thechannel is known as the multiple-access protocol. In this paper weexamine the multiple-access problem and various approaches to itsresolution.In this survey we first define the multiple-access problem andthen present the underlying issues and difficulties in achievingmultiple-access communication. A taxonomy for multiple-accessprotocols is then developed in order to characterize commonapproaches and to provide a framework within which these protocolscan be compared and contrasted. Different proposed protocols arethen described and discussed, and aspects of their performance areexamined. The use of multiple-access protocols for \"real- time\" or\"time-constrained\" communication applications, such as voicetransmission, is examined next. Issues in time-constrainedcommunication are identified, and recent work in the design oftime-constrained multiple-access protocols is surveyed.',15677,'ACM Computing Surveys (CSUR)',3),(322,NULL,'1984',NULL,'Local networks','The rapidly evolving field of local network technology hasproduced a steady stream of local network products in recent years.The IEEE 802 standards that are now taking shape, because of theircomplexity, do little to narrow the range of alternative technicalapproaches and at the same time encourage more vendors into thefield. The purpose of this paper is to present a systematic,organized overview of the alternative architectures for and designapproaches to local networks.The key elements that determine the cost and performance of alocal network are its topology, transmission medium, and mediumaccess control protocol. Transmission media include twisted pair,baseband and broadband coaxial cable, and optical fiber. Topologiesinclude bus, tree, and ring. Medium access control protocolsinclude CSMA/CD, token bus, token ring, register insertion, andslotted ring. Each of these areas is examined in detail,comparisons are drawn between competing technologies, and thecurrent status of standards is reported.',15677,'ACM Computing Surveys (CSUR)',3),(549,NULL,'1984',NULL,'On the selection of efficient record segmentations and backup strategies for large shared databases','In recent years the information processing requirements of business organizations have expanded tremendously. With this expansion, the design of databases to efficiently manage and protect business information has become critical. We analyze the impacts of record segmentation (the assignment of data items to segments defining subfiles), an efficiency-oriented design technique, and of backup and recovery strategies, a data protection technique, on the overall process of database design. A combined record segmentation/backup and recovery procedure is presented and an application of the procedure is discussed. Results in which problem characteristics are varied along three dimensions: update frequencies, available types of access paths, and the predominant type of data retrieval that must be supported by the database, are presented.',16320,'ACM Transactions on Database Systems (TODS)',3),(554,NULL,'1984',NULL,'Optimism and consistency in partitioned distributed database systems','A protocol for transaction processing during partition failures is presented which guarantees mutual consistency between copies of data-items after repair is completed. The protocol is “optimistic” in that transactions are processed without restrictions during failure; conflicts are then detected at repair time using a precedence graph, and are resolved by backing out transactions according to some backout strategy. The resulting database state then corresponds to a serial execution of some subset of transactions run during the failure. Results from simulation and probabilistic modeling show that the optimistic protocol is a reasonable alternative in many cases. Conditions under which the protocol performs well are noted, and suggestions are made as to how performance can be improved. In particular, a backout strategy is presented which takes into account individual transaction costs and attempts to minimize total backout cost. Although the problem of choosing transactions to minimize total backout cost is, in general, NP-complete, the backout strategy is efficient and produces very good results.',16320,'ACM Transactions on Database Systems (TODS)',0),(713,NULL,'1984',NULL,'Performance analysis of recovery techniques','Various logging and recovery techniques for centralized transaction-oriented database systems under performance aspects are described and discussed. The classification of functional principles that has been developed in a companion paper is used as a terminological basis. In the main sections, a set of analytic models is introduced and evaluated in order to compare the performance characteristics of nine different recovery techniques with respect to four key parameters and a set of other parameters with less influence. Finally, the results of model evaluation as well as the limitations of the models themselves are discussed.',16320,'ACM Transactions on Database Systems (TODS)',5),(871,NULL,'1984',NULL,'Vertical partitioning algorithms for database design','This paper addresses the vertical partitioning of a set of logical records or a relation into fragments. The rationale behind vertical partitioning is to produce fragments, groups of attribute columns, that “closely match” the requirements of transactions.Vertical partitioning is applied in three contexts: a database stored on devices of a single type, a database stored in different memory levels, and a distributed database. In a two-level memory hierarchy, most transactions should be processed using the fragments in primary memory. In distributed databases, fragment allocation should maximize the amount of local transaction processing.Fragments may be nonoverlapping or overlapping. A two-phase approach for the determination of fragments is proposed; in the first phase, the design is driven by empirical objective functions which do not require specific cost information. The second phase performs cost optimization by incorporating the knowledge of a specific application environment. The algorithms presented in this paper have been implemented, and examples of their actual use are shown.',16320,'ACM Transactions on Database Systems (TODS)',2),(976,NULL,'1985',NULL,'Optimal prepaging and font caching','An efficient algorithm for communicating letter-shape information from a high-speed computer with a large memory to a typesetting device that has a limited memory is presented. The encoding is optimum, in the sense that the total time for typesetting is minimized, using a model that generalizes well-known “demand paging” strategies to the case where changes to the cache are allowed before the associated information is actually needed. Extensive empirical data show that good results are obtained even when difficult technical material is being typeset on a machine that can store information concerning only 100 characters. The methods of this paper are also applicable to other hardware and software caching applications with restricted lookahead.',16444,'ACM Transactions on Programming Languages and Systems (TOPLAS)',4),(1130,NULL,'1982',NULL,'A Unified Approach to a Class of Data Movements on an Array Processor','The most effective use of mesh-connected array processors is achieved by paying careful attention to the organization of data. Storage and movement of the elements of multidimensional arrays of data within a multidimensional store for a particular problem is a difficult task, often handled in an ad hoc way. For an important class of problems, considerable conceptual simplification arises from considering a specification of the mapping rather than the physical location of data.',117351,'IEEE Transactions on Computers',3),(1149,NULL,'1985',NULL,'Grosch\'s law re-revisited: CPU power and the cost of computation','Does Grosch\'s law, which postulated that the costs of computer systems increase at a rate equivalent to the square root of their power, still hold? The age of mini-, micro-, and supercomputers seems to have complicated the situation. When computers are grouped according to their size and power, Grosch\'s law seems to hold within each group, but not between different groups.',52621,'Communications of the ACM',3),(1155,NULL,'1985',NULL,'Amortized efficiency of list update and paging rules','In this article we study the amortized efficiency of the “move-to-front” and similar rules for dynamically maintaining a linear list. Under the assumption that accessing the ith element from the front of the list takes &thgr;(i) time, we show that move-to-front is within a constant factor of optimum among a wide class of list maintenance rules. Other natural heuristics, such as the transpose and frequency count rules, do not share this property. We generalize our results to show that move-to-front is within a constant factor of optimum as long as the access cost is a convex function. We also study paging, a setting in which the access cost is not convex. The paging rule corresponding to move-to-front is the “least recently used” (LRU) replacement rule. We analyze the amortized complexity of LRU, showing that its efficiency differs from that of the off-line paging rule (Belady\'s MIN algorithm) by a factor that depends on the size of fast memory. No on-line paging algorithm has better amortized performance.',52621,'Communications of the ACM',9),(1317,NULL,'1985',NULL,'Beyond two-phase locking','Many database systems maintain the consistency of the data by using a locking protocol to restrict access to data items. It has been previously shown that if no information is known about the method of accessing items in the database, then the two-phase protocol is optimal. However, the use of structural information about the database allows development of non-two-phase protocols, called graph protocols, that can potentially increase efficiency. Yannakakis developed a general class of protocols that included many of the graph protocols. Graph protocols either are only usable in certain types of databases or can incur the performance liability of cascading rollback. In this paper, it is demonstrated that if the system has a priori information as to which data items will be locked first by various transactions, a new graph protocol that is outside the previous classes of graph protocols and is applicable to arbitrarily structured databases can be constructed. This new protocol avoids cascading rollback and its accompanying performance degradation, and extends the class of serializable sequences allowed by non-two-phase protocols. This is the first protocol shown to be always as effective as the two-phase protocol, and it can be more effective for certain types of database systems.',135870,'Journal of the ACM (JACM)',3),(1327,NULL,'1985',NULL,'Computational implementation of the multivariate Halley method for solving nonlinear systems of equations','Cubicaliy convergent iterative methods for the solution of nonlinear systems of the multivariate Halley method, require first and second partial derivatives of the of the functions comprising the system. Automatic differentiation is used to automate the Halley method, HESSIAN and routines for the required operators and functions. A Pascal-SC which implements this method in a single-step iteration mode. The program nonlinear systems, and the results are compared with Newton\'s method.',16407,'ACM Transactions on Mathematical Software (TOMS)',2),(1357,NULL,'1985',NULL,'An evaluation of retrieval effectiveness for a full-text document-retrieval system','An evaluation of a large, operational full-text document-retrieval system (containing roughly 350,000 pages of text) shows the system to be retrieving less than 20 percent of the documents relevant to a particular search. The findings are discussed in terms of the theory and practice of full-text document retrieval.',52621,'Communications of the ACM',5),(1387,NULL,'1985',NULL,'Use of graph-theoretic models for optimal relational database accesses to perform join','A graph model is presented to analyze the performance of a relational join. The amount of page reaccesses, the page access sequence, and the amount of buffer needed are represented in terms of graph parameters. By using the graph model formed from the index on the join attributes, we determine the relationships between these parameters. Two types of buffer allocation strategies are studied, and the upper bound on the buffer size with no page reaccess is given. This bound is shown to be the maximum cut value of a graph. Hence, the problem of computing this upper bound is NP-hard. We also give algorithms to determine a page access sequence requiring a near optimal buffer size with no page reaccess. The optimal page access sequence for a fixed buffer size has also been considered.',16320,'ACM Transactions on Database Systems (TODS)',9),(1399,NULL,'1985',NULL,'Statistical mechanics and disordered systems','Since computers are able to simulate the equilibrium properties of model systems, they may also prove useful for solving the hard optimization problems that arise in the engineering of complex systems.',52661,'Communications of the ACM - Lecture notes in computer science Vol. 174',5),(1445,NULL,'1985',NULL,'Optimal parallel generation of a computation tree form','Given a general arithmetic expression, we find a computation binary tree representation in O(log n) time using n/log n processors on a concurrent-read, exclusive-write, parallel random-access machine.A new algorithm is introduced for this purpose. Unlike previous serial and parallel solutions, it is not based on using a stack.',16445,'ACM Transactions on Programming Languages and Systems (TOPLAS) - Lecture notes in computer science Vol. 174',9),(1709,NULL,'1985',NULL,'On time and space decomposition of complex structures','Models of large and complex systems can often be reduced to smaller sub-models, for easier analysis, by a process known as decomposition. Certain criteria for successful decompositions can be established.',52621,'Communications of the ACM',2),(1713,NULL,'1985',NULL,'A randomized protocol for signing contracts','Randomized protocols for signing contracts, certified mail, and flipping a coin are presented. The protocols use a 1-out-of-2 oblivious transfer subprotocol which is axiomatically defined.The 1-out-of-2 oblivious transfer allows one party to transfer exactly one secret, out of two recognizable secrets, to his counterpart. The first (second) secret is received with probability one half, while the sender is ignorant of which secret has been received.An implementation of the 1-out-of-2 oblivious transfer, using any public key cryptosystem, is presented.',52621,'Communications of the ACM',2),(1725,NULL,'1985',NULL,'A model of computation for VLSI with related complexity results','A new model of computation for VLSI, based on the assumption that time for propagating information is at least linear in the distance, is proposed. While accommodating for basic laws of physics, the model is designed to be general and technology independent. Thus, from a complexity viewpoint, it is especially suited for deriving lower bounds and trade-offs. New results for a number of problems, including fan-in, transitive functions, matrix multiplication, and sorting are presented. As regards upper bounds, it must be noted that, because of communication costs, the model clearly favors regular and pipelined architectures (e.g., systolic arrays).',135870,'Journal of the ACM (JACM)',9),(1874,NULL,'1985',NULL,'Data-flow algorithms for parallel matrix computation','In this article we develop some algorithms and tools for solving matrix problems on parallel processing computers. Operations are synchronized through data-flow alone, which makes global synchronization unnecessary and enables the algorithms to be implemented on machines with very simple operating systems and communication protocols. As examples, we present algorithms that form the main modules for solving Liapounov matrix equations. We compare this approach to wave front array processors and systolic arrays, and note its advantages in handling missized problems, in evaluating variations of algorithms or architectures, in moving algorithms from system to system, and in debugging parallel algorithms on sequential machines.',52621,'Communications of the ACM',2),(1905,NULL,'1985',NULL,'The Qualified Function Approach to Analysis of Program Behavior and Performance','The notion of a qualified function is introduced as a general means of representing the parameters of dynamic systems. Two specific types of qualified functions are defined for the analysis of the behavior and performance of structured programs. Transformation functions represent the values of variables during execution and timing algorithms express the execution times of programs symbolically. Complete rules of derivation for transformation functions and timing algorithms are given for the control mechanisms of sequence, selection, fixed loop, and while statement. Deterministic and stochastic simplification of transformation functions and timing algorithms are investigated and methods of eliminating recursion for expressions corresponding to while statements are studied.',117421,'IEEE Transactions on Software Engineering - Annals of discrete mathematics, 24',2),(2025,NULL,'1985',NULL,'A simplex algorithm whose average number of steps is bounded between two quadratic functions of the smaller dimension','It has been a challenge for mathematicians to confirm theoretically the extremely good performance of simplex-type algorithms for linear programming. In this paper the average number of steps performed by a simplex algorithm, the so-called self-dual method, is analyzed. The algorithm is not started at the traditional point (1, … , l)T, but points of the form (1, &egr;, &egr;2, …)T, with &egr; sufficiently small, are used. The result is better, in two respects, than those of the previous analyses. First, it is shown that the expected number of steps is bounded between two quadratic functions c1(min(m, n))2 and c2(min(m, n))2 of the smaller dimension of the problem. This should be compared with the previous two major results in the field. Borgwardt proves an upper bound of O(n4m1/(n-1)) under a model that implies that the zero vector satisfies all the constraints, and also the algorithm under his consideration solves only problems from that particular subclass. Smale analyzes the self-dual algorithm starting at (1, … , 1)T. He shows that for any fixed m there is a constant c(m) such the expected number of steps is less than c(m)(ln n)m(m+1); Megiddo has shown that, under Smale\'s model, an upper bound C(m) exists. Thus, for the first time, a polynomial upper bound with no restrictions (except for nondegeneracy) on the problem is proved, and, for the first time, a nontrivial lower bound of precisely the same order of magnitude is established. Both Borgwardt and Smale require the input vectors to be drawn from spherically symmetric distributions. In the model in this paper, invariance is required only under certain',135870,'Journal of the ACM (JACM)',9),(2028,NULL,'1985',NULL,'A fast parallel algorithm for the maximal independent set problem','A parallel algorithm is presented that accepts as input a graph G and produces a maximal independent set of vertices in G. On a P-RAM without the concurrent write or concurrent read features, the algorithm executes in O((log n)4) time and uses O((n/(log n))3) processors, where n is the number of vertices in G. The algorithm has several novel features that may find other applications. These include the use of balanced incomplete block designs to replace random sampling by deterministic sampling, and the use of a “dynamic pigeonhole principle” that generalizes the conventional pigeonhole principle.',135870,'Journal of the ACM (JACM)',9),(2060,NULL,'1985',NULL,'An Implementation of an Automated Protocol Synthesizer (APS) and Its Application to the X.21 Protocol','In the past, a number of methods have been proposed to model and validate communication protocols that have already been designed. However, design criteria and design aids are still lacking for designing correct protocols. The objective of developing automated protocol synthesizers is to provide a systematic way of designing new communication protocols such that their correctness can be ensured.',117428,'IEEE Transactions on Software Engineering - Special issue on COMPSAC 1982 and 1983',3),(2465,NULL,'1986',NULL,'A chaotic asynchronous algorithm for computing the fixed point of a nonnegative matrix of unit spectral radius','Given a nonnegative, irreducible matrix P of spectral radius unity, there exists a positive vector &pgr; such that &pgr; = &pgr;P. If P also happens to be stochastic, then &pgr; gives the stationary distribution of the Markov chain that has state-transition probabilities given by the elements of P. This paper gives an algorithm for computing &pgr; that is particularly well suited for parallel processing. The main attraction of our algorithm is that the timing and sequencing restrictions on individual processors are almost entirely eliminated and, consequently, the necessary coordination between processors is negligible and the enforced idle time is also negligible.Under certain mild and easily satisfied restrictions on P and on the implementation of the algorithm, x(.), the vectors of computed values are proved to converge to within a positive, finite constant of proportionality of &pgr;. It is also proved that a natural measure of the projective distance of x(.) from &pgr; vanishes geometrically fast, and at a rate for which a lower bound is given. We have conducted extensive experiments on random matrices P, and the results show that the improvement over the parallel implementation of the synchronous version of the algorithm is substantial, sometimes exceeding the synchronization penalty to which the latter is always subject.',135871,'Journal of the ACM (JACM) - The MIT Press scientific computation series',9),(2617,NULL,'1985',NULL,'Integrated concurrency control and recovery mechanisms: design and performance evaluation','In spite of the wide variety of concurrency control and recovery mechanisms proposed during the past decade, the behavior and the performance of various concurrency control and recovery mechanisms remain largely not well understood. In addition, although concurrency control and recovery mechanisms are intimately related, the interaction between them has not been adequately explored. In this paper, we take a unified view of the problems associated with concurrency control and recovery for transaction-oriented multiuser centralized database management systems, and we present several integrated mechanisms. We then develop analytical models to study the behavior and compare the performance of these integrated mechanisms, and we present the results of our performance evaluation.',16320,'ACM Transactions on Database Systems (TODS)',5),(2837,NULL,'1986',NULL,'Partitioning and Mapping Algorithms into Fixed Size Systolic Arrays','A technique for partitioning and mapping algorithms into VLSI systolic arrays is presented in this paper. Algorithm partitioning is essential when the size of a computational problem is larger than the size of the VLSI array intended for that problem. Computational models are introduced for systolic arrays and iterative algorithms. First, we discuss the mapping of algorithms into arbitrarily large size VLSI arrays. This mapping is based on the idea of algorithm transformations. Then, we present an approach to algorithm partitioning which is also based on algorithm transformations. Our approach to the partitioning problem is to divide the algorithm index set into bands and to map these bands into the processor space. The partitioning and mapping technique developed throughout the paper is summarized as a six step procedure. A computer program implementing this procedure was developed and some results obtained with this program are presented.',117351,'IEEE Transactions on Computers',9),(2838,NULL,'1986',NULL,'Testability Conditions for Bilateral Arrays of Combinational Cells','Two sets of conditions are derived that make one- dimensional bilateral arrays of combinational cells testable for single faulty cells. The test sequences are preset and, in the worst case, grow quadratically with the size of the array. Conditions for testability in linear time are also derived. The basic cell can operate at the bit or at the word level. An implementation of FIR filters using (systolic) one-dimensional bilateral arrays of cells, which can be considered combinational at the word level, is presented as an example. A straightforward generalization for the two- dimensional case is made; a systolic array used for matrix multiplication is presented as an example for this case.',117351,'IEEE Transactions on Computers',1),(2839,NULL,'1986',NULL,'DFSP: A Data Flow Signal Processor','The concept of data flow computing is applied to digital signal processing (DSP). A data flow signal processor (DFSP) architecture is presented. The principles of data flow computing are carefully considered in order to conform with the special properties of DSP. The bus oriented architecture is easily configured to meet various performance requirements. The DFSP architecture is most suitable for nonrecursive algorithms. Typical tasks of this nature are transforms and FIR filters. A simulation model of the DFSP architecture has been developed. Simulation results of two application examples are given.',117351,'IEEE Transactions on Computers',5),(2840,NULL,'1986',NULL,'A Heuristic for Suffix Solutions','The suffix problem has appeared in solutions of recurrence systems for parallel and pipelined machines and more recently in the design of gate and silicon compilers. In this paper we present two algorithms. The first algorithm generates parallel suffix solutions with minimum cost for a given length, time delay, availability of initial values, and fanout. This algorithm generates a minimal solution for any length n and depth range from log2 n to n. The second algorithm reduces the size of the solutions generated by the first algorithm.',117351,'IEEE Transactions on Computers',9),(2841,NULL,'1986',NULL,'Determining an Optimal Secondary Storage Service Rate for the PASM Control System','One class of reconfigurable parallel processing systems is based on the use of a large number of processing elements which can be partitioned into multiple virtual machines. Each virtual machine is controlled by one or more control units. The multiple control units in such a system share a common secondary storage for programs. The control units use paging to transfer programs to their primary memories. One design problem is determining the optimal service rate for the secondary storage of the control units, where the \"optimal\" is characterized by maximum processor utilization. The PASM parallel processing system is used as a example system to study this problem. The implementation of virtual memory on the PASM control system memory hierarchy is discussed and a queueing network model for the memory hierarchy is developed. Based on assumed values for parameters that characterize the expected task environment, an optimal service rate is derived from the model. The values of the parameters in the model can be varied to determine the impact these changes would have on system performance. Simulation results verifying various aspects of the model are presented and the results are generalized.',117351,'IEEE Transactions on Computers',3),(2842,NULL,'1986',NULL,'An Enhanced Approximation by Pair-Wise Analysis of Servers for Time Delay Distributions in Queueing Networks','An approximation for the distribution of time delays experienced by a customer in a network of queues is presented. Approximate analytical models are necessary since exact solutions are only available for a very restricted class of networks, and are too complex computationally to be viable in practice. Approximations have so far often proved inadequate, particularly for closed networks with first come first served queueing disciplines. We also prove that the correlation between the sojourn times at successive servers on a customer\'s path in a closed queueing network with exponential servers is negative.',117351,'IEEE Transactions on Computers',7),(2851,NULL,'1986',NULL,'Optimization of join operations in horizontally partitioned database systems','This paper analyzes the problem of joining two horizontally partitioned relations in a distributed database system. Two types of semijoin strategies are introduced, local and remote. Local semijoins are performed at the site of the restricted relation (or fragment), and remote semijoins can be performed at an arbitrary site. A mathematical model of a semijoin strategy for the case of remote semijoins is developed, and lower bounding and heuristic procedures are proposed. The results of computational experiments are reported. The experiments include an analysis of the heuristics\' performance relative to the lower bounds, sensitivity analysis, and error analysis. These results reveal a good performance of the heuristic procedures, and demonstrate the benefit of using semijoin operations to reduce the size of fragments prior to their transmission. The algorithms for the case of remote semijoins were found to be superior to the algorithms for the case of local semijoins. In addition, we found that the estimation accuracy of the selectivity factors has a significant effect on the incurred communication cost.',16320,'ACM Transactions on Database Systems (TODS)',2),(2980,NULL,'1986',NULL,'The mutual exclusion problem: part I—a theory of interprocess communication','A novel formal theory of concurrent systems that does not assume any atomic operations is introduced. The execution of a concurrent program is modeled as an abstract set of operation executions with two temporal ordering relations: “precedence” and “can causally affect”. A primitive interprocess communication mechanism is then defined. In Part II, the mutual exclusion is expressed precisely in terms of this model, and solutions using the communication mechanism are given.',135870,'Journal of the ACM (JACM)',2),(3044,NULL,'1986',NULL,'Provably Conservative Approximations to Complex Reliability Models','Provably conservative (and optimistic) reliability models can be systematically derived from more complex models. These derived models incorporate a reduced state space and fewer transitions, and, therefore, have solutions that are more cost- effective than those of the original complex models. The designer can extensively explore the design space without incurring the expense of solving multiple complex models. A conservative- optimistic pair of derived models produces a band that includes the solution to the complex model. Sensitivity analysis can be performed on this pair of models to determine those parameters of the original model that are most sensitive to change (i.e., uncertainty) and hence warrant further expense in obtaining tighter specifications.',117365,'IEEE Transactions on Computers - The MIT Press scientific computation series',2),(3047,NULL,'1986',NULL,'The design and building of Enchère, a distributed electronic marketing system','Building and prototyping an agricultural electronic marketing system involved experimenting with distributed synchronization, atomic activity, and commit protocols and recovery algorithms.',52621,'Communications of the ACM',5),(3199,NULL,'1986',NULL,'Fragmentation: a technique for efficient query processing','A “divide and conquer” strategy to compute natural joins by sequential scans on unordered relations is described. This strategy is shown to always he better than merging SCBIIS when both relations must he sorted before joining, and generally better in practical cases when only the largest relation mutt be sorted.',16320,'ACM Transactions on Database Systems (TODS)',2),(3228,NULL,'1986',NULL,'A comment on “a fast parallel algorithm for thinning digital patterns”','A fast parallel thinning algorithm for digital patterns is presented. This algorithm is an improved version of the algorithms introduced by Zhang and Suen [5] and Stefanelli and Rosenfeld [3]. An experiment using an Apple II and an Epson printer was conducted. The results show that the improved algorithm overcomes some of the disadvantages found in [5] by preserving necessary and essential structures for certain patterns which should not be deleted and maintains very fast speed, from about 1.5 to 2.3 times faster than the four-step and two-step methods described in [3] although the resulting skeletons look basically the same.',52716,'Communications of the ACM - The MIT Press scientific computation series',2),(3231,NULL,'1986',NULL,'How not to lie with statistics: the correct way to summarize benchmark results','Using the arithmetic mean to summarize normalized benchmark results leads to mistaken conclusions that can be avoided by using the preferred method: the geometric mean.',52716,'Communications of the ACM - The MIT Press scientific computation series',2),(3243,NULL,'1986',NULL,'A locally adaptive data compression scheme','A data compression scheme that exploits locality of reference, such as occurs when words are used frequently over short intervals and then fall into long periods of disuse, is described. The scheme is based on a simple heuristic for self-organizing sequential search and on variable-length encodings of integers. We prove that it never performs much worse than Huffman coding and can perform substantially better; experiments on real files show that its performance is usually quite close to that of Huffman coding. Our scheme has many implementation advantages: it is simple, allows fast encoding and decoding, and requires only one pass over the data to be compressed (static Huffman coding takes two passes).',52621,'Communications of the ACM',2),(3422,NULL,'1986',NULL,'A note on the height of binary search trees','Let Hn be the height of a binary search tree with n nodes constructed by standard insertions from a random permutation of 1, … , n. It is shown that Hn/log n → c = 4.31107 … in probability as n → ∞, where c is the unique solution of c log((2e)/c) = 1, c ≥ 2. Also, for all p 0, limn→∞E(Hpn)/ logpn = cp. Finally, it is proved that Sn/log n → c* = 0.3733 … , in probability, where c* is defined by c log((2e)/c) = 1, c ≤ 1, and Sn is the saturation level of the same tree, that is, the number of full levels in the tree.',135870,'Journal of the ACM (JACM)',9),(3427,NULL,'1986',NULL,'Asymptotic expansions for closed Markovian networks with state-dependent service rates','A method is presented for calculating the partition function, and from it, performance measures, for closed Markovian stochastic networks with queuing centers in which the service or processing rate depends on the center\'s state or load. The analysis on which this method is based is new and a major extension of our earlier work on load-independent queuing networks. The method gives asymptotic expansions for the partition function in powers of 1/N, where N is a parameter that reflects the size of the network. The expansions are particularly useful for large networks with many classes, each class having many customers. The end result is a decomposition by which expansion coefficients are obtained exactly by linear combinations of partition function values of small network constructs called pseudonetworks. Effectively computable bounds are given for errors arising from the use of a finite number of expansion terms. This method is important because load dependence is at once an essential element of sophisticated network models of computers, computer communications, and switching, teletraffic, and manufacturing systems, and the cause of very intensive computations in conventional techniques. With this method, very large load-dependent networks can be analyzed, whereas previously only small networks were computationally tractable.',135870,'Journal of the ACM (JACM)',7),(3445,NULL,'1986',NULL,'The concept of a supercompiler','A supercompiler is a program transformer of a certain type. It traces the possible generalized histories of computation by the original program, and compiles an equivalent program, reducing in the process the redundancy that could be present in the original program. The nature of the redundancy that can be eliminated by supercompilation may be various, e.g., some variables might have predefined values (as in partial evaluation), or the structure of control transfer could be made more efficient (as in lazy evaluation), or it could simply be the fact that the same variable is used more than once. The general principles of supercompilation are described and compared with the usual approach to program transformation as a stepwise application of a number of equivalence rules. It is argued that the language Refal serves the needs of supercompilation best. Refal is formally defined and compared with Prolog and other languages. Examples are given of the operation of a Refal supercompiler implemented at CCNY on an IBM/370.',16448,'ACM Transactions on Programming Languages and Systems (TOPLAS) - The MIT Press scientific computation series',2),(3524,NULL,'1986',NULL,'Structure handling in data-flow systems','Data-flow languages have been hailed as the solution to the programmability of general-purpose multiprocessors. However, data-flow semantics introduce constructs that lead to much overhead at compilation, allocation, and execution time. Indeed, due to its functionality, the data-flow model of computation does not handle repetitive program constructs very efficiently. This is due to the fact that the cornerstone of data flow, namely the concept of single assignment, is opposed to the idea of reexecution of a portion of program as in a loop. A corollary of this problem is the effective representation, storage, and processing of data structures, as these will most often be used in loops. In this paper, various aspects of this issue are explailned in detail. Several solutions that have been put forward in the current literature are then surveyed and analyzed. In order to offset some of the disadvantages presented by these, we introduce new methods for handling arrays. In the first one, we raise the level of computation to that of arrays for more efficient operation. In the two others, the opposite approach is taken, and the notion of array is done away with entirely at the execution level in order to take advantage of the data-flow semantics at their best logical level of performance.',117365,'IEEE Transactions on Computers - The MIT Press scientific computation series',2),(3534,NULL,'1986',NULL,'A connecting network with fault tolerance capabilities','A new multistage interconnection network is presented in this paper. It is able to handle the communications between the connected devices correctly, even in the presence of fault(s) in the network. This goal is achieved by using redundant paths with a fast procedure able to dynamically reroute the message. It is also shown that the rerouting properties are still valid when broadcasting transmission is used.',117365,'IEEE Transactions on Computers - The MIT Press scientific computation series',7),(3552,NULL,'1985',NULL,'Distributed operating systems','Distributed operating systems have many aspects in common with centralized ones, but they also differ in certain ways. This paper is intended as an introduction to distributed operating systems, and especially to current university research about them. After a discussion of what constitutes a distributed operating system and how it is distinguished from a computer network, various key design issues are discussed. Then several examples of current research projects are examined in some detail, namely, the Cambridge Distributed Computing System, Amoeba, V, and Eden.',15683,'ACM Computing Surveys (CSUR) - The MIT Press scientific computation series',5),(3554,NULL,'1986',NULL,'Computer and Database Location in Distributed Computer Systems','Design of distributed computer systems is a complex task requiring solutions for several difficult problems. Location of computing resources and databases in a wide-area network is one of these problems which has not yet been solved satisfactorily. Solution of this problem involves determining number and size of computer facilities and their locations, configuring databases and allocating these databases among computer facilities. An integer programming formulation of the problem is presented. Heuristic and optimal solution procedures are developed and computational experience with these procedures is reported. Implications of the model for designing distributed systems are discussed.',117351,'IEEE Transactions on Computers',5),(3555,NULL,'1986',NULL,'Finite State Model and Compatibility Theory: New Analysis Tools for Permutation Networks','In this paper, we present a new model, finite permutation machine (FPM), to describe the permutation networks. A set of theorems are developed to capture the theory of operations for the permutation networks. Using this new framework, an interesting problem is attacked: are 2n - 1 passes of shuffle exchange necessary and sufficient to realize all permutations? where n = log2 N and N is the number of inputs and outputs interconnected by the network. We prove that to realize all permutations, 2n - 1 passes of shuffle exchange are necessary and that 3n - 3 passes are sufficient. This reduces the sufficient number of passes by 2 from the best-known result.',117351,'IEEE Transactions on Computers',7),(3556,NULL,'1986',NULL,'Pseudo-Boolean Logic Circuits','A new class of switch-level logic circuits intended for modeling digital MOS VLSI circuits is presented. These circuits, which are called pseudo-Boolean, are composed of a single (voltage) source, connectors, switches, attenuators, and wells. The latter two devices are digital versions of resistors and capacitors, respectively, and may assume an arbitrary but finite number of different sizes. Signals are bidirectional, and are assigned a finite set of values of the form (v, s) where v corresponds to voltage level and s corresponds to electrical current or charge level (logical strength). It is shown that these signal values and the associated logical operations form a generalization of Boolean algebra called pseudo-Boolean or Heyting algebra. The analysis of pseudo- Boolean circuits using discrete counterparts of Kirchoff\'s current law and the superposition principle is discussed, as well as the application of pseudo-Boolean techniques to digital simulation.',117351,'IEEE Transactions on Computers',1),(3557,NULL,'1986',NULL,'A Simulation Study of the CRAY X-MP Memory System','One of the significant differences between the CRAY X-MP and its predecessor, the CRAY-1S, is a considerably increased memory bandwidth for vector operations. Up to three vector streams in each of the two processors may be active simultaneously. These streams contend for memory banks as well as data paths. All memory conflicts are resolved dynamically by the memory system. This paper describes a simulation study of the CRAY X-MP interleaved memory system with attention focused on steady state performance for sequences of vector operations. Because it is more amenable to analysis, we first study the interaction of vector streams issued from a single processor. We identify the occurrence of linked conflicts, repeating sequences of conflicts between two or more vector streams that result in reduced steady state performance. Both worst case and average case performance measures are given. The discussion then turns to dual processor interactions. Finally, based on our simulations, possible modifications to the CRAY X-MP memory system are proposed and compared. These modifications are intended to eliminate or reduce the effects of linked conflicts.',117351,'IEEE Transactions on Computers',4),(3558,NULL,'1986',NULL,'A Triple Modular Redundancy Technique Providing Multiple-Bit Error Protection Without Using Extra Redundancy','A well-known technique for providing tolerance against single hardware component failures is triplication of the component, called triple modular redundancy (TMR). In this paper a component is taken to be a processor-memory configuration where the memory is organized in a bit-sliced way. If voting is performed bitwise in an orthodox TMR configuration consisting of three of these components, failure of a complete component or failure of bit-slices not on corresponding positions in the memories can be tolerated. We present a TMR technique, not using more redundancy than orthodox TMR, that can tolerate the failure of arbitrary bit-slices (including those on corresponding positions) up to a certain amount. Additionally it can tolerate the failure of arbitrary bit-slices up to a certain amount whenever one component is known to be malfunctioning or whenever one component is disabled. This generalized TMR technique is described for processor-memory configurations processing 4-, 8-, and 16-bit words, respectively.',117351,'IEEE Transactions on Computers',6),(3559,NULL,'1986',NULL,'Processor Scheduling for Linearly Connected Parallel Processors','A low-level parallel processor (LLPP) is one in which two or more machine-level operations are executed in parallel. This paper analyzes the use of linearly connected LLPP\'s for parallel evaluation of program fragments. A graph-theoretic model is presented which describes the communication constraints of linearly connected parallel processors. A tight, necessary condition for finding assignments of program fragments to linearly connected LLPP\'s that require no communication delays is presented. Also, several weak sufficient conditions have been found and efficient heuristics for determining optimal assignments have been developed.',117351,'IEEE Transactions on Computers',9),(3562,NULL,'1986',NULL,'On Fault Isolation and Identification in t1/t1-Diagnosable Systems','Consider a classical PMC system composed of n units [1] where it is assumed that at most t1 of these units are faulty. Such a system is said to be t1/t1-diagnosable [3] if, given any complete collection of test results, the set of faulty units can be isolated to within a set of at most t1 units. This paper exposes some new, important properties of general t1/t1-diagnosable systems to present an O(n2.5) algorithm by which all the faulty units except at most one can be correctly identified and all the faulty units can be isolated to within a set of t1 or fewer units in which at most one can possibly be fault free.',117351,'IEEE Transactions on Computers',6),(3563,NULL,'1986',NULL,'Can Redundancy and Masking Improve the Performance of Synchronizers?','This paper considers the possibility of achieving improvements in the reliability of synchronizing an asynchronous signal, by exploiting redundancy and masking. Redundancy and masking techniques have been applied successfully to mask both permanent and transient hardware faults. However, it is shown in this paper that redundancy and masking techniques are ineffective against synchronization failures which arise because of metastable behavior of synchronizing elements.',117351,'IEEE Transactions on Computers',6),(3564,NULL,'1986',NULL,'Byte-Oriented Error-Correcting Codes for Semiconductor Memory Systems','Byte-oriented error-correcting codes are useful in correcting and detecting errors in a memory system organized in multiple-bit-perchip fashion. This paper presents the construction of new single-byte error-correcting and double-byte error-detecting codes.',117351,'IEEE Transactions on Computers',6),(3565,NULL,'1986',NULL,'Complex Integer to Complex Residue Encoding','Recently, a new algebra for manipulating complex residue numbers was reported. Its advantage over traditional methods is a reduced complex multiplication budget. In this work a complex integer to complex residue encoder is developed for use with this new numbering system.',117351,'IEEE Transactions on Computers',8),(3566,NULL,'1986',NULL,'Efficient Computation of the Maximum of the Sum of Two Sequences and Applications','Computing max{a1+ b1, a2+ b2, ... ,an+ bn} trivially takes n additions. We show that if we are given the ranking for the a\'s and the b\'s separately, then an algorithm exists which will compute the maximum in ?2n additions on the average. This can be generalized to yield an efficient algorithm to compute max{h(a1,b1',117351,'IEEE Transactions on Computers',9),(3567,NULL,'1986',NULL,'Testable Design of Single-Output Sequential Machines Using Checking Experiments','The problem of testing sequential machines using checking experiments is investigated. A method of modifying sequential machines by adding a controllable input is presented. A procedure is given to construct checking experiments for the modified machine and it is shown that only one output observation is sufficient to determine whether the machine is fault free.',117351,'IEEE Transactions on Computers',11),(3568,NULL,'1986',NULL,'Permutations on Illiac IV-Type Networks','Performing permutations of data on SIMD computers efficiently is important for high-speed execution of parallel algorithms. In this correspondence we consider realizing permutations such as perfect shuffle, matrix transpose, bit-reversal, the class of bit-permute- complement (BPC), the class of Omega, and inverse Omega permutations on N = 2n processors with Illiac IV-type interconnection network, where each processor is connected to processors at distances of ± 1 and ± N. The minimum number of data transfer operations required for realizing any of these permutations on such a network is shown to be 2(N − 1). We provide a general three-phase strategy for realizing permutations and derive routing algorithms for performing perfect shuffle, Omega, Inverse Omega, bit reversal, and matrix-transpose permutations in 2(N − 1) steps. Our approach is quite simple, and unlike previous approaches, makes efficient use of the topology of the Illiac IV-type network to realize these permutations using the optimum number of data transfers. Our strategy is quite powerful: any permutation can be realized using this strategy in 3(N − 1) steps.',117351,'IEEE Transactions on Computers',7),(3569,NULL,'1986',NULL,'An Efficient Memory System for Image Processing','Image processing operations require that an image or partial image be stored in a memory system that permits access to p 脳 q, 1 脳 pq, and/or pq 脳 1 subarrays of an image array where p and q are design parameters.',117351,'IEEE Transactions on Computers',4),(3585,NULL,'1985',NULL,'The Alpine file system','Alpine is a file system that supports atomic transactions and is designed to operate as a service on a computer network. Alpine\'s primary purpose is to store files that represent databases. An important secondary goal is to store ordinary files representing documents, program modules, and the like.Unlike other file servers described in the literature, Alpine uses a log-based technique to implement atomic file update. Another unusual aspect of Alpine is that it performs all communication via a general-purpose remote procedure call facility. Both of these decisions have worked out well. This paper describes Alpine\'s design and implementation, and evaluates the system in light of our experience to date.Alpine is written in Cedar, a strongly typed modular programming language that includes garbage-collected storage. We report on using the Cedar language and programming environment to develop Alpine.',16295,'ACM Transactions on Computer Systems (TOCS)',5),(3826,NULL,'1986',NULL,'Test Schedules for VLSI Circuits Having Built-In Test Hardware','In this correspondence, the concept of a test schema which describes how a test methodology is to execute is introduced. We also introduce the powerful concept of an I path which is used to transfer data unchanged from one place in a circuit to another. The process of embedding a test schema into an actual circuit is described. This produces a test plan for the circuit which specifies the sequence of actions that need to be carried out to execute the test. A theory of test plan execution overlap is presented, and is used as the basis for constructing test schedules with optimal execution times.',117365,'IEEE Transactions on Computers - The MIT Press scientific computation series',11),(3830,NULL,'1986',NULL,'Lower Overhead Design for Testability of Programmable Logic Arrays','A new technique for designing easily testable PLA\'s is presented. The salient features of this technique are: 1) low overhead, 2) high fault coverage, 3) simple design, and 4) little or no impact on normal operation of PLA\'s. This technique consists of the addition of input lines in such a way that, in test mode, any single product line can be activated and its associated circuitry and device can be tested. Using this technique, all multiple stuck-at faults, as well as all multiple extra and multiple missing device faults, are detected.',117365,'IEEE Transactions on Computers - The MIT Press scientific computation series',11),(3831,NULL,'1986',NULL,'An Alternative to Scan Design Methods for Sequential Machines','The problem of testing sequential machines using a checking experiment is investigated. An algorithm is given to augment sequential machines by adding extra input(s) to make them testable. We also present a circuit modification method, similar to scan methods, such that the augmented machine can be tested by the checking experiment. A justification of our method for a VLSI environment is given by determining the overheads.',117365,'IEEE Transactions on Computers - The MIT Press scientific computation series',11),(3867,NULL,'1986',NULL,'Evaluating two massively parallel machines','Two radically different parallel computers prompt a debate about the best parallel architectures and may mark the commercial viability of parallelism on the supercomputer scale.',52621,'Communications of the ACM',4),(3868,NULL,'1986',NULL,'Toward real-time performance benchmarks for Ada','Benchmarks are developed to measure the Ada notion of time, the Ada features believed important to real-time performance, and other time-related features that are not part of the language, but are part of the run-time system; these benchmarks are then applied to the language and run-time system, and the results evaluated.',52621,'Communications of the ACM',5),(3872,NULL,'1986',NULL,'Graph-Based Algorithms for Boolean Function Manipulation','In this paper we present a new data structure for representing Boolean functions and an associated set of manipulation algorithms. Functions are represented by directed, acyclic graphs in a manner similar to the representations introduced by Lee [1] and Akers [2], but with further restrictions on the ordering of decision variables in the graph. Although a function requires, in the worst case, a graph of size exponential in the number of arguments, many of the functions encountered in typical applications have a more reasonable representation. Our algorithms have time complexity proportional to the sizes of the graphs being operated on, and hence are quite efficient as long as the graphs do not grow too large. We present experimental results from applying these algorithms to problems in logic design verification that demonstrate the practicality of our approach.',117351,'IEEE Transactions on Computers',9),(3873,NULL,'1986',NULL,'A Simulation Study of Decoupled Architecture Computers','Decoupled architectures achieve high scalar performance by cleanly splitting instruction processing into memory access and execution tasks. Several decoupled architectures have been proposed, and they all have two characteristics in common: 1) they have two separate sets of instructions, one for accessing memory and one for performing function execution. 2) The memory accessing task and the execution task communicate via architectural queues.',117351,'IEEE Transactions on Computers',4),(3874,NULL,'1986',NULL,'Analysis of a Class of Recovery Procedures','Recovery procedures involving time redundancy in the form of instruction retries and program rollbacks have proved to be very effective against transient failures in computer systems. A class of such recovery procedures is presented and analyzed here, and the parameters of each procedure are determined so that the system\'s operation is optimized. These procedures are then compared in order to select the most appropriate one for given system parameters.',117351,'IEEE Transactions on Computers',2),(3875,NULL,'1986',NULL,'Algorithms for Iterative Array Multiplication','Algorithms for the parallel multiplication of two n- bit binary numbers by an iterative array of logic cells are discussed. The regular interconnection structures of the multiplier array cell elements, which are ideal for VLSI implementation, are described. The speed and hardware complexity of two new iterative array algorithms, both of which require n-cell delays for one n-bit 脳 n-bit multiplication, are compared to a straightforward iterative array algorithm having a 2n-cell delay and its higher radix version having an n-cell delay.',117351,'IEEE Transactions on Computers',8),(3876,NULL,'1986',NULL,'An Empirical Study of Task Switching Locality in MVS','The \"hit ratio\" of a high-speed buffer (cache) depends on the \"locality\" of memory references. However, locality of reference is disturbed and the hit ratio decreases whenever a task switch occurs. This performance degradation can be minimized if \"locality of task switching,\" the tendency for a small set of favored tasks to be frequently executed, exists and the cache is organized in such a way that it can hold blocks (lines) of multiple tasks. Locality of task switching and locality of memory references in individual tasks exhibit overall locality of memory references at a system level. This paper addresses the following questions. Does locality of task switching really exist? How can it be modeled? Task switching in IBM operating system/virtual storage with multiple virtual storage (OS/VS2 MVS) was measured using event traces for three different workloads to show that locality of task switching actually exists in MVS. Two different models of task switching are proposed. These models can be incorporated into cache multitasking models to predict more accurately the misses in real computer systems. A key parameter of these models is the task execution interval; measurements of execution intervals for the workloads used in the paper are presented and discussed.',117351,'IEEE Transactions on Computers',4),(3877,NULL,'1986',NULL,'Compression of Three-State Data Serial Streams by Means of a Parallel LFSR Signature Analyzer','In this paper drawbacks of the three-state data compressor in the form of the unit decoder 3/2 JK flip-flop are described. The main results of the paper are the algebraic operation model and the description of detection capability of a new three-state data stream compressor consisting of decoder 3/2 and a two-input shift register TISR. In particular, the properties of the unit decoder 3/2 TISR in detecting faults of the s-a-0, s- a-1, and s-a-HZ type are discussed. In this paper important aspects of the application of the new compressor are given. An example of the new compressor\'s performance scheme is also described. An additional result of this paper is the description of the operation model and the detection capability of the multiinput shift register MISR in which the most significant bit and other selected flip-flop output signals are fed back to the least significant bit positions via Exclusive-OR gates outside the flip-flops.',117351,'IEEE Transactions on Computers',2),(3878,NULL,'1986',NULL,'Testable Realizations for FET Stuck-Open Faults in CMOS Combinational Logic Circuits','In this paper, potential invalidation of stuck-open fault-detecting tests, derived by neglecting circuit delays and charge distribution in CMOS logic circuits, is studied. Several classes of circuits derived from sum of products and product of sums expressions for a given combinational logic function are investigated to determine the testability of FET stuck-open faults by tests which will remain valid in the presence of arbitrary circuit delays. Necessary and sufficient conditions for the existence of tests that will remain valid in the presence of arbitrary circuit delays are derived. Using these conditions, it is shown that all single FET stuck-open faults, in a specific design using a single CMOs complex gate, are detectable by tests that remain valid in the presence of arbitrary circuit delays. For several other realizations, methods to augment them, to insure detectability of all single FET stuck-open faults by tests that will remain valid in the presence of arbitrary circuit delays are proposed. It is observed that in many of the logic circuits investigated it is also possible to avoid test invalidation due to charge distribution.',117351,'IEEE Transactions on Computers',11),(3881,NULL,'1986',NULL,'An Algorithm for Optimal Logic Design Using Multiplexers','A set of characterizing parameters, called ratio parameters, has been used to formulate an efficient algorithm for realizing any given Boolean funetion with a single multiplexer of minimum size. The algorithm is applicable to fuctions of a large number of variables because the conventional logic design tools, e.g., Karnaugh map, decomposition chart, etc., which are unsuitable for higher variables, have not been used. The algorithm is also simple in computation, iterative in nature, and very suitable for machine implementation.',117351,'IEEE Transactions on Computers',1),(3882,NULL,'1986',NULL,'Reducing the Diameters of Computer Networks','We discuss three methods of reducing the diameters of computer networks by adding additional processor to processor links under the constraint that no more than one I/O port be added to each processor. This is equivalent to adding edges to a given graph under the constraint that the degree of any node be increased, at most, by one.',117351,'IEEE Transactions on Computers',7),(3883,NULL,'1986',NULL,'Prime Implicants, Minimum Covers, and the Complexity of Logic Simplification','We show that any Boolean function f which can be expressed in a sum-of-products form using m product terms can contain as many as 2m- 1 implicants but no more.',117351,'IEEE Transactions on Computers',1),(3884,NULL,'1986',NULL,'An Implementation of Mixed-Radix Conversion for Residue Number Applications','A method of residue number system (RNS) conversion to mixed-radix (MR) representation is presented. This method is found to be cost-effective and efficient, particularly for moduli size 4/5 bits. A comparison of conversion times and hardware necessary for RNS conversion to MR digits based on different methods is also presented.',117351,'IEEE Transactions on Computers',8),(3885,NULL,'1986',NULL,'Finding Lowest Common Ancestors in Parallel','Two parallel algorithms for finding the lowest common ancestors of a set of vertex pairs Q (the query set) in a directed tree are presented. With all the overheads taken into account, these algorithms take O((n + QI) P log2 n) and O(n2/p + log2n) time, respectively, with p( 0) processors (n is the size of the tree). These results are better than the best known result in that the first achieves th',117351,'IEEE Transactions on Computers',9),(3886,NULL,'1986',NULL,'Checkpoint Faults are not Sufficient Target Faults for Test Generation','Stuck-at faults on primary inputs and fan-out branches are commonly used as target faults in test generation algorithms for combinational circuits. This correspondence shows that these faults may not constitute an adequate set of target faults. A procedure is presented for selecting a set of target faults with the property that the detection of all detectable faults from this set guarantees the detection of all detectable faults in the circuit.',117351,'IEEE Transactions on Computers',11),(4032,NULL,'1986',NULL,'Microprocessor architectures: a comparison based on code generation by compiler','By carefully tuning computer and compiler, it is possible to avoid the otherwise inevitable compromises between complex compiling algorithms and less-than-optimal compiled code, where the key to performance appears to lie neither in sophisticated nor drastically reduced architectures, but in the key concepts of regularity and completeness.',52621,'Communications of the ACM',10),(4617,NULL,'1986',NULL,'The Escrow transactional method','A method is presented for permitting record updates by long-lived transactions without forbidding simultaneous access by other users to records modified. Earlier methods presented separately by Gawlick and Reuter are comparable but concentrate on “hot-spot” situations, where even short transactions cannot lock frequently accessed fields without causing bottlenecks. The Escrow Method offered here is designed to support nonblocking record updates by transactions that are “long lived” and thus require long periods to complete. Recoverability of intermediate results prior to commit thus becomes a design goal, so that updates as of a given time can be guaranteed against memory or media failure while still retaining the prerogative to abort. This guarantee basically completes phase one of a two-phase commit, and several advantages result: (1) As with Gawlick\'s and Reuter\'s methods, high-concurrency items in the database will not act as a bottleneck; (2) transaction commit of different updates can be performed asynchronously, allowing natural distributed transactions; indeed, distributed transactions in the presence of delayed messages or occasional line disconnection become feasible in a way that we argue will tie up minimal resources for the purpose intended; and (3) it becomes natural to allow for human interaction in the middle of a transaction without loss of concurrent access or any special difficulty for the application programmer. The Escrow Method, like Gawlick\'s Fast Path and Reuter\'s Method, requires the database system to be an “expert” about the type of transactional updates performed, most commonly updates involving incremental changes to aggregate quantities. However, the Escrow Method is extendable to other types of updates.',16320,'ACM Transactions on Database Systems (TODS)',3),(4618,NULL,'1986',NULL,'Transaction management in the R* distributed database management system','This paper deals with the transaction management aspects of the R* distributed database system. It concentrates primarily on the description of the R* commit protocols, Presumed Abort (PA) and Presumed Commit (PC). PA and PC are extensions of the well-known, two-phase (2P) commit protocol. PA is optimized for read-only transactions and a class of multisite update transactions, and PC is optimized for other classes of multisite update transactions. The optimizations result in reduced intersite message traffic and log writes, and, consequently, a better response time. The paper also discusses R*\'s approach toward distributed deadlock detection and resolution.',16320,'ACM Transactions on Database Systems (TODS)',3),(4682,NULL,'1986',NULL,'Buffer management in relational database systems','The hot-set model, characterizing the buffer requirements of relational queries, is presented. This model allows the system to determine the optimal buffer space to be allocated to a query; it can also be used by the query optimizer to derive efficient execution plans accounting for the available buffer space, and by a query scheduler to prevent thrashing. The hot-set model is compared with the working-set model. A simulation study is presented.',16320,'ACM Transactions on Database Systems (TODS)',0),(5191,NULL,'1987',NULL,'Electing a leader in a synchronous ring','The problem of electing a leader in a synchronous ring of n processors is considered. Both positive and negative results are obtained. On the one hand, if processor IDS are chosen from some countable set, then there is an algorithm that uses only O(n) messages in the worst case. On the other hand, any algorithm that is restricted to use only comparisons of IDs requires &OHgr;(n log n) messages in the worst case. Alternatively, if the number of rounds is required to be bounded by some t in the worst case, and IDs are chosen from any set having at least ƒ(n, t) elements, for a certain very fast-growing function ƒ, then any algorithm requires &OHgr;(n log n) messages in the worst case.',135870,'Journal of the ACM (JACM)',9),(6067,NULL,'1987',NULL,'Hard examples for resolution','Exponential lower bounds are proved for the length-of-resolution refutations of sets of disjunctions constructed from expander graphs, using the method of Tseitin. Since these sets of clauses encode biconditionals, they have short (polynomial-length) refutations in a standard axiomatic formulation of propositional calculus.',135870,'Journal of the ACM (JACM)',9),(6315,NULL,'1986',NULL,'Signal Processors Based Upon GaAs ICs: The Need for a Wholistic Design Approach','First Page of the Article',56373,'Computer - Special issue: GaAs: a technology for environmental extremes',5),(7511,NULL,'1986',NULL,'Implementing Watson\'s algorithm in three dimensions','Computer generated solid models must be decomposed into finite element meshes for analysis by the Finite Element Method. To enable decompositions of complex solid models, tetrahedra are employed and to avoid badly skewed tetrahedra for finite element analysis, a Delaunay triangulation is created by Watson\'s Algorithm [6]. Certain two-dimensional properties of Delaunay triangulations do not extend to the three-dimensional implementation of Watson\'s Algorithm. Furthermore, serious numerical difficulties can occur due to the nonrandomness of triangulation points, Nonrandomness imposed by the geometry can be ameliorated by using tetrahedral decompositions of icosahedra to fill space. A measure of the quality of tetrahedra is proposed and used to identify undesirable tetrahedra created due to point distributions and geometric constraints of solid models. Postprocessing Delaunay triangulations to rectify undesirable tetrahedra is briefly discussed.',211170,'SCG \'86 Proceedings of the second annual symposium on Computational geometry',2),(7518,NULL,'1986',NULL,'A sweepline algorithm for Voronoi diagrams','We present a transformation that can be used to compute Voronoi diagrams with a sweepline technique. The transformation is used to obtain simple algorithms for computing the Voronoi diagram of point sites, of line segment sites, and of weighted point sites. All algorithms have &Ogr;(n log n) worst case running time and use &Ogr;(n) space.',211170,'SCG \'86 Proceedings of the second annual symposium on Computational geometry',9),(7820,NULL,'1987',NULL,'Local Distributed Deadlock Detection by Cycle Detection and Clusterng','A distributed algorithm for the detection of deadlocks in store-and-forward communication networks is presented. At first, we focus on a static environment and develop an efficient knot detection algorithm for general graphs. The knot detection algorithm uses at most O(n2+ m) messages and O(log (n)) bits of memory to detect all deadlocked nodes in the static network. Using the knot detection algorithm as a building block, a deadlock detection algorithm in a dynamic environment is developed. This algorithm has the following properties: It detects all the nodes which cause the deadlock. The algorithm is triggered only when there is a potential for deadlock and only those nodes which are potentially deadlocked perform the algorithm. The algorithm does not affect other processes at the nodes.',117430,'IEEE Transactions on Software Engineering - Special issue on distributed systems',7),(7823,NULL,'1987',NULL,'The Gradient Model Load Balancing Method','A dynamic load balancing method is proposed for a class of large-diameter multiprocessor systems. The method is based on the \"gradient model,\" which entails transferring backlogged tasks to nearby idle processors according to a pressure gradient indirectly established by requests from idle processors. The algorithm is fully distributed and asynchronous. Global balance is achieved by successive refinements of many localized balances. The gradient model is formulated so as to be independent of system topology.',117430,'IEEE Transactions on Software Engineering - Special issue on distributed systems',0),(8194,NULL,'1987',NULL,'Distrbution and Abstract Types in Emerald','Emerald is an object-based language for programming distributed subsystems and applications. Its novel features include 1) a single object model that is used both for programming in the small and in the large, 2) support for abstract types, and 3) an explicit notion of object location and mobility. This paper outlines the goals of Em-erald, relates Emerald to previous work, and describes its type system and distribution support. We are currently constructing a prototype implementation of Emerald.',117430,'IEEE Transactions on Software Engineering - Special issue on distributed systems',5),(8195,NULL,'1987',NULL,'A Stub Generator for Multilanguage RPC in Heterogeneous Environments','A stub generator for marshalling the arguments and results of remote procedure calls in heterogeneous environments is presented. The stub generator is itself language and machine independent, and derives all its knowledge of source languages and machine types from a set of language and machine specifications. These specifications can be paired in any combination to accommodate interlanguage calls between differing machines.',117430,'IEEE Transactions on Software Engineering - Special issue on distributed systems',2),(9907,NULL,'1986',NULL,'Efficient instruction scheduling for a pipelined architecture','As part of an effort to develop an optimizing compiler for a pipelined architecture, a code reorganization algorithm has been developed that significantly reduces the number of runtime pipeline interlocks. In a pass after code generation, the algorithm uses a dag representation to heuristically schedule the instructions in each basic block.Previous algorithms for reducing pipeline interlocks have had worst-case runtimes of at least O (n4). By using a dag representation which prevents scheduling deadlocks and a selection method that requires no lookahead, the resulting algorithm reorganizes instructions almost as effectively in practice, while having an O (n2) worst-case runtime.',216668,'SIGPLAN \'86 Proceedings of the 1986 SIGPLAN symposium on Compiler construction',2),(9909,NULL,'1986',NULL,'Compilation for a high-performance systolic array','We report on a compiler for Warp, a high-performance systolic array developed at Carnegie Mellon. This compiler enhances the usefulness of Warp significantly and allows application programmers to code substantial algorithms.The compiler combines a novel programming model, which is based on a model of skewed computation for the array, with powerful optimization techniques. Programming in W2 (the language accepted by the compiler) is orders of magnitude easier than coding in microcode, the only alternative available previously.',216668,'SIGPLAN \'86 Proceedings of the 1986 SIGPLAN symposium on Compiler construction',5),(9916,NULL,'1986',NULL,'Effectiveness of a machine-level, global optimizer','We present an overview of the design of a machine-code-level, global (intraprocedural) optimizer that supports several front-ends producing code for the Hewlett-Packard Precision Architecture family of machines. The basic optimization strategy is described, including information about the division of responsibilities between various components of the compiler. Optimization algorithms are described, including a discussion of the dataflow information they require. Measurements showing the collective and individual effects of various optimizer components are presented.The performance data presented here was collected using a preliminary version of the optimizer. Development is continuing and further improvements are expected.',216668,'SIGPLAN \'86 Proceedings of the 1986 SIGPLAN symposium on Compiler construction',5),(11310,NULL,'1986',NULL,'Group Properties of Cellular Automata and VLSI Applications','The study of one-dimensional cellular automata exhibiting group properties is presented. The results show that only a certain class of cellular automata rules exhibit group characteristics based on rule multiplication. However, many other of these automata reveal groups based on permutations of their global states. It is further shown how these groups may be utilized in the design of modulo arithmetic units. The communication properties of cellular automata are observed to map favorably to optimal communication graphs for VLSI layouts. They exploit the implementation medium and properly address the physical limits on computational structures. Comparisons of cellular automata-based modulo arithmetic units with other VLSI algorithms are presented using area-time complexity measures.',117351,'IEEE Transactions on Computers',2),(11311,NULL,'1986',NULL,'The Load-Sharing Banyan Network','Banyan networks, as well as many other self-routing networks, have a simple and regular topology, and can be easily diagnosed and maintained. However, like many other self- routing networks, Banyan networks have only one path between each input and output pair. Failures of a single link or node will make many paths unavailable, and certain traffic patterns can cause severe congestion in the networks.',117351,'IEEE Transactions on Computers',7),(11312,NULL,'1986',NULL,'Automatic Verification of Sequential Circuits Using Temporal Logic','Verifying the correctness of sequential circuits has been an important problem for a long time. But lack of any formal and efficient method of verification has prevented the creation of practical design aids for this purpose. Since all the known techniques of simulation and prototype testing are time consuming and not very reliable, there is an acute need for such tools. In this paper we describe an automatic verification system for sequential circuits in which specifications are expressed in a propositional temporal logic. In contrast to most other mechanical verification systems, our system does not require any user assistance and is quite fast experimental results show that state machines with several hundred states can be checked for correctness in a matter of seconds!',117351,'IEEE Transactions on Computers',10),(11313,NULL,'1986',NULL,'Analytic Queueing Network Models for Parallel Processing of Task Systems','This paper is concerned with the performance evaluation of a realistic model of parallel computations. We present an efficient algorithm to determine the mean completion time and related performance measures for a task system: a set of tasks with precedence relationships in their execution sequence, such that the resulting graph is acyclic. A queueing network (QN) is used to model tasks executing on a single or multicomputer system. In the case of multicomputer systems, we take into account the delay due to interprocess communication. A straight- forward application of a QN solver to the problem is not possible due to variations in the state of the system (composition of tasks in execution). An accurate algorithm based on hierarchical decomposition is presented for solving task systems. At the higher level, the system behavior is specified by a Markov chain whose states correspond to the combination of tasks in execution. The state transition rate matrix for the Markov chain is triangular (since the task system graph was assumed to be acyclic), therefore it can be solved efficiently to compute the state probabilities and the task initiation/completion times. At the lower level, the transition rates among the states of the Markov chain are computed using a QN solver, which determines the throughput of the computer system for each system state. The model and the solution method can be used in performance evaluation of applications exhibiting concurrency in centralized/distributed systems where there are conflicting goals of load balancing and minimizing interprocess communication overhead.',117351,'IEEE Transactions on Computers',0),(11314,NULL,'1986',NULL,'An Array Layout Methodology for VLSI Circuits','A new methodology for the layout design of several classes of useful VLSI structures is proposed. The approach produces a structured layout for commonly found computation structures, using regular elements called layout slices. Algorithms for optimal array realization are described that offer several significant advantages over existing layout schemes. Any network that can be decomposed into instances of these structures can therefore be realized using layout slices. Algorithms for the array realization of a class of arbitrary networks are also described. Several well-known structures such as trees, carry-save adders and cube-connected cycles can be realized using the proposed array layout methodology, not only with optimal area but also with several features necessary for practical implementation, e.g., access to key nodes, high area utilization and global signal routing. The proposed methodology is illustrated with actual layouts of useful circuits.',117351,'IEEE Transactions on Computers',10),(11315,NULL,'1986',NULL,'Multiple Stuck-Fault Detection and Location in Multivalued Linear Circuits','In this correspondence, we present procedures for constructing universal fault detection test sets as well as fault location test sets for multivalued linear circuits, under a multiple stuck-fault model. The bin packing problem is involved in the procedures. The sizes of the fault detection test set and the fault location test set constructed for an n- variable v-valued linear tree circuit are 1 + ?n/(v - 1)? and 1 + ?n/ ?log2 v? ?, respectively. It has been proved that the sizes listed above are optimal for some cases.',117351,'IEEE Transactions on Computers',11),(11316,NULL,'1986',NULL,'A Special-Function Unit for Sorting and Sort-Based Database Operations','Achieving efficiency in database management functions is a fundamental problem underlying many computer applications. Efficiency is difficult to achieve using the traditional general-purpose von Neumann processors. Recent advances in microelectronic technologies have prompted many new research activities in the design, implementation, and application of database machines which are tailored for processing database management functions. To build an efficient system, the software algorithms designed for this type of system need to be tailored to take advantage of the hardware characteristics of these machines. Furthermore, special hardware units should be used, if they are cost- effective, to execute or to assist the execution of these software algorithms.',117351,'IEEE Transactions on Computers',5),(11317,NULL,'1986',NULL,'Performance Analysis of a Database Filter Search Hardware','Several hardware algorithms to search for a large number of keys in a database are presented. These algorithms allow some false matches but guarantee hits for the desired search keys. This imperfectness allows us to design a variety of simple hardware searchers by using only RAM\'s and shift registers. Analytic models are developed to compare the performances of these hardware devices. Applications of these devices for database systems are also discussed.',117351,'IEEE Transactions on Computers',5),(11318,NULL,'1986',NULL,'On the Diagnosis of System Faults with Propagation','This correspondence proposes a new fault model for system diagnosis, wherein the interaction among faulty subsystems and fault propagation is considered. Criteria for one-step diagnosability are given. Optimal design of diagnosable systems is also developed. As to sequential diagnosis, single-loop systems are studied in depth.',117351,'IEEE Transactions on Computers',6),(11319,NULL,'1986',NULL,'Linear Dependencies in Linear Feedback Shift Registers','Linear feedback shift registers have been proposed to generate test patterns for the self-test of logic networks. The probability of linear dependence among k bit positions of a subset of k bits in a maximum length shift register sequence is an outstanding problem. In this correspondence, we derive a formula for the calculation of the probability.',117351,'IEEE Transactions on Computers',1),(11320,NULL,'1986',NULL,'Spectral Signature Testing of Multiple Stuck-at Faults in Irredundant Combinational Networks','Earlier spectral signature testing methods are extended to the multiple stuck-at fault model. The testability condition for multiple- input faults is established and a minimal spanning signature (MSS) is defined to cover all these faults. It is then shown that an MSS, which in most cases contains a single spectral coefficient, will detect over 99 percent of all input and internal multiple faults. An approach is described to obtain a complete signature for all multiple faults in any irredundant combinational network with comparatively small numbers of fan-outs. Tree networks that include XOR/XNOR gates are shown to be easily tested. Internally fan-out-free and general irredundant networks are also considered. A design approach is proposed to enable a network to be tested for all single and most multiple faults using a single coefficient, with the possible overhead being an extra control input.',117351,'IEEE Transactions on Computers',11),(11321,NULL,'1986',NULL,'Roving Emulation as a Fault Detection Mechanism','In this paper we present a new built-in test methodology for detecting and locating faults in digital systems. The technique is called roving emulation and consists of an off-line snap shot type emulation or simulation of operating components in a system. Its primary application is in testing systems in the field where real-time fault detection is not required. The primary performance measure of this test schema is taken to be the expected value of the error latency, i.e., the time required to detect a fault once it first occurs. The primary results of this paper deal with deriving equations for the error latency. We present both a probabilistic and service-waiting model to analyze the expected error latency in a system tested via roving emulation. The effects of various controllable and uncontrollable system parameters on error latency are studied. Finally, the technique is applied to a system consisting of combinational logic modules, and numerical results are presented.',117351,'IEEE Transactions on Computers',6),(11322,NULL,'1986',NULL,'A Formal Definition of Data Flow Graph Models','In this paper, a new model for parallel computations and parallel computer systems that is based on data flow principles is presented. Uninterpreted data flow graphs can be used to model computer systems including data driven and parallel processors. A data flow graph is defined to be a bipartite graph with actors and links as the two vertex classes. Actors can be considered similar to transitions in Petri nets, and links similar to places. The nondeterministic nature of uninterpreted data flow graphs necessitates the derivation of liveness conditions.',117351,'IEEE Transactions on Computers',2),(11323,NULL,'1986',NULL,'A LOTOS Specification of the PROWAY Highway Service','The Language for temporal ordering specification (LOTOS) is a formal description technique whose development is under way within ISO, the International Organization for standardization, mainly for application to open systems interconnection (OSI) standards. The paper presents a LOTOS specification of the PROWAY interface for process control applicatioins, defined by IEC, the International Electrotechnical Commision. LOTOS is shown to be tailored for the specification of asynchronous systems. In particular, it proves suitable for the specification both of the services which define an interface and of the protocols which implement it. The paper shows how LOTOS supports formal reasoning aimed at establishing consistency between service and protocol specifications. Two examples of such a verification are developed that are related to the PROWAY interface. Finally, advantages and limitations of this approach are outlined.',117351,'IEEE Transactions on Computers',5),(11324,NULL,'1986',NULL,'Multigrid Algorithms on the Hypercube Multiprocessor','This paper examines several ways of implementing multigrid algorithms on the hypercube multiprocessor. We consider both the standard multigrid algorithms and a concurrent version proposed by Gannon and Van Rosendale. We present several mappings of the mesh points onto the nodes of the cube. The main property of these mappings, which are based on binary reflected Gray codes, is that the distance between neighboring grid points remains constant from one grid level to another. This results in a communication effective implementation of multigrid algorithms on the hypercube multiprocessor.',117351,'IEEE Transactions on Computers',7),(11325,NULL,'1986',NULL,'Synchronized Disk Interleaving','A group of disks may be interleaved to speed up data transfers in a manner analogous to the speedup achieved by main memory interleaving. Conventional disks may be used for interleaving by spreading data across disks and by treating multiple disks as if they were a single one. Furthermore, the rotation of the interleaved disks may be synchronized to simplify control and also to optimize performance. In addition, check- sums may be placed on separate check-sum disks in order to improve reliability. In this paper, we study synchronized disk interleaving as a high-performance mass storage system architecture. The advantages and limitations of the proposed disk interleaving scheme are analyzed using the M/G/1 queueing model and compared to the conventional disk access mechanism.',117351,'IEEE Transactions on Computers',4),(11326,NULL,'1986',NULL,'Synthesis of an Optimal Family of Matrix Multiplication Algorithms on Linear Arrays','Synthesis of a family of matrix multiplication algorithms on a linear array is described. All these algorithms are optimal in their area and time requirements. An important feature of the family of algorithms is that they are modularly extensible, that is, larger problem sizes can be handled by cascading smaller arrays consisting of processors having a fixed amount of local storage. These algorithms exhibit a tradeoff between the number of processors required and the local storage within a processor. In particular, as the local storage increases the number of processors required to multiply the two matrices decrease.',117351,'IEEE Transactions on Computers',9),(11327,NULL,'1986',NULL,'Row/Column Replacement for the Control of Hard Defects in Semiconductor RAM\'s','We describe and analyze row/column replacement, the technique currently used to control hard cell defects in semiconductor RAM\'s during manufacture. This strategy is shown to be asymptotically ineffective; it is demonstrated that this ineffectiveness may become a limiting issue for very large memory arrays.',117351,'IEEE Transactions on Computers',10),(11328,NULL,'1986',NULL,'A Parallel Algorithm to Compute the Shortest Paths and Diameter of a Graph and Its VLSI Implementation','In this correspondence we develop a parallel algorithm to compute the all-pairs shortest paths and the diameter of a given graph. Next, this algorithm is mapped into a suitable VLSI systolic architecture and the performance of this proposed VLSI implementation is evaluated.',117351,'IEEE Transactions on Computers',9),(11329,NULL,'1986',NULL,'An Algorithm for Determining the Fault Diagnosability of a System','The fault diagnosability problem is the problem of computing the maximum number of faulty units which a system can tolerate without losing its capability of identifying all such faulty units. We study this problem for the model introduced by Barsi, Grandoni, and Maestrini [2]. We present a new characterization of the model, and develop an efficient diagnosability algorithm for a system in this model.',117351,'IEEE Transactions on Computers',6),(11330,NULL,'1986',NULL,'Techniques for Computing the Discrete Fourier Transform Using the Quadratic Residue Fermat Number Systems','In this correspondence, the complex integer multiplier and adder over the direct sum of two copies of finite field developed in [1] is specialized to the direct sum of the rings of integers modulo Fermat numbers. Such multiplication over the rings of integers modulo Fermat numbers can be performed by means of two integer multiplications, whereas the complex integer multiplication requires three integer multiplications. Such multiplications and additions can be used in the implementation of a discrete Fourier transform (DFT) of a sequence of complex numbers. The advantage of the present approach is that the number of multiplications needed to compute a systolic array of the DFT can be reduced substantially. The architectural designs using this approach are regular, simple, expandable and, therefore, naturally suitable for VLSI implementation.',117351,'IEEE Transactions on Computers',8),(11592,NULL,'1986',NULL,'A Survey of Multivalued Memories','Techniques of storing multiple bits of information in a single memory location are reviewed. Any of several states can be stored in ROM\'s by adjusting the threshold voltage or the size of a particular memory device. In dynamic RAM\'s, this can be achieved by varying the charge stored on the cell capacitor. The peripheral circuitry required to distinguish between the states stored in the memory areas is discussed.',117351,'IEEE Transactions on Computers',4),(11593,NULL,'1986',NULL,'Uncertainty, Energy, and Multiple-Valued Logics','The multiple-valued logics obtained by introducing uncertainty and energy considerations into classical switching theory are studied in this paper. First, the nature of uncertain or unknown signals is examined, and two general uncertainty types called U-values and P-values are identified. It is shown that multiple-valued logics composed of U/P-values can be systematically derived from 2-valued Boolean algebra. These are useful for timing and hazard analysis, and provide a rigorous framework for designing gate-level logic simulation programs. Next, signals of the form (v, s) are considered where v and s denote logic level and strength, respectively, and the product vs corresponds to energy flow or power. It is shown that these signals form a type of lattice called a pseudo-Boolean algebra. Such algebras characterize the behavior of digital circuits at a level (the switch level) intermediate between the conventional analog and logical levels. They provide the mathematical basis for an efficient new class of switch-level simulation programs used in MOS VLSI design.',117351,'IEEE Transactions on Computers',1),(11594,NULL,'1986',NULL,'Complexity Based on Partitioning of Boolean Circuits and their Relation to Multivalued Circuits','We present a new complexity measure for Boolean functions based on partitions of combinatorial circuits into subcircuits, and give upper and lower bounds on the complexity for Boolean functions. Roughly speaking, for a function g whose range is the set of positive integers, g(n)-partition of a circuit is a partition of a circuit into subcircuits such that. 1) each subcircuit has at most g(n) output gates, through which gates in the subcircuit are connected to gates in another succeeding subcircuits and 2) each subcircuit has at most two preceding subcircuits where subcircuit N1 (N2) is said to precede (succeed) subcircuit N2 (N1) when there is a line directed from a gate in N1 to a gate in N2. Our main result, which is stated in terms of a lower bound theorem and an upper bound theorem, is a precise version of the following statement: For \"almost all\" n-argument Boolean functions fn, the minimum nu mber of subcircuits over g n)-partition of a circuit to compute fn is given as (2n/g(n)22g(n)) unless g(n) grows much more slowly than n as n increases. To prove the theorems, we regard a Boolean circuit, together with g(n)-partition of it, as the multivalued circuit composed of multivalued gates corresponding to the subcircuits obtained from the g(n)-partition.',117351,'IEEE Transactions on Computers',1),(11595,NULL,'1986',NULL,'Synthesis of Multivalued Multithreshold Functions for CCD Implementation','Basic multivalued building blocks constructed using CCD (charge-coupled devices) technology are presented. They are used to realize simple threshold functions. Existing techniques for decomposition of multivalued multithreshold functions into simpler subfunctions are reviewed. Usage of the CCD technology in implementation of these subfunctions is discussed. Two new decomposition techniques are proposed. Their aim is to obtain realizations that are better suited to CCD technology in terms of the maximum number of thresholds per element and the generation of negative weights. Synthesis techniques based on the proposed decompositions are presented and compared. Although 4-valued logic functions are stressed, the techniques are, in principle, applicable to functions of any radix.',117351,'IEEE Transactions on Computers',1),(11596,NULL,'1986',NULL,'Heuristic Minimization of MVL Functions: A Direct Cover Approach','A heuristic method to obtain near-minimal covers of p-valued switching functions is introduced. First, we describe transform tools useful in the processing of MVL functions. They are: p-adic shifting, weighting, and implicant detecting transformations. Based on these tools, a direct cover algorithm is presented that uses local information for heuristic decision making. The heuristics are taken from weight coefficients calculated for canonical terms and implicants. The method allows to assign cost factors to implicants. Further, the algorithms can be modified easily, so as to correspond to various connectives (e.g., MAX, PLUS).',117351,'IEEE Transactions on Computers',1),(11597,NULL,'1986',NULL,'Representation of Uncertainty in Computer Vision Using Fuzzy Sets','Uncertainty in computer vision can arise at various levels. It can occur in the low level in the raw sensor input, and extends all the way through intermediate and higher levels. Ideally, at any level where decisions are being made on the basis of previous processing steps, a computer vision system must have sufficient flexibility for representation of uncertainty in any of these levels.',117351,'IEEE Transactions on Computers',10),(11598,NULL,'1986',NULL,'Characteristics of Prototype CMOS Quaternary Logic Encoder-Decoder Circuits','The use of quaternary logic input and output signals for delivering information on and off chip could reduce the number of required package pins or increase the amount of information conveyed on a fixed number of package pins. In this correspondence, we discuss the performance of prototype CMOS binary-to-quaternary encoder and quaternary-to-binary decoder test circuits that have been realized on a gate array IC chip.',117351,'IEEE Transactions on Computers',10),(11599,NULL,'1986',NULL,'The Current Mode Fuzzy Logic Integrated Circuits Fabricated by the Standard CMOS Process','Nine basic fuzzy logic circuits employing p-ch and n-ch current mirrors are presented, and the fuzzy information processing hardware system design at a low cost with only one kind of master slice (semicustom fuzzy logic IC) is described. The fuzzy logic circuits presented here will be indispensable for a \"fuzzy computer\" in the near future.',117351,'IEEE Transactions on Computers',10),(11600,NULL,'1986',NULL,'Ternary Scan Design for VLSI Testability','In this correspondence, a new scheme is proposed in which ternary clocking signals are used to replace binary clocking signals in VLSI scan-testing designs. This scheme has the same advantage of high testability as the binary scan method [1], but it eliminates the mode- selecting signal line. Since this mode-selecting line must be routed to each flip-flop in the binary scan scheme, the saving is significant in reducing the circuit interconnection complexity and chip area. This correspondence describes the new ternary scheme in detail, and also suggests appropriate circuit designs using CMOS technology. Furthermore, comparisons are made between ternary scan and binary scan [3] and between ternary scan and a scan scheme using binary with a local decoder [2].',117351,'IEEE Transactions on Computers',11),(11601,NULL,'1986',NULL,'On the Diagnosability of a General Model of System with Three-Valued Test Outcomes','The problem of diagnosability of a system with three-valued test outcomes was considered in earlier works [1]-[3]. However all these works assume the system to be modeled as in [4]. In this correspondence, we consider a more general model of the system and study the diagnosability criteria in presence of three-valued test outcomes. In this model, each unit is tested jointly by a number of other units of the system as opposed to each test being carried out by a single unit of the system as in [4]. Necessary and sufficient conditions for the diagnosability of a system under this general model have been presented in this correspondence. Throughout the correspondence, diagnosability without repair has been considered.',117351,'IEEE Transactions on Computers',6),(11602,NULL,'1986',NULL,'Iteration Properties of Multivalued Switching Functions','The purpose of this correspondence is to survey the literature concerning the iterative properties of multivalued switching functions. These properties are important for the synthesis of switching circuits by cascades of simpler elements. Our presentation evolves around the graphs of transformations of finite sets. We discuss such topics as limitations of the computational capabilities of cascades, the existence of roots of given functions with respect to iteration powers, etc.',117351,'IEEE Transactions on Computers',1),(11603,NULL,'1986',NULL,'Regular Ternary Logic Functions Ternary Logic Functions Suitable for Treating Ambiguity','A special group of ternary functions, called regular ternary logic functions, are defined. These functions are useful in switching theory, programming languages, algorithm theory, and many other fields if we are concerned with the indefinite state in such fields. This correspondence describes the fundamental properties and representations of the regular ternary logic functions.',117351,'IEEE Transactions on Computers',1),(11604,NULL,'1986',NULL,'Design of a Multiple-Valued Systolic System for the Computation of the Chrestenson Spectrum','This correspondence deals with the computation of the Chrestenson spectrum of an n-ary, n-place, p-valued function by means of a systolic system. The design of a systolic system in a multiple-valued environment is discussed in details and some aspects are compared to binary realizations.',117351,'IEEE Transactions on Computers',10),(11771,NULL,'1986',NULL,'Random sequence generation by cellular automata','A 1-dimensional cellular automaton which generates random sequences is discussed. Each site in the cellular automaton has value 0 or 1, and is updated in parallel according to the rule a\'\"i = a\"i\" \"-\" \"1 XOR (a\"i OR a\"i\" \"+\" \"1) (a\'\"i = (a\"i\" \"-\" \"1 + a\"i + a\"i\" \"+\" \"1 + a\"ia\"i\" \"+\" \"1) mod 2). Despite the simplicity of this rule, the time sequences of site values that it yields seem to be completely random. These sequences are analysed by a variety of empirical, combinatorial, statistical, dynamical systems theory and computation theory methods. An efficient random sequence generator based on them is suggested.',20279,'Advances in Applied Mathematics',1),(12170,NULL,'1986',NULL,'Fast constructive-solid geometry display in the pixel-powers graphics system','We present two algorithms for the display of CSG-defined objects on Pixel-Powers, an extension of the Pixel-Planes logic-enhanced memory architecture, which calculates for each and every pixel on the screen (in parallel) the value of any quadratic function in the screen coordinates (x,y). The first algorithm restructures any CSG tree into an equivalent, but possibly larger, tree whose display can be achieved by the second algorithm. The second algorithm traverses the restructured tree and generates quadratic coefficients and opcodes for Pixel-Powers. These opcodes instruct Pixel-Powers to generate the boundaries of primitives and perform set operations using the standard Z-buffer algorithm.Several externally-supplied CSG data sets have been processed with the new tree-traversal algorithm and an associated Pixel-Powers simulator. The resulting images indicate that good results can be obtained very rapidly with the new system. For example, the commonly used MBB test part (at right) with 24 primitives is translated into approximately 1900 quadratic equations. On a Pixel-Powers system running at 10MHz (the speed at which our current Pixel-Planes memories run), the image should be rendered in about 7.5 milliseconds.',216222,'SIGGRAPH \'86 Proceedings of the 13th annual conference on Computer graphics and interactive techniques',2),(12176,NULL,'1986',NULL,'Constructive solid geometry for polyhedral objects','Constructive Solid Geometry (CSG) is a powerful way of describing solid objects for computer graphics and modeling. The surfaces of any primitive object (such as a cube, sphere or cylinder) can be approximated by polygons. Being abile to find the union, intersection or difference of these objects allows more interesting and complicated polygonal objects to be created. The algorithm presented here performs these set operations on objects constructed from convex polygons. These objects must bound a finite volume, but need not be convex. An object that results from one of these operations also contains only convex polygons, and bounds a finite volume; thus, it can be used in later combinations, allowing the generation of quite complicated objects. Our algorithm is robust and is presented in enough detail to be implemented.',216222,'SIGGRAPH \'86 Proceedings of the 13th annual conference on Computer graphics and interactive techniques',2),(12261,NULL,'1986',NULL,'Algorithmic State Machine Design and Automatic Theorem Proving: Two Dual Approaches to the Same Activity','This paper shows that synthesizing binary decision programs (formed by means of decision instructions of the type if then else and of execution instructions of the type do) and proving theorems can be carried out by using the same approach. It is proved that the same transformations acting on P-functions can be interpreted in terms of binary program synthesis and of theorem proving. Since binary program leads to algorithmic state machine design while theorem proving leads to declarative programming, this allows us to lay a bridge between logic design and declarative languages such as Prolog.',117351,'IEEE Transactions on Computers',2),(12262,NULL,'1986',NULL,'Built-In Testing of Memory Using an On-Chip Compact Testing Scheme','In this paper we study the problem of testing RAM. A new fault model, which encompasses the existing fault models, is proposed. We then propose a scheme of testing faults from the new fault model using built-in testing techniques. We introduce concept of p-hard and determine the complexity of the extra hardware required for built-in self-testing on our hardness scale. A novel approach using microcoded ROM for implementation of built-in testing is also proposed and its complexity is determined.',117351,'IEEE Transactions on Computers',11),(12263,NULL,'1986',NULL,'Distributed Recovery in Fault-Tolerant Multiprocessor Networks','A methodology for characterizing dynamic distributed recovery in fault-tolerant multiprocessor systems is developed using graph theory. Distributed recovery, which is intended for systems with no central supervisor, depends on the cooperation of a set of processors to execute the recovery function, since each processor is assumed to have only a limited amount of information about the system as a whole. Facility graphs, whose nodes denote the system components (processors), and whose edges denote interconnection between components, are used to represent multiprocessor systems, and error conditions. A general distributed recovery strategy R, which allows global recovery to be achieved via a sequence of local actions, is given. R recovers the system in several steps in which different nodes successively act as the local supervisor. R is specialized for two important classes of systems: loop networks and tree networks. For each of these cases, fault-tolerant designs and their associated distributed recovery strategies, which allow recovery from up to k faults within a specified number of steps, are presented.',117351,'IEEE Transactions on Computers',6),(12264,NULL,'1986',NULL,'Clocking Schemes for High-Speed Digital Systems','A key element (one is tempted to say the heart) of most digital systems is the clock. Its period determines the rate at which data are processed, and so should be made as small as possible, consistent with reliable operation.',117351,'IEEE Transactions on Computers',10),(12265,NULL,'1986',NULL,'A Signed Bit-Sequential Multiplier','Bit-sequential algorithms for arithmetic processing are good candidates for VLSI signal processing circuits because of their canonical structure and minimal interconnection requirements. Several recent papers have dealt with algorithms that accept unsigned binary inputs, one bit at a time, least significant bit first, and produce an unsigned binary product in a bit-serial fashion.',117351,'IEEE Transactions on Computers',8),(12266,NULL,'1986',NULL,'Analysis of Performability for Stochastic Models of Fault-Tolerant Systems','Performability, a composite measure for the performance and reliability, may be interpreted as the probability density function of the aggregate reward obtained from a system during its mission time. For large mission times we show that known limit theorems lead to an asymptotic normal distribution for the aggregate reward. For finite mission times and Markovian models we obtain the expressions for all moments of performability and give recursions to compute coefficients involved in the expressions. We illustrate the use of the results through an example of a multiple processor computer system.',117351,'IEEE Transactions on Computers',0),(12267,NULL,'1986',NULL,'Comments on \"A Massive Memory Machine\"','Garcia-Molina, Lipton, and Valdes [1] introduced a new machine architecture called \"massive memory machines\" (MMM). The primary application of their proposed architecture was for so-called memory bound computations. In this correspondence we argue: 1) that massive memories will likely become feasible, but will be most effective with much more powerful processors, and 2) that a massive memory on the proposed machine will perform poorly in the same cases that virtual memory performs poorly: whenever there is poor locality of memory reference. Other problems with the architecture are also discussed. These related issues include: 1) the infeasibility of large on-chip dual port memory, 2) the support of multiprocessing on an ESP, 3) the possibility of memory prerequest, 4) the potential of trading program size for execution time, and 5) the time required for clearing the entire memory.',117351,'IEEE Transactions on Computers',4),(12268,NULL,'1986',NULL,'Reconfiguration Procedures for a Polymorphic and Partitionable Multiprocessor','This correspondence presents a collection of reconfiguration procedures for a multiprocessor which employs multistage interconnection networks. These procedures are used to dynamically partitipn the multiprocessor into many subsystems, and reconfigure them to form a variety commonly used topologies to match task graphs. By examining the switching capability of the interconnection network, design rules for avoiding connection conflicts are exploited. Then, on the basis of these rules, parallel procedures are designed. With the procedures, a subsystem can be reconfigured in the form of the desired topologies without interfering with other subsystems. In addition, the reconfiguration of a subsystem can be accomplished in constant time, independently of subsystem size.',117351,'IEEE Transactions on Computers',7),(12269,NULL,'1986',NULL,'Dual Systolic Architectures for VLSI Digital Signal Processing Systems','This correspondence presents a linear systolic array for the implementation pf digital signal processing systems based upon matrix- vector multiplication algorithms where the matrix elements can be computed from their row and column indexes. Haar, Walsh, and the discrete Fourier transforms are solved using this approach. The method presented enables the n2 matrix elements to be computed in situ directly from the 2n matrix indexes. Thus, performance comparable to known systolic matrix-vector multipliers is achieved using only constant I/O bandwidth, rather than O(n) bandwidth required in the more general case. A generalized method is given for the development of recursively formed matrices and specifically the VLSI implementation of the Haar and Walsh transforms.',117351,'IEEE Transactions on Computers',8),(12270,NULL,'1986',NULL,'A VLSI Solution to the Vertical Segment Visibility Problem','We present a parallel algorithm to solve the visibility problem among n vertical segments in a plane, which can be implemented on a VLSI chip arranged as a mesh of trees. Our algorithm determines all the pairs of segments that \"see\" each other in time O(log n); while the fastest sequential algorithm requires O(n log n). A lower bound to the area-time complexity of this problem of O(n2 log2 n) is also derived.',117351,'IEEE Transactions on Computers',9),(12271,NULL,'1986',NULL,'Comments on \"Matrix Processors Using p-Adic Arithmetic for Exact Linear Computations\"','The addition and multiplication algorithms of two Hensel codes were presented in two earlier papers [1], [2] on p-adic arithmetic. It is shown here that these algorithms do not always generate a correct result having the same code word length as the two operands and the correct algorithms are given.',117351,'IEEE Transactions on Computers',8),(12272,NULL,'1986',NULL,'Comments on \"Detection of Faults in Programmable Logic Arrays\"','This correspondence shows two counter examples which contradict the Theorems 4 and 5 in [1].',117351,'IEEE Transactions on Computers',11),(12433,NULL,'1986',NULL,'Scheduling Multiprocessor Tasks to Minimize Schedule Length','The problem considered in this paper is the deterministic scheduling of tasks on a set of identical processors. However, the model presented differs from the classical one by the requirement that certain tasks need more than one processor at a time for their processing. This assumption is especially justified in some microprocessor applications and its impact on the complexity of minimizing schedule length is studied. First we concentrate on the problem of nonpreemptive scheduling. In this case, polynomial-time algorithms exist only for unit processing times. We present two such algorithms of complexity O(n) for scheduling tasks requiring an arbitrary number of processors between 1 and k at a time where k is a fixed integer. The case for which k is not fixed is shown to be NP-complete. Next, the problem of preemptive scheduling of tasks of arbitrary length is studied. First an algorithm for scheduling tasks requiring one or k processors is presented. Its complexity depends linearly on the number of tasks. Then, the possibility of a linear programming formulation for the general case is analyzed.',117351,'IEEE Transactions on Computers',0),(12434,NULL,'1986',NULL,'Systematic t-Error Correcting/All Unidirectional Error Detecting Codes','In this paper we give methods for the construction of systematic t-random error correcting and all unidirectional error detecting codes. Also we give the encoding/decoding algorithms and discuss their implementation.',117351,'IEEE Transactions on Computers',8),(12435,NULL,'1986',NULL,'New Classes for Parallel Complexity: A Study of Unification and Other Complete Problems for P','Previous theoretical work in computational complexity has suggested that any problem which is log-space complete for P is not likely in NC, and thus not parallelizable. In practice, this is not the case. To resolve this paradox, we introduce new complexity classes PC and PC* that capture the practical notion of parallelizability we discuss in this paper. We show that foqur complete problems for P (nonsparse versions of unification, path system accessibility, monotone circuit value, and ordered depth-first search) are parallelizable. That is, their running times are O(E + V) on a sequential RAM and O(E/P + V log P) on an EXCLUSIVE-READ EXCLUSIVE-WRITE Parallel RAM with P processors where V and E are the numbers of vertices and edges in the inputed instance of the problem. These problems are in PC and PC*, since an appropriate choice of P can speed up their sequential running times by a factor of µ(P). Several interesting open questions are raised regarding these new parallel complexity classes PC and PC*. Unification is particularly important because it is a basic operation in theorem proving, in type inference algorithms, and in logic programming languages such as Prolog. A fast parallel implementation of Prolog is needed for software development in the Fifth Generation project.',117351,'IEEE Transactions on Computers',2),(12436,NULL,'1986',NULL,'A Clustering Approximation Technique for Queueing Network Models with a Large Number of Chains','The past few years have witnessed an increasing number of large distributed computer system implementations based on local area networks. In these systems a number of resources (CPU\'s, file servers, disks, etc.) are shared among jobs originating at different sites. Evaluating the performance of such large systems typically requires the solution of a queueing network model with a large number of closed chains, which precludes the use of exact solution techniques. Therefore, it is important to develop accurate and cost-effective methods for the approximate analysis of closed queueing networks with many chains. In this paper, we present an approach based on the clustering of chains and service centers. The method is applicable to queueing networks with single server fixed rate, infimite server and multiple server service centers. We present the results obtained when the method is used to solve large queueing network models. Extensive comparison of this method to existing approximation techniques indicates that the approach has better accuracy/cost characteristics.',117351,'IEEE Transactions on Computers',3),(12437,NULL,'1986',NULL,'A Study of Pipelining in Computing Arrays','In this paper, we take a hard look at scheduling considerations in computing arrays. A simple sufficient condition is developed for determining whether a computing array can be pipelined. If the array cannot be pipelined in the form given, the condition also indicates the direction in which to proceed to make it pipelineable. The overall framework and methodology take a good part of the load off the logical architect of the array, and make the translation from the logical to the physical architecture a mechanical process.',117351,'IEEE Transactions on Computers',2),(12438,NULL,'1986',NULL,'Improving the Performance of Buddy Systems','This paper discusses ways of reducing fragmentation ion in buddy systems. Although internal fragmentation may be estimated for any buddy system, external fragmentation cannot be determined theoretically. It is suggested here that mean external fragmentation for any buddy system is directly related to the height of the associated binary tree. Simulation studies with a new buddy system support this conjecture. Attempts at reducing internal fragmentation have, in the past, increased the tree height covering the range of request sizes and given rise to a commensurate increase in external fragmentation. A new buddy system is described which supports a large number of buddy sizes without requiring a large tree height. The new scheme is a modified form of the weighted buddy method, entitled the dual buddy system. It provides the same set of block sizes as the weighted scheme but has the same tree height as the binary buddy system. Simulation results show that mean external fragmentation is within four percent of that of the binary system and much lower than that of the weighted scheme. The new system has better overall storage utilization han others for uniform random request sizes.',117351,'IEEE Transactions on Computers',2),(12439,NULL,'1986',NULL,'On Scheduling Tasks with a Quick Recovery from Failure','Multiprocessors used in life-critical real-time systems must recover quickly from failure. Part of this recovery consists of switching to a new task schedule that ensures that hard deadlines for critical tasks continue to be met. We present a dynamic programming algorithm that ensures that backup, or contingency, schedules can be efficiently embedded within the original, \"primary\" schedule to ensure that hard deadlines continue to be met in the face of up to a given maximum number of processor failures. Several illustrative examples are included.',117351,'IEEE Transactions on Computers',0),(12440,NULL,'1986',NULL,'Fast Search Algorithms for Associative Memories','A new scheme for constructing search algorithms for bit-parallel associative memories of m n-bit words is described. The resulting equivalence searches, threshold searches, and double-limit searches achieve the time bound of O(log n), compared to O(n), the recent result of Ramamoorthy et al. [12]. The extremum search algorithm by Frei and Goldberg [2] is modified and generalized so that the number of memory interrogations is reduced by 30 percent over the initial algorithm in the average case.',117351,'IEEE Transactions on Computers',8),(12441,NULL,'1986',NULL,'Algorithmic Aspects of MOS VLSI Switch-Level Simulation with Race Detection','We present algorithms and time complexity results for MOS switch-level simulation with particular reference to race detection. Under the switching model used in classical (Boolean) switching theory, we derive a linear-time race detection algorithm for switch-level circuits that have no feedback within a clock phase, and have unit fan-out. We show that the problem becomes NP-complete if fan-out of two or more is allowed. We Also relate this result to others that have recently been reported, using a different switching model.',117351,'IEEE Transactions on Computers',1),(12442,NULL,'1986',NULL,'Minimization by the D Algorithm','Programmed logic arrays [1], [2] are common in computer design. A form of this method of design has been used since the beginnings of computers, in telephone relay networks [3]. Optimization of such realizations of functions were begun by Karnaugh [4], Quine [5], McCluskey [6], and Roth [7]. Substantial use was mnade of such programs by Preiss [8] and Perlman [9]. Despite the existence of exact procedures, \"fast,\" \"approximate\" procedures have been widely used. A new approximate procedure, using the D algorithm [1], [10], [11] is introduced here. It gets around a large computation, in complementation, using prior methods. Running programs \"verify\" this expectation.',117351,'IEEE Transactions on Computers',2),(12443,NULL,'1986',NULL,'The Calcualtion of Multiplicative Inverses Over GF(P) Efficiently Where P is a Mersenne Prime','The extended Euclidean algorithm is typically used to calculate multiplicative inverses over finite fields and rings of integers. The algorithm presented here has approximately the same number of average iterations and maximum number of iterations. It is shown, when P is a Mersenne prime, implementation of this algorithm on a processor, designed especially for mod P arithmetic operations, produces a more efficient algorithm with respect to the amount of program statements and number of operations. It is then shown heuristically, when the division and multiplications are performed simultaneously, the Euclidean algorithm has fewer subiterations.',117351,'IEEE Transactions on Computers',8),(12444,NULL,'1986',NULL,'Comments on \"Sign/Logarithm Arithmetic for FFT Implementation\"','This note points out several errors in the paper [1] by E. E. Swartzlander, Jr. et al. Corrected results are presented including detailed reasons and derivations.',117351,'IEEE Transactions on Computers',2),(12628,NULL,'1986',NULL,'On the Height of Multidimensional Height-Balanced Trees','It is shown that the worst case height of a k- dimensional height-balanced tree, k = 2, is the same as that of an AVL-tree, to within an additive factor of 2k - 2.',117351,'IEEE Transactions on Computers',9),(12629,NULL,'1986',NULL,'The VLSI Design of an Error-Trellis Syndrome Decoder for Certain Convolutional Codes','In this paper a recursive algorithm using the error-trellis decoding technique is developed to decode certain convolutional codes (CC\'s). An example, illustrating the VLSI architecture of such a decoder, is given for a dual-k CC. It is demonstrated that such a decoder can be realized readily on a single chip with NMOS technology.',117351,'IEEE Transactions on Computers',8),(12630,NULL,'1986',NULL,'The Architecture of SM3: A Dynamically Partitionable Multicomputer System','The architecture of a multicomputer system with switchable main memory modules (SM3) is presented. This architecture supports the efficient execution of parallel algorithms for nonnumeric processing by 1) allowing the sharing of switchable main memory modules between computers, 2) supporting dynamic partitioning of the system, and 3) employing global control lines to efficiently support interprocessor communication. Data transfer time is reduced to memory switching time by allowing some main memory modules to be switched between processors. Dynamic partitioning gives a common bus system the capability of an MIMD machine while performing global operations. The global control lines establish a quick and efficient high-level protocol in the system. The network is supervised by a control computer which oversees network partitioning and other global functions. The hardware involved is quite simple and the network is easily extensible. A simulation study using discrete event simulation techniques has been carried out and the results of the study are presented. The architecture of this system is compared to those of conventional local area networks and shared-memory systems in order to establish the distinct nature and characteristics of a multicomputer system based on the SM3 concept.',117351,'IEEE Transactions on Computers',5),(12631,NULL,'1986',NULL,'An Aggregation Technique for the Transient Analysis of Stiff Markov Chains','An approximation algorithm for systematically converting a stiff Markov chain into a nonstiff chain with a smaller state space is discussed in this paper. After classifying the set of all states into fast and slow states, the algorithm proceeds by further classifying fast states into fast recurrent subsets and a fast transient subset. A separate analysis of each of these fast subsets is done and each fast recurrent subset is replaced by a single slow state while the fast transient subset is replaced by a probabilistic switch. After this reduction, the remaining small and nonstiff Markov chain is analyzed by a conventional technique.',117351,'IEEE Transactions on Computers',2),(12632,NULL,'1986',NULL,'An Instruction Issuing Approach to Enhancing Performance in Multiple Functional Unit Processors','Processors with multiple functional units, such as CRAY-1, Cyber 205, and FPS 164, have been used for high-end scientific computation tasks. Much effort has been put into increasing the throughput of such systems. One critical consideration in their design is the identification and implementation of a suitable instruction issuing scheme. Existing approaches do not issue enough instructions per machine cycle to fully utilize the functional units and realize the high-performance level achievable with these powerful execution resources.',117351,'IEEE Transactions on Computers',4),(12633,NULL,'1986',NULL,'Comments on \"Direct Implementation of Discrete and Residue-Based Functions Via Optimal Encoding: A Programmable Array Logic Approach\"','An analytic expression for the lower bound on the complexity of residue multiplication is developed. Significant reduction of the required stored logic in a content-addressable memory is noted. Errors in Figs. 5(a), 7, and 8 of the above paper1 are corrected.',117351,'IEEE Transactions on Computers',8),(12634,NULL,'1986',NULL,'Signature Analysis for Multiple-Output Circuits','A scheme of a good signature analysis by a linear feedback shift register (LFSR) is presented. It works for k-output circuits, even if k is greater than the register length. It is built according to rules which are presented in the correspondence, taking into account error models which are introduced. The rules are derived from a property which is formally shown for one kind of LFSR. However, some of them apply to other LFSR schemes too.',117351,'IEEE Transactions on Computers',1),(12635,NULL,'1986',NULL,'Optimal Diagnosable System Design Using Full-Difference Triangles','In the literature on diagnosable multiprocessor systems, regular testing structures which isolate up to t1 faulty processors to within a set of t1 processors have been studied. These structures are called D(n, t0, X) systems and are said to be t1/t1-diagnosable. In this correspondence, the problem of designing regular testing structures which isolate the largest number of faulty processors is shown to be equivalent to determining full-difference triangles. These triangles have been used to design error-correcting convolutional codes and transmission systems without third-order intermodulation interference, and have been studied extensively. Recognizing this relationship allows results from these areas to be applied directly to the design of diagnosable systems. A list of the best-known systems is given.',117351,'IEEE Transactions on Computers',6),(12636,NULL,'1986',NULL,'Optimal Rotation Problems in Channel Routing','In the channel routing problem, a problem arising in the design of layout systems, two rows of terminals which are opposite each other, have to be connected. We study what effect the rotation of one row of terminals has on the cost measures of the routing phase. The cost measures we consider are the density, which is proportional to the width of the channel, the crossing number, which is closely related to the number of crossings between two wires in the channel, and the length of nets, which is related to the wire length needed in the routing. We present algorithms for determining the rotations which minimize each of these cost measures. The algorithms can also be used for solving optimal offset problems.',117351,'IEEE Transactions on Computers',7),(12637,NULL,'1986',NULL,'A Crash Recovery Scheme for a Memory-Resident Database System','Database systems normally have been designed with the assumption that main memory is too small to hold the entire database. With the decreasing cost and increasing performance of semiconductor memories, future database systems may be constructed that keep most or all of the data for the database in main memory. The challenge in the design of these systems is to provide fast transaction processing, to effectively use multiple processors, and to perform a fast restart after a crash. This correspondence presents a method of performing crash recovery for these systems.',117351,'IEEE Transactions on Computers',5),(12638,NULL,'1986',NULL,'An O(20.304n) Algorithm for Solving Maximum Independent Set Problem','A faster algorithm for finding a maximum independent set in a graph is presented. The algorithm is an improved version of the one by Tarjan and Trojanowski [7]. A technique to further accelerate this algorithm is also described.',117351,'IEEE Transactions on Computers',9),(13481,NULL,'1986',NULL,'Implementation and evaluation of a list-processing-oriented data flow machine','The architecture of a data flow machine, called DFM, is developed for parallel list processing. The DFM can maximally exploit parallelism inherent in list processing, due to its ultra-multi-processing mechanism, packet communication-based parallel and pipeline execution mechanism, and lenient cons mechanism. A practical DFM implementation is described. A DFM prototype machine is implemented and DFM performance is evaluated in a simulation on the register transfer level using several benchmark programs. The DFM single processor system is shown to be about five times faster than conventional machines which use the same device technology, while a multi-processor DFM system is shown to achieve a linear speed-up ratio of 0.6 ~ 0.9.',131952,'ISCA \'86 Proceedings of the 13th annual international symposium on Computer architecture',4),(13482,NULL,'1986',NULL,'A new string search hardware architecture for VLSI','This paper presents a new architecture for practical string search hardware design. This architecture is based on the finite state automaton design concept using a character control charge transfer model. The resultant hardware is a set of programmable sequential logic (PSL) circuits, each of which consists of a sequential logic and memory parts. The logic part is an array of logical gates, each of which is controlled by the read-out signal from the memory part, to connect the flip-flops. The memory part stores each variable-length pattern string character on a bit line by bit line basis. Then, several pattern strings in the memory part can be compared with the serial input data string in parallel, even at a non-anchor mode and an approximate matching mode. This new hardware can be easily implemented in an LSI chip, which allows 8192 pattern string storage using 1 Mb RAM cells.',131952,'ISCA \'86 Proceedings of the 13th annual international symposium on Computer architecture',10),(13486,NULL,'1986',NULL,'Graph allocation in static dataflow systems','One of the most important considerations for a dataflow multiprocessor is the algorithm by which the nodes of a program graph are allocated for execution to its processors. In the case of the static type of architecture one must consider pipelining as well as spatial concurrency. This paper uses a graph partitioning scheme to aid in the design of such algorithms and selection of the associated interconnection topology. The scheme first refines the usual dataflow program graph and then partitions it into “trees.” Our study shows that the hypercube interconnection accommodates these trees in a way that allows as to develop an algorithm that places producer nodes (of a dataflow graph) nears their consumers to keep the message path very short. The algorithm achieves concurrency in simultaneous execution of subgraphs that involve parallel operations, e.g., array operations, and subgraphs that are highly iterative or recursive. An analytical model is given to evaluate the performance of the algorithm.',131952,'ISCA \'86 Proceedings of the 13th annual international symposium on Computer architecture',9),(13492,NULL,'1986',NULL,'Performance measurement of paging behavior in multiprogramming systems','This paper presents empirical results on the performance of CD, a compiler directed memory management policy, and the Working Set policy in a multiprogramming system. A description of the multiprogramming model used in the experiments is also presented. The results show that CD outperforms WS in terms of fault rate, space time cost, and throughput characteristics. Moreover, WS is shown to lack controllability. Two anomaly types are reported in this paper, both of which are exhibited by WS but not by CD.',131952,'ISCA \'86 Proceedings of the 13th annual international symposium on Computer architecture',0),(13497,NULL,'1986',NULL,'An efficient routing control for the SIGMA network Σ(4)','When processing vectors on SIMD computers, the interconnection network may become the bottleneck for performances if it lacks an efficient routing control unit. In the pass, many multistage networks have been designed, but general algorithms to control them cannot be used at execution time : they are too time consuming. This has led many manufacturers to use crossbar networks in the design of SIMD computers. In [Se84a],[Se84b], we defined the Sigma network &Sgr;(n) and we gave realistic algorithms to control it for performing families of permutations covering standard needs in vector processing. Here, we expose the design of a very efficient control unit for the Sigma network &Sgr;(4) (16 entries, 16 exits).',131952,'ISCA \'86 Proceedings of the 13th annual international symposium on Computer architecture',3),(13506,NULL,'1986',NULL,'Evaluation of a prototype data flow processor of the SIGMA-1 for scientific computations','A processing element and a structure element of data flow computer SIGMA-1 for scientific computations is now operational. The elements are evaluated for several benchmark programs. For efficient execution of loop constructs, the sticky token mechanism which holds loop invariants is evaluated and exhibits a remarkable effect. From the standpoint that performance of a single processor of a data flow computer must be comparable to that of a Von Neumann computer, comparison of both computers is discussed and improvement of the SIGMA-1 instruction set is proposed.',131952,'ISCA \'86 Proceedings of the 13th annual international symposium on Computer architecture',4),(13507,NULL,'1986',NULL,'Stored data structures on the Manchester dataflow machine','Experience with the Manchester Dataflow Machine has highlighted the importance of efficient handling of stored data structures in a practical parallel machine. It has proved necessary to add a special-purpose structure store to the machine, and this paper describes the role of this structure store and the software which uses it. Some key issues in data structure handling for parallel machines are raised.',131952,'ISCA \'86 Proceedings of the 13th annual international symposium on Computer architecture',5),(13510,NULL,'1986',NULL,'Modular architecture for high performance implementation of FFT algorithm','The paper presents two new versions of the FFT algorithm. Based on these versions a new VLSI oriented architecture for implementing of the FFT algorithm is introduced. It consists of a homogenous structure of processing elements. The structure has a performance equal to 1/tB transforms per second, where tB is the time needed for execution of a single butterfly computation.Besides high performance the architecture is modular and makes it possible to design a system which performs the DFT of any size with constant performance and without any extra circuitry. Moreover, the system can provide a built-in self test.',131952,'ISCA \'86 Proceedings of the 13th annual international symposium on Computer architecture',10),(13518,NULL,'1986',NULL,'Pseudo MIMD array processor—AAP2','A highly integrated array processor (AAP2)-LSI has been developed. After the past 3 years study on the adaptive array processor 1 (AAP1), a challenging improvements on the SIMD\'s restraints are achieved by using the AAP2-LSI. The AAP2 array system makes it possible to carry out wideband modifiable operation (pseudo MIMD). Furthermore, each PE is capable of supporting a large amount of memory. The AAP2 potential for massively, parallel and pipelined processing is discussed in the field of image processing and CAD applications.A highly integrated array processor (AAP2)-LSI has been developed. After the past 3 years study on the adaptive array processor 1 (AAP1), a challenging improvements on the SIMD\'s restraints are achieved by using the AAP2-LSI. The AAP2 array system makes it possible to carry out wideband modifiable operation (pseudo MIMD). Furthermore, each PE is capable of supporting a large amount of memory. The AAP2 potential for massively, parallel and pipelined processing is discussed in the field of image processing and CAD applications.',131952,'ISCA \'86 Proceedings of the 13th annual international symposium on Computer architecture',10),(13529,NULL,'1986',NULL,'Memory access buffering in multiprocessors','In highly-pipelined machines, instructions and data are prefetched and buffered in both the processor and the cache. This is done to reduce the average memory access latency and to take advantage of memory interleaving. Lock-up free caches are designed to avoid processor blocking on a cache miss. Write buffers are often included in a pipelined machine to avoid processor waiting on writes. In a shared memory multiprocessor, there are more advantages in buffering memory requests, since each memory access has to traverse the memory- processor interconnection and has to compete with memory requests issued by different processors. Buffering, however, can cause logical problems in multiprocessors. These problems are aggravated if each processor has a private memory in which shared writable data may be present, such as in a cache-based system or in a system with a distributed global memory. In this paper, we analyze the benefits and problems associated with the buffering of memory requests in shared memory multiprocessors. We show that the logical problem of buffering is directly related to the problem of synchronization. A simple model is presented to evaluate the performance improvement resulting from buffering.',131952,'ISCA \'86 Proceedings of the 13th annual international symposium on Computer architecture',4),(14255,NULL,'1986',NULL,'A resilient distributed protocol for network synchronization','We present a resilient distributed protocol that enables a synchronous algorithm to run on an asynchronous network. The protocol is resilient in the sense that it can continue providing network synchronization in the presence of topological changes in the underlying communication network of a distributed system. These changes are caused by link/node failures and recoveries that occur while running the protocol. In general, the protocol is a useful tool in the design of resilient distributed algorithms as it isolates the algorithm from the characteristics of the communication network.',216035,'SIGCOMM \'86 Proceedings of the ACM SIGCOMM conference on Communications architectures & protocols',3),(14888,NULL,'1985',NULL,'A microprogrammable architecture with quasi time-transparent structured control','The paper is concerned with efficient implementation of evolved modular and structured microprogramming. A microprogrammable architecture is presented that permits designing hierarchical complicated modular microprograms at two distinct levels: the global control and the data processing level. The architecture is based on two cooperating microprogram control units that separately store and perform control and executive microinstructions and microcode modules. The control organization of an implementing computer is presented which assures the quasi time-transparency of modular control in microprograms during the microprogram execution. This is achieved by parallel functioning of constituent control units, that permits preparing in advance addresses of executive modules referenced by control microinstructions. The efficient implementation of control statements of high level languages and microprogramming at the assembler language level for the proposed architecture are also discussed in the paper.',152674,'MICRO 18 Proceedings of the 18th annual workshop on Microprogramming',5),(14900,NULL,'1985',NULL,'Microcode development for microprogrammed processors','The aim of this paper is to develop a top-down design automation tool for digital system design such as microprogrammed processors. The package contains a hardware description language to specify the design, a microcode development module to generate an efficient microprogam for the microprogrammed processor\'s control, and a functional simulator module to verify the validity of the design. The goal of this project is to develop an interactive computer-aided design environment for specification, design and verification of instruction set processors.',152674,'MICRO 18 Proceedings of the 18th annual workshop on Microprogramming',5),(15932,NULL,'1986',NULL,'Cryptanalysts representation of nonlinearly filtered ML-sequences','A running key generator consisting of a maximum-length (ML) linear feedback shift register (LFSR) and some nonlinear feedforward state filter function is investigated. It is shown how a cryptanalyst can find an equivalent system in a ciphertext-only attack. The analysis uses a Walsh orthogonal expansion of the state filter function and its relation to the crosscorrelation function (CCF) between the ML-sequence and the produced running key sequence.',189682,'Proc. of a workshop on the theory and application of cryptographic techniques on Advances in cryptology---EUROCRYPT \'85',1),(15941,NULL,'1986',NULL,'Linear complexity and random sequences','The problem of characterizing the randomness of finite sequences arises in cryptographic applications. The idea of randomness clearly reflects the difficulty of predicting the next digit of a sequence from all the previous ones. The approach taken in this paper is to measure the (linear) unpredictability of a sequence (finite or periodic) by the length of the shortest linear feedback shift register (LFSR) that is able to generate the given sequence. This length is often referred to in the literature as the linear complexity of the sequence. It is shown that the expected linear complexity of a sequence of n independent and uniformly distributed binary random variables is very close to n/2 and, that the variance of the linear complexity is virtually independent of the sequence length, i.e. is virtually a constant! For the practically interesting case of periodically repeating a finite truly random sequence of length 2m or 2m-1, it is shown that the linear complexity is close to the period length.',189682,'Proc. of a workshop on the theory and application of cryptographic techniques on Advances in cryptology---EUROCRYPT \'85',9),(16009,NULL,'1985',NULL,'An optimal class of symmetric key generation systems','It is sometimes required that user pairs in a network share secret information to be used for mutual identification or as a key in a cipher system. If the network is large it becomes impractical or even impossible to store all keys securely at the users. A natural solution then is to supply each user with a relatively small amount of secret data from which he can derive all his keys. A scheme for this purpose will be presented and we call such a scheme a symmetric key generation system (SKGS). However, as all keys will be generated from a small amount of data, dependencies between keys will exist. Therefore by cooperation, users in the system might be able to decrease their uncertainty about keys they should not have access to.The objective of this paper is to present a class of SKGS for which the amount of secret information needed by each user to generate his keys is the least possible while at the same time a certain minimum number of users have to cooperate to resolve the uncertainty of unknown keys.',189702,'Proc. of the EUROCRYPT 84 workshop on Advances in cryptology: theory and application of cryptographic techniques',3),(17844,NULL,'1985',NULL,'One, two, three . . . infinity: lower bounds for parallel computation','In this paper we compare the power of the two most commonly used concurrent-write models of parallel computation, the COMMON PRAM and the PRIORITY PRAM. These models differ in the way they resolve write conflicts. If several processors want to write into the same shared memory cell at the same time, in the COMMON model they have to write the same value. In the PRIORITY model, they may attempt to write different values; the processor with smallest index succeeds.We consider PRAM\'s with n processors, each having arbitrary computational power. We provide the first separation results between these two models in two extreme cases: when the size m of the shared memory is small (m ≤ n&egr;, &egr; In the case of small memory, the PRIORITY model can be faster than the COMMON model by a factor of &THgr;(log n), and this lower bound holds even if the COMMON model is probabilistic. In the case of infinite memory, the gap between the models can be a factor of &OHgr;(log log log n).We develop new proof techniques to obtain these results. The technique used for the second lower bound is strong enough to establish the first tight time bounds for the PRIORITY model, which is the strongest parallel computation model. We show that finding the maximum of n numbers requires &THgr;(log log n) steps, generalizing a result of Valiant for parallel computation trees.',225132,'STOC \'85 Proceedings of the seventeenth annual ACM symposium on Theory of computing',9),(18482,NULL,'1987',NULL,'Clock synchronization of a large multiprocessor system in the presence of malicious faults','Clock synchronization in the presence of malicious faults is one of the main problems associated with the design of a multiprocessor system. Although over the past few years many different algorithms have been proposed for overcoming this problem, they are not suitable for a large real-time multiprocessor system due to their excessive time overhead, asymmetric structure, and/or large number of interconnections. To remedy this problem, we propose a new method in this paper that i) requires little time overhead by using phase-locked clock synchronization, ii) needs a clock network very similar to the processor network, and iii) uses only 20-30 percent of the total number of interconnections required by a fully connected network for almost no loss in the synchronizing capabilities. Both ii) and iii) are made possible by grouping the various clocks in the system into many different clusters and then treating the clusters themselves as single clock units as far as the network is concerned. The method is significant in that regardless of their size multiprocessor systems can be built at an inexpensive cost without sacrificing both the synchronization and fault tolerance capabilities. To show the feasibility of our method, an example hardware implementation is presented. This implementation turns out to be much simpler than the other existing methods and also retains the symmetry and synchronizing capabilities of the network.',117351,'IEEE Transactions on Computers',3),(18483,NULL,'1987',NULL,'Static scheduling of synchronous data flow programs for digital signal processing','Large grain data flow (LGDF) programming is natural and convenient for describing digital signal processing (DSP) systems, but its runtime overhead is costly in real time or cost-sensitive applications. In some situations, designers are not willing to squander computing resources for the sake of programmer convenience. This is particularly true when the target machine is a programmable DSP chip. However, the runtime overhead inherent in most LGDF implementations is not required for most signal processing systems because such systems are mostly synchronous (in the DSP sense). Synchronous data flow (SDF) differs from traditional data flow in that the amount of data produced and consumed by a data flow node is specified a priori for each input and output. This is equivalent to specifying the relative sample rates in signal processing system. This means that the scheduling of SDF nodes need not be done at runtime, but can be done at compile time (statically), so the runtime overhead evaporates. The sample rates can all be different, which is not true of most current data-driven digital signal processing programming methodologies. Synchronous data flow is closely related to computation graphs, a special case of Petri nets. This self-contained paper develops the theory necessary to statically schedule SDF programs on single or multiple processors. A class of static (compile time) scheduling algorithms is proven valid, and specific algorithms are given for scheduling SDF systems onto single or multiple processors.',117351,'IEEE Transactions on Computers',5),(18484,NULL,'1987',NULL,'Elimination the normalization problem in digit on-line arithmetic','In digit on-line arithmetic, operands are introduced a digit at a time. After the first few operand digits have been introduced, the result begins to appear a digit at a time. This feature of digit on-line arithmetic allows a significant amount of overlapping of arithmetic operations. Digit on-line arithmetic can sometimes produce unnormalized results. This can present a problem for the divide and square root algorithms. If the divisor and radicand are highly unnormalized, these algorithms will not produce the correct results. Two advances in overcoming this problem are presented. First, several techniques for producing results that are closer to being normalized are developed. Second, it is shown that normalized results are not necessary for divide and square root to work properly. Combining these results yields algorithms that will always give the correct results.',117351,'IEEE Transactions on Computers',8),(18485,NULL,'1987',NULL,'Exact performance estimates for multiprocessor memory and bus interference','Exact results are given for the processing power in a multibus multiprocessor with constant memory cycle times and geometric interrequest times. Both uniform and nonuniform memory accesses are considered. Such results have not previously been obtained. In order to derive these results we use a method of introducing time into Petri nets, called Generalized Timed Petri Nets (GTPN), that we have developed. We describe the GTPN and how it is applied to the multiprocessor interference question. We reach several new conclusions. A commonly used definition of processing power can lead to substantial underestimation of the true processing power of the system. If the real system has a constant memory access time and any number of buses, then assuming an exponential access time can lead to substantial errors when estimating processing power probability distributions. In multibus systems with only a few buses a critical memory interrequest time exists. Performance close to that with a crossbar is attainable when the interrequest time is larger than the critical value. Obtaining these results illustrates the advantages, for moderate size state spaces, of the GTPN over simulation with respect to both model design and running time.',117351,'IEEE Transactions on Computers',0),(18611,NULL,'1987',NULL,'Dynamic quorum adjustment for partitioned data','A partition occurs when functioning sites in a distributed system are unable to communicate. This paper introduces a new method for managing replicated data objects in the presence of partitions. Each operation provided by a replicated object has a set. of quorums, which are sets of sites whose cooperation suffices to execute the operation. The method permits an object\'s quorums to be adjusted dynamically in response to failures and recoveries. A transaction that is unable to progress using one set of quorums may switch to another, more favorable set, and transactions in different. Partitions may progress using different sets. This method has three novel aspects: (1) it supports a wider range of quorums than earlier proposals, (2) it, scales up effectively to large systems because quorum adjustments do not require global reconfiguration, and (3) it, systematically exploits the semantics of typed objects to support more flexible quorum adjustment.',16320,'ACM Transactions on Database Systems (TODS)',2),(19445,NULL,'1987',NULL,'A Quantitative Comparison of the Performance of Three Discrete Distributed Associative Memory Models','Monte Carlo methods have been used to study the recall accuracy of three discrete distributed associative memory models: a discrete correlation matrix model (DCM), the Bayes discriminant rule model developed by Murakami and Aibara (MA), and a discrete version of the generalized inverse model of Kohonen (DGI). The key (input) and data (output) vectors have nc components restricted to the values - 1 and + 1. The elements of the nc 脳 nc recall matrix may take on any floating point value. Auto-associative (key and data vectors identical) and hetero- associative operation have been examined with both noiseless (perfect) and noisy key vectors. Simulations have been performed over a range of nc from 20 to 100 and of nv, the number of vector pairs stored, from 1 to 50. The recall accuracy, defined as the probability that a component of the output vector is correct, depends strongly on the ratio nv/nc. The DGI model is the only one able to provide perfect hetero-associative recall with perfect input for nv = nc, but is extremely sensitive to input noise. If the probability that a component of the input vector is correct is 0.9 the three models will provide perfect output only if nv is less than about 0.15 nc. For more noisy inputs the MA model provides the highest probability that a component of the output will be correct.',117351,'IEEE Transactions on Computers',2),(19446,NULL,'1987',NULL,'Processor Control Flow Monitoring Using Signatured Instruction Streams','This paper presents an innovative approach, called signatured instruction streams (SIS), to the on-line detection of control flow errors caused by transient and intermittent faults. At compile time an application program is appropriately partitioned into smaller subprograms, and cyclic codes, or signatures, characterizing the control flow of each subprogram are generated and embedded in the object code. At runtime, special built-in hardware regenerates these signatures using runtime information and compares them to the precomputed signatures. A mismatch indicates the detection of an error. A demonstration system, based on the MC68000 processor, has been designed and built. Fault insertion experiments have been performed using the demonstration system. The demonstration system, using 17 percent hardware overhead, is able to detect 98 percent of faults affecting the control flow and 82 percent of all randomly inserted faults.',117351,'IEEE Transactions on Computers',6),(19447,NULL,'1987',NULL,'Derivation of Minimal Sums for Completely Specified Functions','Some new concepts in switching theory are pre sented. One of these is called an \"abridged minterm base.\" We can use an abridged minterm base instead of the minterm expansion in conventional absolute minimization procedures. Since an abridged minterm base almost always has much fewer minterms than are in the minterm expansion, we can derive an abridged minterm base for many functions for which it is impossible to derive the minterm expansion. This paper also introduces the concept of generalized inclusion function Q(f) and its decomposition theorem Q(g)·Q(h) = Q(g V h). The theorem is very useful.',117351,'IEEE Transactions on Computers',1),(19448,NULL,'1987',NULL,'Vector Computer Memory Bank Contention','A number of recent vector supercomputer designs have featured main memories with very large capacities, and presumably even larger memories are planned for future generations. While the memory chips used in these computers can store much larger amounts of data than before, their operation speeds are rather slow when compared to the significantly faster CPU (central processing unit) circuitry in new supercomputer designs. A consequence of this speed disparity between CPU\'s and main memory is that memory access times and memory bank reservation times (as measured in CPU ticks) are sharply increased from previous generations.',117351,'IEEE Transactions on Computers',4),(19449,NULL,'1987',NULL,'Parallel Block Predictor-Corrector Methods for Ode\'s','The problem of achieving parallelism in the solution of the ordinary differential equations is investigated in this paper. The study focuses on an examination of block methods as a practical means for conveniently distributing the computational workload over multiple processors. Both previously suggested and newly proposed predictor-corrector formula pairs are presented and analyzed and a variable stepsize procedure is developed. The performance of two particular members of the block predictor-corrector class is evaluated experimentally using a collection of test problems. A multimicroprocessor system architecture which uses a distributed memory to deal with the interprocessor communications problem is described as a feasible hardware realization of the approach.',117351,'IEEE Transactions on Computers',2),(19450,NULL,'1987',NULL,'Heuristic Algorithms for Single Row Routing','A heuristic algorithm, based on the criterion of having nets with larger cut numbers assigned to inner tracks and nets with smaller cut numbers assigned to outer tracks, for single row routing problem has recently been proposed by Tarng et al. It has been reported that this algorithm has always been able to produce the optimal solutions for all the examples tested so far. In this paper, we have proved that algorithms based on the heuristic criterion of cut numbers produce optimal solutions for instances in which all nets cover at least one common node (i.e., form a single group). However, the algorithm proposed by Tarng et al. may not produce optimal solutions for instances of multiple net groups. Thus, several possible heuristic algorithms based on the same criterion, but also taking into consideration the net grouping situation have been proposed. The experimental results show that the proposed algorithms are faster and often generate better results than the one proposed by Tarng et al. A tighter lower bound on the number of tracks required is also obtained in this paper.',117351,'IEEE Transactions on Computers',9),(19451,NULL,'1987',NULL,'Rectilinear Shortest Paths and Minimum Spanning Trees in the Presence of Rectilinear Obstacles','We study the rectilinear shortest paths and minimum spanning tree (MST) problems for a set of points in the plane in the presence of rectilinear obstacles. We use the track graph, a suitably defined grid-like structure, to obtain efficient solutions for both problems. The track graph consists of rectilinear tracks defined by the obstacles and the points for which shortest paths and a minimum spanning tree are sought. We use a growth process like Dijkstra\'s on the track graph to find shortest paths from any point in the set to all other points (the one-to-all shortest paths problem). For the one-to-all shortest paths problem for n points we derive an O(n min {log n, log e} + (e + k) log t) time algorithm, where e is the total number of edges of all obstacles, t is the number of extreme edges of all obstacles, and k is the number of intersections among obstacle tracks (all bounds are for the worst case). The MST for the points is constructed also in time O(n log n + (e + k) log t) by a hybrid method of searching for shortest paths while simultaneously constructing an MST. An interesting application of the MST algorithm is the approximation of Steiner trees in graphs.',117351,'IEEE Transactions on Computers',9),(19452,NULL,'1987',NULL,'Pseudorandom Testing','Algorithmic test generation for high fault coverage is an expensive and time-consuming process. As an alternative, circuits can be tested by applying pseudorandom patterns generated by a linear feedback shift register (LFSR). Although no fault simulation is needed, analysis of pseudorandom testing requires the circuit detectability profile.',117351,'IEEE Transactions on Computers',11),(19453,NULL,'1987',NULL,'Modeling the Effect of Redundancy on Yield and Performance of VLSI Systems','The incorporation of different forms of redundancy has been recently proposed for various VLSI and WSI designs. These include regular architectures, built by interconnecting a large number of a few types of system elements on a single chip or wafer. The motivation for introducing fault-tolerance (redundancy) into these architectures is two-fold: yield enhancement and performance (like computational availability) improvement.',117351,'IEEE Transactions on Computers',10),(19454,NULL,'1987',NULL,'Generating Essential Primes for a Boolean Function with Multiple-Valued Inputs','Detecting essential primes is important in multiple-valued logic minimization. In this correspondence, we present a fast algorithm that can generate all essential primes without generating a prime cover of the Boolean function. A new consensus operation called asymmetric consensus (acons) is defined. In terms of acons, we prove a necessary and sufficient condition for detecting essential primes for a Boolean function with multiple-valued inputs. The detection of essential primes can be performed by using a tautology checking algorithm. We exploit the unateness of a Boolean function to speed up tautology checking. The notion of unateness considered is more general than that has appeared in the literature.',117351,'IEEE Transactions on Computers',1),(19455,NULL,'1987',NULL,'A Probabilistic Pipeline Algorithm for K Selection on the Tree Machine','We consider the problem of selecting the kth largest of n inputs, where initially the inputs are stored in the n leaf processors of the 2n - 1 processor tree machine. A probabilistic algorithm is presented that implements a type of pipelining to solve the problem in a simple data driven fashion, with each processor maintaining just a constant amount of state information. On any problem instance, t',117351,'IEEE Transactions on Computers',9),(19457,NULL,'1987',NULL,'Evaluation of On-Chip Static Interconnection Networks','This correspondence evaluates three types of static interconnection networks for VLSI implementation. The criteria of evaluation have been selected from three orthogonal aspects-physical (chip area and dissipation), computational speed (message delay and message density) and cost (chip yield, operational reliability and layout cost). The main feature of this paper is to augment the selection criteria for the interconnection networks from the classical AT2 metric and to provide results pertaining to realistic VLSI implementation.',117351,'IEEE Transactions on Computers',10),(19458,NULL,'1987',NULL,'A New Built-In Self-Test Design for PLA\'s with Hligh Fault Coverage and Low Overhead','This correspondence presents a new built-in self-test design for PLA\'s, that has a lower area overhead and higher multiple fault coverage (of three types of faults: crosspoint, stuck, and bridging) than any existing design. This new design uses function independent test input patterns (which are generated on chip), compresses the output responses into a function independent string of parity bits (whose fault-free expected values are generated on-line with a simple circuit), and detects all siqgle faults and more than ( 1 --2(m+2n) of all multiple faults where m and n represent the number of product terms and input variables, respectively.',117351,'IEEE Transactions on Computers',11),(19459,NULL,'1987',NULL,'The Comparison Approach to Multiprocessor Fault Diagnosis','In this correspondence a system-level, comparison-based strategy for identifying faulty processors in a multiprocessor system is described. Unlike other strategies which have been proposed in the literature, the comparison approach is more efficient and relies on more realistic assumptions about the system under consideration. The new strategy is shown to correctly identify the set of faulty processors with a remarkably high probability, making it an attractive and viable addition or alternative to present fault diagnosis techniques.',117351,'IEEE Transactions on Computers',6),(19460,NULL,'1987',NULL,'A New Measure for Hybrid Fault Diagnosability','Using the PMC model of a multiprocessor system, a new, general quality of hybrid fitult (combinations of hard anid soft failing units) diagnosability is characterized which encompasses previously known results as well as provides a major extension. This new diagnosability, called t/ts/t-diagnosability, serves as a measure of the extent to which collections of test results, called syndromes, contain information relative to faulty unit identification for various testing assignments. By analyzing a system\'s test assignment over tahges of the parameter values t, ts, and t, the spectrum of diagnosis quality achievable in that system can be established. Fundamental interrelationships among these parameters are developed. Optimal designs of t/ts/t-diagnosable systems are presented. The main result of this correspondence can be viewed as a master fault diagnosability characterization which from the perspective of usefulness of the syndrome space for correct diagnosis both unifies and expands the domain of hybrid fault diagnosabilities.',117351,'IEEE Transactions on Computers',6),(19461,NULL,'1987',NULL,'Comments on \"Reliable Loop Topologies for Large Local Computer Networks\"','We comment on the paper by Raghavendra, Gerla, and Avizienis recently published in this TRANSACTIONS [3]. We point out a different routing strategy leading to a skip distance with diameter roughly v3N as compared to the diameter 2vN from the \"optimal\" skip distance obtained in that paper.',117351,'IEEE Transactions on Computers',7),(19616,NULL,'1986',NULL,'Transforming FORTRAN DO loops to improve performance on vector architectures','The performance of programs executing on vector computers is significantly improved when the number of accesses to memory can be reduced. Unrolling Fortran DO loops, followed by substitutions and eliminations in the unrolled code, can reduce the number of loads and stores. In this paper we characterize the unrolling transformation and associated transformations of Fortran DO loops and describe a set of software tools to carry out these transformations. The tools use the machinery available in Toolpack and have been integrated into that environment. We describe the results of applying these tools to a collection of linear algebra subroutines.',16407,'ACM Transactions on Mathematical Software (TOMS)',4),(19617,NULL,'1987',NULL,'Intersection of convex objects in two and three dimensions','One of the basic geometric operations involves determining whether a pair of convex objects intersect. This problem is well understood in a model of computation in which the objects are given as input and their intersection is returned as output. For many applications, however, it may be assumed that the objects already exist within the computer and that the only output desired is a single piece of data giving a common point if the objects intersect or reporting no intersection if they are disjoint. For this problem, none of the previous lower bounds are valid and algorithms are proposed requiring sublinear time for their solution in two and three dimensions.',135870,'Journal of the ACM (JACM)',2),(19645,NULL,'1987',NULL,'High-performance operating system primitives for robotics and real-time control systems','To increase speed and reliability of operation, multiple computers are replacing uniprocessors and wired-logic controllers in modern robots and industrial control systems. However, performance increases are not attained by such hardware alone. The operating software controlling the robots or control systems must exploit the possible parallelism of various control tasks in order to perform the necessary computations within given real-time and reliability constraints. Such software consists of both control programs written by application programmers and operating system software offering means of task scheduling, intertask communication, and device control.The Generalized Executive for real-time Multiprocessor applications (GEM) is an operating system that addresses several requirements of operating software. First, when using GEM, programmers can select one of two different types of tasks differing in size, called processes and microprocesses. Second, the scheduling calls offered by GEM permit the implementation of several models of task interaction. Third, GEM supports multiple models of communication with a parameterized communication mechanism. Fourth, GEM is closely coupled to prototype real-time programming environments that provide programming support for the models of computation offered by the operating system. GEM is being used on a multiprocessor with robotics application software of substantial size and complexity.',16295,'ACM Transactions on Computer Systems (TOCS)',5),(19788,NULL,'1987',NULL,'Integral-C—a practical environment for C programming','Integral C1 is an industrial grade integrated programming environment for C programming on an engineering workstation. A single interactive tool replaces a syntax checking editor, a compiler, and a source-level debugger. Its multi-window user interface allows program editing and animated source level debugging, tailored to the needs of a C programmer. The compiler accepts standard C code and reacts to editing changes with function-level incremental compilation. Compilation is done without prompting to maintain the client program in a ready-to-run state. Emitted code is instrumented to catch run-time errors and to permit fine grained debugging. Debugging support code is written in C in a \'workspace\', which grants it direct access to a local scope while keeping it separate from the client program.',212030,'SDE 2 Proceedings of the second ACM SIGSOFT/SIGPLAN software engineering symposium on Practical software development environments',5),(20372,NULL,'1987',NULL,'Design of a high-speed square root multiply and divide unit','In this paper radix-4 algorithms for square root and division are developed. The division algorithm evaluates the more useful function xz/y. These algorithms are shown to be suitable for implementing as a unified hardware unit which evaluates square root, division, and multiplication. Cost reductions in the hardware are obtained by use of gate arrays. A design based on the Motorola MCA2500 series of Macrocell gate array (MCA) is presented. At a cost of 9 MCA\'s and 16 commercial ECL 100 K parts a 64-bit square root can be evaluated in 750 us using worst case delays. Division takes 710 ns and multiplication 325 ns. Redundancy in the digit set together with carry-save adders are used to achieve this high performance.',117351,'IEEE Transactions on Computers',8),(20373,NULL,'1987',NULL,'Fault-tolerant decoders for cyclic error-correcting codes','High-speed cyclic code decoders, which are central to modern communication systems, when implemented in dense very large scale integration (VLSI), are susceptible to pernicious momentary internal soft fails presenting a demanding error-control challenge. However, special structures inherent in such decoders offer new methods for incorporating distributed error control throughout their designs. The underlying design principles and motivations are emphasized providing a variety of options to meet various requirements. Bose-Chaudhuri-Hocquenghem (BCH) codes are used to exemplify the new techniques as applied to the usual three standard subsystems present in a decoder. The first and last parts, syndrome calculations and transform inversion, both involve finite field transforms suggesting the effective application of fast transform algorithms. Error control features are based upon the chord properties of the transform coefficients including even fast algorithms. The third subsystem, the Berlekamp-Massey algorithm, can be protected through a chord recursion property affiliated with the error location connection polynomial. The propagation and spread of internal errors are studied and a special sink register compares several quantities, available in close proximity, to their easily recomputed counterparts. Most of these results are applicable to generalized to decoders for codes over higher ordered alphabets such as Reed-Solomon codes.',117351,'IEEE Transactions on Computers',2),(20374,NULL,'1987',NULL,'Parallel parsing on a one-way array of finite-state machines','We show that a one-way two-dimensional iterative array of finite-state machines (2-DIA) can recognize and parse strings of any context-free language in linear time. What makes this result interesting and rather surprising is the fact that each processor of the array holds only a fixed amount of information (independent of the size of the input) and communicates with its neighbors in only one direction. This makes for a simple VLSI implementation. Although it is known that recognition can be done on a 2-DIA, previous parsing algorithms require the processors to have unbounded memory, even when the communication is two-way. We also consider the problem of finding approximate patterns in strings, the string-to-string correction problem, and the longest common subsequence problem, and show that they can be solved in linear time on a 2-DIA.',117351,'IEEE Transactions on Computers',9),(20375,NULL,'1987',NULL,'A self-checking generalized prediction checker and its use for built-in testing','This paper presents a new design for a 驴self-checking checker for nonencoded multiinput combinational circuits. A built-in testing method is also stressed. The proposed checker, called a generalized prediction checker (GPC), has an extended and generalized form of conventional parity prediction checkers, and includes a duplication checker as a special case. A parity check matrix H imparts arbitrary error detection ability to the new GPC. The GPC is made perfectly self-testing by applying a new method that adds one extra input to the cascaded multiinput comparator and to the cascaded XOR tree circuit in the GPC. This extra input may take any value during normal operation. The 驴self-checking GPC is implemented for specific circuit examples and verified. For these examples, the 驴self-checking GPC\'s show 100 percent fault coverage for single stuck faults in both the circuit under check and the checker itself. Using this checker, the built-in testing method taking advantage of the checker\'s automatic fault detection ability is shown to be suitable for testing combinational circuits.',117351,'IEEE Transactions on Computers',11),(20376,NULL,'1987',NULL,'A unified view of test compression methods','A unified treatment of the various techniques to reduce the output data from a unit under test is given. The characteristics of time compression schemes with respect to errors detected are developed. The use of two or more of these methods together is considered. Methods to design efficient test compression structures for built-in-tests are proposed. The feasibility of the proposed approach is demonstrated by simulation results.',117351,'IEEE Transactions on Computers',11),(21834,NULL,'1987',NULL,'Guest Editors\' Introduction the Federal Aviation Administration\'s Advanced Automation Program','First Page of the Article',56375,'Computer - The FAA\'s Advanced Automation Program',5),(21836,NULL,'1987',NULL,'Evaluating Proposed Architectures for the FAA\'s Advanced Automation System','First Page of the Article',56375,'Computer - The FAA\'s Advanced Automation Program',5),(21840,NULL,'1987',NULL,'On the Achievement of a Highly Dependable and Fault-Tolerant Air Traffic Control System','First Page of the Article',56375,'Computer - The FAA\'s Advanced Automation Program',3),(23615,NULL,'1987',NULL,'A new approach to all pairs shortest paths in planar graphs','An algorithm is presented for generating a succinct encoding of all pairs shortest path information in a directed planar graph G with real-valued edge costs but no negative cycles. The algorithm runs in &Ogr;(pn) time, where n is the number of vertices in G, and p is the minimum cardinality of a subset of the faces that cover all vertices, taken over all planar embeddings of G. Linear-time algorithms are presented for various subproblems including that of finding an appropriate embedding of G and a corresponding face-on-vertex covering of cardinality &Ogr;(p), and of generating all pairs shortest path information in a directed outerplanar graph.',225134,'STOC \'87 Proceedings of the nineteenth annual ACM symposium on Theory of computing',9),(23637,NULL,'1987',NULL,'How to play ANY mental game','We present a polynomial-time algorithm that, given as a input the description of a game with incomplete information and any number of players, produces a protocol for playing the game that leaks no partial information, provided the majority of the players is honest.Our algorithm automatically solves all the multi-party protocol problems addressed in complexity-based cryptography during the last 10 years. It actually is a completeness theorem for the class of distributed protocols with honest majority. Such completeness theorem is optimal in the sense that, if the majority of the players is not honest, some protocol problems have no efficient solution [C].',225134,'STOC \'87 Proceedings of the nineteenth annual ACM symposium on Theory of computing',2),(23638,NULL,'1987',NULL,'Optimal distributed algorithms for minimum weight spanning tree, counting, leader election, and related problems','This paper develops linear time distributed algorithms for a class of problems in an asynchronous communication network. Those problems include Minimum-Weight Spanning Tree (MST), Leader Election, counting the number of network nodes, and computing a sensitive decomposable function (e.g. majority, parity, maximum, OR, AND).The main problem considered is the problem of finding the MST. This problem, which has been known for at least 9 years, is one of the most fundamental and the most studied problems in the field of distributed network algorithms.Any algorithm for any one of the problems above requires at least &OHgr;(E + VlogV) communication and &OHgr;(V) time in the general network. In this paper, we present new algorithms, which achieve those lower bounds. The best previous algorithm requires &THgr;(E + VlogV) in communication and &THgr;(V log V) in time.Our result enables to improve algorithms for many other problems in distributed computing, achieving lower bounds on their communication and time complexities.',225134,'STOC \'87 Proceedings of the nineteenth annual ACM symposium on Theory of computing',9),(23645,NULL,'1987',NULL,'A model for hierarchical memory','In this paper we introduce the Hierarchical Memory Model (HMM) of computation. It is intended to model computers with multiple levels in the memory hierarchy. Access to memory location x is assumed to take time ⌈ log x ⌉. Tight lower and upper bounds are given in this model for the time complexity of searching, sorting, matrix multiplication and FFT. Efficient algorithms in this model utilize locality of reference by bringing data into fast memory and using them several times before returning them to slower memory. It is shown that the circuit simulation problem has inherently poor locality of reference. The results are extended to HMM\'s where memory access time is given by an arbitrary (nondecreasing) function. Tight upper and lower bounds are obtained for HMM\'s with polynomial memory access time; the algorithms for searching, FFT and matrix multiplication are shown to be optimal for arbitrary memory access time. On-line memory management algorithms for the HMM model are also considered. An algorithm that uses LRU policy at the successive “levels” of the memory hierarchy is shown to be optimal.',225134,'STOC \'87 Proceedings of the nineteenth annual ACM symposium on Theory of computing',9),(23649,NULL,'1987',NULL,'Fast parallel algorithms for chordal graphs','We present an NC algorithm for recognizing chordal graphs, and we present NC algorithms for finding the following objects on chordal graphs: all maximal cliques, an intersection graph representation, an optimal coloring, a perfect elimination scheme, a maximum independent set, a minimum clique cover, and the chromatic polynomial. The well known polynomial algorithms for these problems seem highly sequential, and therefore a different approach is needed to find parallel algorithms.',225134,'STOC \'87 Proceedings of the nineteenth annual ACM symposium on Theory of computing',9),(23911,NULL,'1986',NULL,'An introduction to Trellis/Owl','Trellis/Owl is an object-based language incorporating a type hierarchy with multiple inheritance and compile-time type checking. The combination of features in the language facilitates the design, implementation, and evolution of large computer programs. This paper provides an brief introduction to the Trellis/Owl language. It discusses the basic elements of the language, objects, and shows how these are specified and implemented using types, operations, and components. The notion of a type hierarchy is introduced by a discussion of subtyping and inheritance. Other elements of the Trellis/Owl language such as type generators, iterators, and exceptions are briefly presented.',173972,'OOPLSA \'86 Conference proceedings on Object-oriented programming systems, languages and applications',5),(23919,NULL,'1986',NULL,'Virtual memory on a narrow machine for an object-oriented language','LOOM (Large Object-Oriented Memory) is a virtual memory implemented in software that supports the Smalltalk-80(™) programming language and environment on the Xerox Dorado computer. LOOM provides 8 billion bytes of secondary memory address space and is specifically designed to run on computers with a narrow word size (16-bit wide words). All storage is viewed as objects that contain fields. Objects may have an average size as small as 10 fields. LOOM swaps objects between primary and secondary memory, and addresses each of the two memories with a different sized object pointer. When objects are cached in primary memory, they are known only by their short pointers. On a narrow word size machine, the narrow object pointers in primary memory allow a program such as the Smalltalk-80 interpreter to enjoy a substantial speed advantage. Interesting design problems and solutions arise from the mapping between the two address spaces and the temporary nature of an object\'s short address. The paper explains why the unusual design choices in LOOM were made, and provides an interesting example of the process of designing an integrated virtual memory and storage management system.',173972,'OOPLSA \'86 Conference proceedings on Object-oriented programming systems, languages and applications',4),(23920,NULL,'1986',NULL,'SOAR: Smalltalk without bytecodes','We have implemented Smalltalk-80 on an instruction-level simulator for a RISC microcomputer called SOAR. Measurements suggest that even a conventional computer can provide high performance for Smalltalk-80 by abandoning the \'Smalltalk Virtual Machine\' in favor of compiling Smalltalk directly to SOAR machine code, linearizing the activation records on the machine stack, eliminating the object table, and replacing reference counting with a new technique called Generation Scavenging. In order to implement these techniques, we had to find new ways of hashing objects, accessing often-used objects, invoking blocks, referencing activation records, managing activation record stacks, and converting the virtual machine images.',173972,'OOPLSA \'86 Conference proceedings on Object-oriented programming systems, languages and applications',4),(23942,NULL,'1986',NULL,'The design and implementation of Concurrent Smalltalk','ConcurrentSmalltalk is a programming language/system which incorporates the facilities of concurrent programming in Smalltalk-801. Such facilities are realized by providing concurrent constructs and atomic objects. This paper first gives an outline of ConcurrentSmalltalk. Then, the design of ConcurrentSmalltalk is described. The implementation of ConcurrentSmalltalk is presented in detail.',173972,'OOPLSA \'86 Conference proceedings on Object-oriented programming systems, languages and applications',5),(23955,NULL,'1986',NULL,'Design of a distributed object manager for the Smalltalk-80 system','This paper describes the design of a distributed object manager which allows several Smalltalk-80 systems to share objects over a local-area network. This object manager is based on the following principles: location transparency and uniform object naming, unique object representation and use of symbolic links for remote access, possibility of object migration and distributed garbage collection. A version of the object manager has been implemented and is currently being integrated on a two nodes configuration.',173972,'OOPLSA \'86 Conference proceedings on Object-oriented programming systems, languages and applications',5),(24416,NULL,'1987',NULL,'Efficient embeddings of binary trees in VLSI arrays','We consider the problem of embedding a complete binary tree in squareor hexagonally-connected VLSI arrays Of processing elements (PE\'s). This problem can be solved in a radically different manner from current layout techniques which are aimed at laying out a given graph in the plane. The difference is due to the fact that a PE can be used both as a tree node and as a connecting element between distant nodes. New embedding schemes are presented in which (asymptotically) 100 percent of the PE\'s are utilized as tree nodes. This is a significant savings over known schemes, which achieve 50 percent utilization (the well-known H-tree) and 71 percent for some hexagonal schemes. These schemes also speed up signal propagation from the root to the leaves.',117351,'IEEE Transactions on Computers',7),(24417,NULL,'1987',NULL,'The effect of operation scheduling on the performance of a data flow computer','The effect of incorporating a priority scheme into a data flow computer is studied in this paper. Specifically, we deal with the scheduling of instructions in a data flow program, and the mechanisms by which such scheduling may be implemented within a data flow computer. We show that the assignment of priorities to data flow operations is a special case of a problem in scheduling theory, and also belongs to the NP-complete class of problems. Therefore, we develop a heuristic approach, based on the well-known Critical Path algorithm, as a basis for determining instruction priorities. Our conclusions, based on the simulation of programs executed in a modified data flow computer, show that adding a priority mechanism is not justifiable in the general case. This is due mostly to the inability to reach the potential improvement offered by scheduling operations, because of implementation restrictions. Nevertheless, certain algorithms (e. g., DFT) can still benefit from the proposed scheme, mainly because of their highly regular, static structure.',117351,'IEEE Transactions on Computers',0),(24418,NULL,'1987',NULL,'Processor tradeoffs in distributed real-time systems','Optimizing the design of real-time distributed systems is important since the systems are frequently critical to life. This optimization is a difficult problem, and heuristics and designer judgment are called for in the process. The chief cause of the difficulty is the large number of parameters under the designer\'s control which impact performance and life-cycle cost. We study the interplay between the more important parameters in this paper using two objective measures, i. e., the mean cost and the probability of dynamic failure in [6], [10]. Among these are the processor burn-in time and processor replacement policy. A central feature of this work is a look at how the application requirements affect the optimality of the distributed systems; indeed, the application requirements are an integral part of the analysis.',117351,'IEEE Transactions on Computers',0),(24419,NULL,'1987',NULL,'Performance models of timestamp-ordering concurrency control algorithms in distributed databases','A distributed database (DDB) consists of copies of data files (usually redundant) geographically distributed and managed on a computer network. One important problem in DDB research is that of concurrency control. This paper develops a performance model of timestamp-ordering concurrency control algorithms in a DDB. The performance model consists of five components: input data collection, transaction processing model, communication subnetwork model, conflict model, and performance measures estimation. In this paper we describe the conflict model in detail. We first determine the probability of transaction restarts, the probability of transaction blocking, and the delay due to blocking for the basic timestamp-ordering algorithm. We then develop conflict models for variations of the basic algorithm. These conflict models are illustrated by numerical examples.',117351,'IEEE Transactions on Computers',3),(24420,NULL,'1987',NULL,'On switching policies for modular redundancy fault-tolerant computing systems','The objective of fault-tolerant computing systems is to provide an error-free operation in the presence of faults. The system has to recover from the effects of a fault by employing certain recovery procedures like program rollback, reload, and restart, etc. However, these recovery procedures, result in interruptions in the system\'s operation, thus reducing the availability of the system for user applications. Fault-tolerant systems for critical applications include, therefore, standby spares that are ready to replace active modules which fail to recover from the effects of a fault. A standby spare may also be used to replace a module suffering from frequent fault occurrences resulting in too many repetitions of the recovery process, in order to increase the availability of the system for user applications. In this case a module switching policy is needed indicating upon a fault occurrence, whether to retry a failing module or switch it out and replace it by a spare, considering the remaining mission time and the probability of a system crash. A module switching policy for dynamic redundancy systems is presented in this paper and the improvement in application-oriented availability due to the use of this policy is illustrated.',117351,'IEEE Transactions on Computers',6),(24421,NULL,'1987',NULL,'Line (block) size choice for CPU cache memories','The line (block) size of a cache memory is one of the parameters that most strongly affects cache performance. In this paper, we study the factors that relate to the selection of a cache line size. Our primary focus is on the cache miss ratio, but we also consider influences such as logic complexity, address tags, line crossers, I/O overruns, etc. The behavior of the cache miss ratio as a function of line size is examined carefully through the use of trace driven simulation, using 27 traces from five different machine architectures. The change in cache miss ratio as the line size varies is found to be relatively stable across workloads, and tables of this function are presented for instruction caches, data caches, and unified caches. An empirical mathematical fit is obtained. This function is used to extend previously published design target miss ratios to cover line sizes from 4 to 128 bytes and cache sizes from 32 bytes to 32K bytes; design target miss ratios are to be used to guide new machine designs. Mean delays per memory reference and memory (bus) traffic rates are computed as a function of line and cache size, and memory access time parameters. We find that for high performance microprocessor designs, line sizes in the range 16-64 bytes seem best; shorter line sizes yield high delays due to memory latency, although they reduce memory traffic somewhat. Longer line sizes are suitable for mainframes because of the higher bandwidth to main memory.',117351,'IEEE Transactions on Computers',4),(24422,NULL,'1987',NULL,'New methods for realizing plural near-native performance virtual machines','This paper presents methods for increasing the efficiency of operating systems in plural virtual machines to a near-native performance level. The proposed direct execution methods support direct I/O execution for plural virtual machines, that is, the V = R virtual machine, and the V = Resi virtual machines, including both I/O instruction issuances and I/O interrupts. All V = Resi virtual machines have an entirely resident memory and their real addresses are translated into those of the host simply by adding a constant, 驴(驴 0), which constitutes a starting address given to each V = Resi virtual machine. The V = R virtual machine has almost the same memory attribute as the V = Resi VM except for 驴 = 0. Only one V = R virtual machine can be present in all virtual machines. The experimental results obtained confirm that a near-native performance level, that is, a level exceeding 90 percent of native performance, can be realized for the V = R virtual machine as well as for the V = Resi virtual machines.',117351,'IEEE Transactions on Computers',4),(24423,NULL,'1987',NULL,'Implementation and test of the ACRITH facility in a system/370','This paper covers some key aspects of the implementation and testing of the ACRITH (``High-Accuracy Arithmetic\'\') facility in the IBM 4361. It also includes a brief description of its definition in the IBM System/370 Architecture RPQ (IBM Publication SA22-7093). The ACRITH facility consists of five new floating-point operations with controlled rounding. Besides the four basic operations (+, 驴, *, /) the scalar product of two vectors has been architectured. The theory and many details of this paper are neither bound to IBM System/370 architecture nor to hexadecimal number systems. They apply also to other architectures, for example binary or decimal.',117351,'IEEE Transactions on Computers',10),(24424,NULL,'1987',NULL,'Testing programmable logic arrays by sum of syndromes','Syndrome testing is a simple and effective fault detection technique applicable to many general circuits. It is particularly useful in two-level circuits, such as programmable logic arrays (PLA\'s). For a multiple-output network, like PLA\'s, existing methods test the individual syndromes for each function, where a fault should be detectable in at least one output. This paper shows that the weighted sum of syndromes of all the outputs covers all single stuck-at-faults, bridging faults, and cross-point faults. Primary input faults are also covered except in one special case which requires some preventive design for testability. This results in the use of one test to cover all single faults.',117351,'IEEE Transactions on Computers',11),(24425,NULL,'1987',NULL,'A study of data interlock in computational networks for sparse matrix multiplication','The general question addressed in this study is: are regular networks suitable for sparse matrix computations? More specifically, we consider a special purpose self-timed computational array that is designed for a specific dense matrix computation. We add to each cell in the network the capability of recognizing and skipping operations that involve zero operands, and then ask how efficient is this resulting network for sparse matrix computation? In order to answer this question, it is necessary to study the effect of data interlock on the performance of self-timed networks. For this, the class of pseudosystolic networks is introduced as a hybrid class between systolic and self-timed networks. Networks in this class are easy to analyze, and provide a means for the study of the worst case performance of self-timed networks. The well known concept of computation fronts is also generalized to include irregular flow of data, and a technique based on the propagation of such computation fronts is suggested for the estimation of the processing time and the communication time of pseudosystolic networks.',117351,'IEEE Transactions on Computers',7),(24426,NULL,'1987',NULL,'Successively improving bounds on performance measures for single class product form queueing networks','The use of queueing network models to analyze the performance of computer systems is widespread. Typically the analysis requires certain assumptions to be made. Even under such assumptions, the exact analysis of these models for the performance measures could be quite time consuming, especially when various alternate configurations of the system are to be evaluated. In some situations, bounds on the performance may often be adequate. This issue of obtaining reasonable bounds has hence been the subject of some discussion and a number of bounding techniques have been proposed over the past few years. In this paper we present a bounding technique for networks with a single class of customers that appears to be more effective than techniques previously reported.',117351,'IEEE Transactions on Computers',3),(24427,NULL,'1987',NULL,'Constructing test cases for partitioning heuristics','In analyzing the effectiveness of min-cut partitioning heuristics, we are faced with the task of constructing ``random\'\' looking test networks with a prescribed cut-set size in its optimal partition. We present a technique for constructing networks over a given set of components that has been a priori partitioned into two parts. The networks have the property that the optimal partition, i.e., one that minimizes the size of the cut-set, is the predefined partition, and this partition has a cut-set of a given size. Furthermore, these networks can be designed to possess certain statistical properties, such as a desired mean and standard deviation for the number of components per net, so that they truly reflect the input space in the application domain. We also extend these techniques to the generalized partitioning problem.',117351,'IEEE Transactions on Computers',9),(24428,NULL,'1987',NULL,'Self-adjusting networks for VLSI simulations','Magnitude networks [1l, [2] have been used as a theoretical base for switch-level simulation of MOS VLSI circuits. We address in this paper the particular problem of evaluating the influence of switches in unknown state on the steady-state response of the network. A two-pass procedure based on local controllers attached to such switches is described and a hardware implementation is proposed which models magnitude networks as self-adjusting combinational circuits.',117351,'IEEE Transactions on Computers',10),(24429,NULL,'1987',NULL,'A note on strongly fault-secure sequential circuits','It is proved that any sequential circuit with its next-state function d and output function w is strongly fault secure for unidirectional faults in d and w if i) the outputs of w are encoded in an unordered code, and ii) d and w are implemented with inverter-free circuits.',117351,'IEEE Transactions on Computers',11),(24430,NULL,'1987',NULL,'MOS test pattern generation using path algebras','There is extensive evidence that the classical, stuck-at fault model, operating at the gate level, is inadequate for testing MOS VLSI circuits. By contrast, a ``nonclassical,\'\' switch-level model驴directly representing open and short circuits in the interconnect and transistors stuck-open or stuck-on驴allows important effects such as MOSFET bidirectionality and tristate behavior to be taken into account. This paper describes a new switch-level method for generating the singular cover of an MOS primitive gate using path algebras. The method yields tests to cover all specified interconnect open and short circuits, and all irredundant transistor stuck-open and stuck-on faults, should such tests exist. It relies on specification of an appropriate algebra by redefinition of the operators used in computing powers of a matrix. Two such algebras are required驴one to generate tests for open circuit faults and the other for short circuit faults. Test generation for networks of primitive gates is achieved in two stages: after deriving singular covers for the primitives, a variant of the D-algorithm with modified ``D-drive\'\' is used. The approach is unified and powerful, having the potential to detect parasitic latch behavior and to generate tests for any of the current MOS VLSI technologies. In common with most present automatic test generation methods, it is restricted to combinational logic. Practical limits on the size of circuit which can be dealt with appear comparable to those set by use of the classical D-algorithm.',117351,'IEEE Transactions on Computers',11),(24431,NULL,'1987',NULL,'Performance analysis of a multiprocessor-based packet switch in networks with link-level sliding-window flow control','In the literature, performance studies on packet switches and link-level flow control procedures were treated separately. In this paper, we use a queueing network approach to analyze packet switch performance in terms of the combined effects of switch architectures and link-level flow-control procedures. Results of the study provide us with valuable insights about switch designs and unfold the relationship between switch performance and packet acknowledgment schemes.',117351,'IEEE Transactions on Computers',3),(24432,NULL,'1987',NULL,'Binary search revisited: another advantage of Fibonacci search','Binary search method is a well-known and a fundamental technique to search a key out of an ordered table. Fibonacci serh is kind of binary search adopting nonequal splitting criterion for dividing the remaining part of the table. This paper clarifies another advantage of Fibonacci search, which has not been found so far. First, it is shown that, from the viewpoint of the amount of head movement, Fibonacci search gives more than 10 percent better efficiency than the ordinary binary search. Furthermore, we propose a novel variation of Fibonacci search, and show that it attains nearly 20 percent better efficiency in average than the ordinary binary search.',117351,'IEEE Transactions on Computers',9),(24780,NULL,'1987',NULL,'A block-and-actions generator as an alternative to a simulator for collecting architecture measurements','To design a new processor or to modify an existing one, designers need to gather data to estimate the influence of specific architecture features on the performance of the proposed machine (PM). To obtain this data, it is necessary to measure on an existing machine (EM) the dynamic behavior of typical programs. Traditionally, simulators have been used to obtain measurements for PMs. Since several hundred EM instructions are required to decode, interpret, and measure each simulated (PM) instruction, the simulation time of typical programs is prohibitively large. Thus, designers tend to simulate only small programs and the results obtained might not be representative of a real system behavior. In this paper we present an alternative tool for collecting architecture measurements: the Block-and-Actions Generator (BKGEN). BKGEN produces a version of the program being measured which is directly executable by the EM. This executable version is obtained directly with the EM compiler or with the PM compiler and a assembly-to-assembly translator. The choice between these alternatives depends on the EM and PM compiler technology and the type of measurements to be obtained. BKGEN also collects the PM events to be measured (called actions). Each EM block of instructions is associated with a PM block of actions so that when the program is executed, it collects the measurements associated with the PM. The main advantage of BKGEN is that the execution time is substantially reduced compared to the execution time of a simulator while collecting similar data. Thus, large typical programs (compilers, assemblers, word processors, ...) can be used by the designer to obtain meaningful measurements.',216669,'SIGPLAN \'87 Papers of the Symposium on Interpreters and interpretive techniques',4),(24801,NULL,'1987',NULL,'Constructive real interpretation of numerical programs','We explore the feasibility of providing exact real arithmetic for use in conventional numerical programs. We have built a prototype interpreter which replaces floating point operations with operations on constructive real numbers in the execution of conventional Fortran programs. Such a facility makes it unnecessary to concern oneself with issues of numerical stability in the solution of small problems. It also provides a useful tool for the development of larger numerical programs.We discuss the computability and algorithmic issues involved in the design of the interpreter, as well as some preliminary experiences and performance measurements.',216669,'SIGPLAN \'87 Papers of the Symposium on Interpreters and interpretive techniques',5),(24976,NULL,'1987',NULL,'Disk file allocation based on the buddy system','The buddy system is known for its speed and simplicity. However, high internal and external fragmentation have made it unattractive for use in operating system file layout. A variant of the binary buddy system that reduces fragmentation is described. Files are allocated on up to t extents, and inoptimally allocated files are periodically reallocated. The Dartmouth Time-Sharing System (DTSS) uses this method. Several installations of DTSS, representing different classes of workload, are studied to measure the method\'s performance. Internal fragmentation varies from 2-6 percent, and external fragmentation varies from 0-10 percent for expected request sizes. Less than 0.1 percent of the CPU is spent executing the algorithm. In addition, most files are stored contiguously on disk. The mean number of extents per file is less than 1.5, and the upper bound is t. Compared to the tile layout method used by UNIX, the buddy system results in more efficient access but less efficient utilization of disk space. As disks become larger and less expensive per byte, strategies that achieve efficient I/O throughput at the expense of some storage loss become increasingly attractive.',16295,'ACM Transactions on Computer Systems (TOCS)',4),(25014,NULL,'1987',NULL,'Memory access patterns of parallel scientific programs','A parallel simulator, PSIMUL, has been used to collect information on the memory access patterns and synchronization overheads of several scientific applications. The parallel simulation method we use is very efficient and it allows us to simulate execution of an entire application program, amounting to hundreds of millions of instructions. We present our measurements on the memory access characteristics of these applications; particularly our observations on shared and private data, their frequency of access and locality. We have found that, even though the shared data comprise the largest portion of the data in the application program, on the average a small fraction of the memory references are to shared data. The low averages do not preclude bursts of traffic to shared memory nor does it rule out positive benefits from caching shared data. We also discuss issues of synchronization overheads and their effect on performance.',216352,'SIGMETRICS \'87 Proceedings of the 1987 ACM SIGMETRICS conference on Measurement and modeling of computer systems',4),(25023,NULL,'1987',NULL,'Performance analysis of a fault detection scheme in multiprocessor systems','A technique is described for detecting and diagnosing faults at the processor level in a multiprocessor system. In this method, a process is assigned whenever possible to two processors: the processor that it would normally be assigned to (primary) and an additional processor which would otherwise be idle (secondary). Two strategies will be described and analyzed: one which is preemptive and another which is non-preemptive. It is shown that for moderately loaded systems, a sufficient percentage of processes can be performed redundantly using the system\'s spare capacity to provide a basis for fault detection and diagnosis with virtually no degradation of response time.',216352,'SIGMETRICS \'87 Proceedings of the 1987 ACM SIGMETRICS conference on Measurement and modeling of computer systems',6),(25026,NULL,'1987',NULL,'Modeling the software architecture of a prototype parallel machine','A high-level Petri net model of the software architecture of an experimental MIMD multiprocessor system for Artificial Intelligence applications is derived by direct translation of the code corresponding to the assumed workload. Hardware architectural constraints are then easily added, and formal reduction rules are used to simplify the model, which is then further approximated to obtain a performance model of the system based on generalized stochastic Petri nets. From the latter model it is possible to estimate the optimal multiprogramming level of each processor so as to achieve the maximum performance in terms of overall throughput (number of tasks completed per unit time).',216352,'SIGMETRICS \'87 Proceedings of the 1987 ACM SIGMETRICS conference on Measurement and modeling of computer systems',5),(25406,NULL,'1987',NULL,'Mapping data flow programs on a VLSI array of processors','With the advent of VLSI, relatively large processing arrays may be realized in a single VLSI chip. Such regularly structured arrays take considerably less time to design and test, and fault-tolerance can easily be introduced into them. However, only a few computational algorithms which can effectively use such regular arrays have been developed so far.We present an approach to mapping arbitrary algorithms, expressed as programs in a data flow language, onto a regular array of data-driven processors implemented by a number of VLSI chips. Each chip contains a number of processors, interconnected by a set of regular paths, and connected to processors in other similar chips to form a large array. This array is thus tailored to perform a specific computational task, as an attached processor in a larger system.The data flow program is first translated into a graph representation, the data flow graph, which is then mapped onto a finite but (theoretically) unbounded array of identical processors. Each node in the graph represents an operation which can be performed by an individual processor in the array. Therefore, the mapping operation consists of assigning nodes in the graph to processors in the array, and defining the connections between the processors according to the arcs in the graph. The last step consists of partitioning the unbounded array into a number of segments, to account for the number of processors which fit in a single VLSI chip.',131953,'ISCA \'87 Proceedings of the 14th annual international symposium on Computer architecture',10),(25407,NULL,'1987',NULL,'Analytical modeling and architectural modifications of a dataflow computer','Dataflow computers are an alternative to the von Neumann architectures and are capable of exploiting large amount of parallelism inherent in many computer applications. This paper deals with the performance analysis of the Manchester dataflow computer based on queueing network models. The model of the dataflow computer has been validated by comparing the analytical results with those obtained from the prototype Manchester dataflow computer. The bottleneck centers in the prototype machine have been identified through the model and various architectural modifications have been investigated both from performance and reliability viewpoints.',131953,'ISCA \'87 Proceedings of the 14th annual international symposium on Computer architecture',5),(25408,NULL,'1987',NULL,'A unified resource management and execution control mechanism for data flow machines','This paper presents a unified resource management and execution control mechanism for data flow machines. The mechanism integrates load control, depth-first execution control, cache memory control and a load balancing mechanism. All of these mechanisms are controlled by such basic information as the number of active state processes, Na. In data flow machines, synchronization among processes is an essential hardware function. Hence, Na can easily be detected by the hardware.Load control and depth-first execution control make it possible to execute a program with a designated degree of parallelism, and depth-first order. A cache memory of data flow processors in multiprocessing environments can be realized by using load and depth-first execution controls together with a deterministic replacement algorithm, i.e. replacement of only waiting state processes. A new load balancing method called group load balancing is also presented to evaluate the above mentioned mechanisms in multiprocessor environments.These unified control mechanisms are evaluated on a register transfer level simulator for a list-processing oriented data flow machine.',131953,'ISCA \'87 Proceedings of the 14th annual international symposium on Computer architecture',4),(25410,NULL,'1987',NULL,'Performance studies of a parallel Prolog architecture','This paper presents a new multiprocessor architecture for the parallel execution of logic programs, developed as part of the Aquarius Project. This architecture is designed to support AND-parallelism, OR-parallelism, and intelligent backtracking. We present the most comprehensive experimental results available to date on combined AND-parallelism, OR-parallelism, and intelligent backtracking in Prolog programs. Simulation results indicate that most Prolog programs in use today cannot effectively make use of multiprocessing.',131953,'ISCA \'87 Proceedings of the 14th annual international symposium on Computer architecture',5),(25415,NULL,'1987',NULL,'Rearrangeability of multistage shuffle/exchange networks','In this paper we study the rearrangeability of multistage shuffle/exchange networks. Although a theoretical lower bound of (2 log2N - 1) stages for rearrangeability of a network with N = 2n inputs and outputs has been known, the sufficiency of (2 log2N - 1) stages has neither been proved nor disproved. The best known upper bound for rearrangeability is (3 log2N - 3) stages. We prove that, if (2 log2R - 1) shuffle/exchange stages are sufficient for rearrangeability of a network with R = 2\' inputs and outputs, then, for any N R, 3 log2N - (r + 1) stages are sufficient for a network with N inputs and outputs. This result is established by setting some of the middle stages of the network to realize a fixed permutation and showing the reduced network to be topologically equivalent to a member of the Benes class of rearrangeable networks. We first characterize equivalence to Benes networks in set-theoretic terms and use this to prove equivalence of the reduced shuffle/exchange network to the Benes network. From the known result that 5 stages are sufficient for rearrangeability when N = 8, we obtain an upper bound of (3 log2N - 4) stages for rearrangeability when N ≥ 8. Further, any increase in the network size R for which the rearrangeability of (2 log2R - 1) stages could be shown, results in a corresponding improvement in the upper bound for all N ≥ R. In addition, due to the one-to-one correspondence that exists between the switches in the reduced shuffle/exchange network and those in the Benes network, the former network can be controlled by the well-known looping algorithm.',131953,'ISCA \'87 Proceedings of the 14th annual international symposium on Computer architecture',7),(26270,NULL,'1987',NULL,'A data-driven model for a subset of logic programming','There is a direct correspondence between semantic networks and a subset of logic programs, restricted only to binary predicates. The advantage of the latter is that it can describe not only the nodes and arcs comprising a semantic net, but also the data-retrieval operations applied to such nets. The main objective of this paper is to present a data-driven model of computation that permits this subset of logic programs to be executed on a highly parallel computer architecture. We demonstrate how logic programs may be converted into collections of data-flow graphs in which resolution is viewed as a process of finding matches between certain graph templates and portions of the data-flow graphs. This graph fitting process is carried out by messages propagating asynchronously through the data-flow graph; thus computation is entirely data driven, without the need for any centralized control and centralized memory. This permits a potentially large number of independent processing elements to cooperate in solving a given query.',16444,'ACM Transactions on Programming Languages and Systems (TOPLAS)',2),(27181,NULL,'1987',NULL,'Optimization models for configuring distributed computer systems','This paper develops models for designing the architecture of distributed computing systems of the type used to support corporate management and control activities. The data for the design process consist of two major data sets describing the inputs and outputs to the information system and the relationships between them. The model accepts a listing of the relevant data sources in the organization, their physical locations, the number and rate of transactions originating from those locations and the amount of data that have to be transferred before the transactions can be updated, the list of reports that have to be generated by the system, their generation frequency and their physical distribution of those reports to end users. For each report type, the sources of data needed to generate it and the volume of data that have to be transferred for each run.',117351,'IEEE Transactions on Computers',3),(27182,NULL,'1987',NULL,'A new interconnection network for SIMD computers: the sigma networks','When processing vectors on SIMD computers, some data manipulations (rearrangement, expansion, compression, perfect-shuffle, bit-reversal) have to be performed by an interconnection network. When this network lacks an efficient routing control, it becomes the bottleneck for performance. It has been pointed out that general algorithms to control rearrangeable networks for arbitrary permutations are time consuming. To overcome this difficulty, Lenfant [9] proposed a set of permutations covering standard needs associated with efficient control algorithms for the Benes network. But to perform explicit permutations on vectors, several passes through the network are necessary because they have to be composed with transfer rearrangements. We present efficient control algorithms to perform these vector permutations in a single pass on a new interconnection network.',117351,'IEEE Transactions on Computers',7),(27183,NULL,'1987',NULL,'Programming cellular permutation networks through decomposition of symmetric groups','A fundamental problem in interconnection network theory is to design permutation networks with as few cells as possible and a small programming or setup time. The well-known networks of Benes and Waksman have asymptotically optimal cell counts, but the best setup algorithm available for such networks with n inputs requires O(n log2 n) sequential time. As an alternative, this paper considers another class of permutation networks which are collectively referred to as cellular permutation arrays. Using a group theoretic formulation, a natural correspondence is established between such permutation networks and iterative decompositions of symmetric groups through cosets. Based on this correspondence, the setup problem is reduced to iteratively determining the leaders of the cosets to which the permutation to be realized belongs. This, in turn, leads to linear-time setup algorithms for cellular permutation arrays. The paper describes these algorithms in detail for two families of cellular permutation arrays reported in the literature.',117351,'IEEE Transactions on Computers',7),(27184,NULL,'1987',NULL,'On the permutation capability of multistage interconnection networks','We present analytic models for the blocking probability of both unique path and multiple path multistage interconnection networks under the assumption of either permutation or random memory request patterns. The blocking probability of an interconnection network under the assumption of permutation requests is a quantitative measure of the network\'s permutation capability. We compare the performance of networks with approximately equivalent hardware complexity. It is shown that variations of banyan networks can be designed with extremely low blocking probabilities under the assumption of permutation requests.',117351,'IEEE Transactions on Computers',7),(27185,NULL,'1987',NULL,'Analysis and synthesis of dynamic multicomputer networks that reconfigure into rings, trees, and stars','This paper presents analysis and synthesis techniques for multicomputer networks that perform fast reconfiguration into rings, stars, and trees. Each reconfiguration into a new network structure requires only two codes (reconfiguration code RC and bias B), and can be performed during one clock period. Because the reconfiguration methodology presented is based on some fine mathematical properties exhibited by special shift registers with variable bias (SRVB), they are also introduced in this paper.',117351,'IEEE Transactions on Computers',2),(27186,NULL,'1987',NULL,'Stencils and problem partitionings: their influence on the performance of multiple processor systems','Given a discretization stencil, partitioning the problem domain is an important first step for the efficient solution of partial differential equations on multiple processor systems. We derive partitions that minimize interprocessor communication when the number of processors is known a priori and each domain partition is assigned to a different processor. Our partitioning technique uses the stencil structure to select appropriate partition shapes. For square problem domains, we show that nonstandard partitions (e.g., hexagons) are frequently preferable to the standard square partitions for a variety of commonly used stencils. We conclude with a formalization of the relationship between partition shape, stencil structure, and architecture, allowing selection of optimal partitions for a variety of parallel systems.',117351,'IEEE Transactions on Computers',2),(27187,NULL,'1987',NULL,'Characterization of branch and data dependencies on programs for evaluating pipeline performance','The nature by which branches and data dependencies generate delays that degrade pipeline performance is investigated in this paper. We show that for the general execution trace, few specific delays can be considered in isolation; rather, the magnitude of any specific delay may depend on the relative proximity of other delays. This phenomenon can make the task of accurately characterizing a trace tape with simple statistics intractable. We present a set of trace reductions that facilitates this task by simplifying the corresponding data-dependency graph. The reductions operate on multiple data-dependency arcs and branches in conjunction; those arcs whose performance implications are redundant with respect to the dependency graph are identified, and eliminated from the graph. We show that the reduced graph can be accurately characterized by simple statistics. We use these statistics to show that as the length of a pipeline increases, the performance degradation due to data dependencies and branches increases monotonically. However, lengthening the pipeline may correspond to decreasing the cycle time of the pipeline. These two opposing effects are used in conjunction to derive an equation for optimal pipeline length for a given trace tape. The optimal pipeline length is shown to be characterized by n = √γα where γ is the ratio of overall circuit delay to latching overhead, and a is a function of the trace statistics that accounts for the delays induced by data dependencies and branches.',117351,'IEEE Transactions on Computers',4),(27188,NULL,'1987',NULL,'A multiprocessor architecture for two-dimensional digital filters','In this paper, a generic computational primitive is developed for the implementation of any arbitrary order one-dimensional or two-dimensional FIR or IIR digital filter. This computational primitive can form the basis for a single chip processor for one-dimensional and two-dimensional digital signal processing. A multiprocessor architecture for real-time implementation of spatial domain filters is developed with each processing unit in the network implementing the computational primitive. This multiprocessor system has a simple control scheme, a simple interconnection network, a very high efficiency, and low data transfers and storage requirements. Thus, it avoids the bottlenecks associated with traditional parallel computers and multiprocessor systems.',117351,'IEEE Transactions on Computers',10),(27189,NULL,'1987',NULL,'On group graphs and their fault tolerance','This paper investigates group graphs as a source of interconnection networks. It is shown that while these graphs possess many properties desirable in all interconnection networks, their diversity allows the generation of interconnection networks which may be optimized with regard to a variety of specific parameters. Techniques are described for generating, combining, and analyzing these graphs with respect to their order, diameter, fault tolerance, etc. A theorem is derived which shows that a large important class of group graphs are optimally fault tolerant. A number of examples are included.',117351,'IEEE Transactions on Computers',7),(27190,NULL,'1987',NULL,'Assignment of job modules onto array processors','This paper deals with the optimum assignment of job modules onto array processors. In array processors it is important to assign job modules onto processors such that the modules that communicate with each other are assigned to adjacent processors, because communication overhead increases as communications occur between processors that are remotely connected. We propose an efficient algorithm to solve this assignment problem for a specific array of processors. The algorithm reduces the quadratic problem to a solvable linear problem that produces a good, but not necessarily optimal solution. This is followed by a phase of iterations in which the solution is improved by small perturbation of the assignment.',117351,'IEEE Transactions on Computers',9),(27191,NULL,'1987',NULL,'A minimum test set for multiple fault detection on ripple carry adders','Previous papers have shown that a ripple carry adder composed of several full adder cells can be completely tested by a minimum test set of size 8 independent of the number of cells in the ripple carry adder under single faulty cell assumption. The fault model assumed is that faults in a cell can change the cell behavior in any arbitrary way, as long as the cell remains a combinational circuit. In this paper, we assume that any number of cells can be faulty at any time. A minimum test set of size 11 which can detect arbitrary length ripple carry adders under this fault model is presented. For general (N, p) adders in which each cell is a p-bit adder, a minimum test set of size 3 × 22P − 1 is also presented.',117351,'IEEE Transactions on Computers',11),(27192,NULL,'1987',NULL,'On-the-fly conversion of redundant into conventional representations','An algorithm to convert redundant number representations into conventional representations is presented. The algorithm is performed concurrently with the digit-by-digit generation of redundant forms by schemes such as SRT division. It has a step delay roughly equivalent to the delay of a carry-save adder and simple implementation. The conversion scheme is applicable in arithmetic algorithms such as nonrestoring division, square root, and on-line operations in which redundantly represented results are generated in a digit-by-digit manner, from most significant to least significant.',117351,'IEEE Transactions on Computers',8),(27193,NULL,'1987',NULL,'Performance Analysis of Distributed Routing Strategies Free of Ping-Pong-Type Looping','This paper deals with a distributed adaptive routing strategy which is very simple and effective, and is free of a ping-pong-type looping in the presence of network failures. Using the number of time intervals required for a node to recover from a network failure as the measure of network\'s adaptability, performance of this strategy and the ARPANET\'s previous routing strategy (APRS) is comparatively analyzed without resorting to simulation. Formulas of the exact number of time intervals required for failure recovery under both strategies are also derived. We show that i)the performance of the strategy is always better than, or at least as good as, that of APRS, and ii) network topology has significant effects on the performance of both strategies.',117351,'IEEE Transactions on Computers',7),(27194,NULL,'1987',NULL,'Performance Models of Asynchronous Multitrunk HYPERchannel Networks','The HYPERchannel communication network based on one to four trunks, or channels is considered. We develop closed queueing models with dependent servers which characterize the network performance as a function of the number of channels, the channel load, the number of stations and the packet length distribution. For analyzing the network behavior with constant packet length we introduce techniques for representing the actual asynchronous network operation by a tractable \"sequential synchronous\" model. Throughput and delay measures are in this way obtained for asynchronous systems operating with constant or exponential service times. The developed approach can also be used for obtaining tractable analyses of other asynchronous systems, such as multiprocessors employing multiple-bus interconnection. In the case of HYPERchannel networks, we apply the introduced models for analyzing multi- trunk network behavior and for predicting the number of channels needed to obtain a required packet-delay/trunk-utilization performance. In HYPERchannel networks the observed results are of special significance since they are most pronounced when the number of stations is small, the situation found in the majority of operational networks.',117351,'IEEE Transactions on Computers',7),(27195,NULL,'1987',NULL,'The Fast Hartley Transform Algorithm','The fast Hartley transform (FHT) is similar to the Cooley-Tukey fast Fourier transform (FFT) but performs much faster because it requires only real arithmetic computations compared to the complex arithmetic computations required by the FFT. Through use of the FHT, discrete cosine transforms (DCT) and discrete Fourier transforms (DFT) can be obtained. The recursive nature of the FHT algorithm derived in this paper enables us to generate the next higher order FHT from two identical lower order FHT\'s. In practice, this recursive relationship offers flexibility in programming different sizes of transforms, while the orderly structure of its signal flow-graphs indicates an ease of implementation in VLSI.',117351,'IEEE Transactions on Computers',8),(27196,NULL,'1987',NULL,'Logic Networks with a Minimum Number of NOR(NAND) Gates for Parity Functions of n Variables','Design of logic networks, in single-rail input logic, with a minimum number of NOR gates for parity functions of an arbitrary number of variables is described. This is partly based on minimum networks for parity functions of a small number of variables which are designed by the integer programming logic design method. Although it is generally difficult to design minimum networks for functions of an arbitrarily large number of variables, we have previously designed minimum networks for adders of an arbitrary number of variables. The minimum networks for parity functions of an arbitrary number of variables discussed in this paper is another case. Many unique properties of minimum NOR networks for parity functions are shown. Minimum networks with NAND gates for parity functions can be easily obtained from those with NOR gates because of duality relationship between NAND and NOR.',117351,'IEEE Transactions on Computers',1),(27197,NULL,'1987',NULL,'On the Schur Decomposition of a Matrix for Parallel Computation','An algorithm to solve the eigenproblem for nonsymmetric matrices on an N 脳 N array of mesh-connected processors, isomorphic to the architecture described by Brent and Luk for symmetric matrices, is presented. This algorithm is a generalization of the classical Jacobi method, and, as such, holds promise for parallel architectures. The rotational parameters for the nonsymmetric case are carefully analyzed; many examples of a working program, simulating the parallel architecture, are given with experimental evidence of quadratic convergence.',117351,'IEEE Transactions on Computers',9),(27198,NULL,'1987',NULL,'A General Model for Memory-Based Finite-State Machines','A general model of a memory-based finite-state machine architecture is introduced, the 2k- decision machine (2k- D). The classical (2n- D) and binary decision (2 - D) architectures are shown to be special cases of the 2k- D architecture. The equivalence among the 2k- D solutions for different values of k follows from the sequentialization prin',117351,'IEEE Transactions on Computers',1),(27199,NULL,'1987',NULL,'Abstractions of Finite-State Machines Optimal with Respect to Single Undetectable Output Faults','An observer, whose task is to monitor a large and complex system M^ subject to malfunctions, may be interested in dealing with a simplified, abstracted model (M^A of it, at the expense of some loss in fault-detection ability. Let M^ be a finite- state machine whose inputs are modeled by stationary random variables. The abstraction A is effected by lumping M^\'s states, inputs, and outputs into classes, to obtain a smaller probabilistic machine M^A. These ideas have been introduced in a previous paper, and the question of finding an optimal abstraction A* which minimizes the number of faults undetectable by the observer was posed. An algorithm for constructing the output component of the optimal abstraction A* is given in this paper. If there are no faults in the next-state map of M^, this construction is sufficient to minimize the number of single faults in the output map that are undetectable by the observer because of the abstraction. Some experiments carried out using the algorithm provide general insight into the tradeoff between simplifying M^ and making some faults in it undetectable. As a specific example, optimal output abstractions are found for a finite-state machine specification of the link level of the X.25 communication protocol.',117351,'IEEE Transactions on Computers',1),(27200,NULL,'1987',NULL,'A New Approach to the Design of Testable PLA\'s','Programmable logic arrays (PLA\'s) are extensively used to realize area efficient combinational logic circuits. As the size of the PLA\'s increases, a cost-effective way to test them is to realize testable PLA\'s. In this paper a new approach to the design of testable PLA\'s is presented. The proposed method leads to testable PLA\'s with minimal area penalty and small number of tests that can be obtained as a by-product of the synthesis procedure, or can be directly obtained from the personality of the PLA\'s, thus simplifying the test derivation step. Results of an experiment involving 56 PLA\'s, to compare the test set sizes of differenit testable PLA designs (including the design proposed here) as well as the size of tests derived to detect single faults by algorithmic procedures are also reported.',117351,'IEEE Transactions on Computers',11),(27201,NULL,'1987',NULL,'Using Decision Trees to Derive the Complement of a Binary Function with Multiple-Valued Inputs','An algorithm to minimize decision trees of Boolean functions with multiple-valued inputs is presented. The recursive algorithm is used to obtain a complement of a sum-of-products expression for a binary function with multiple-valued inputs. In the case where each input is p-valued, the algorithm produces at most pn-l products for n-variable functions, whereas Sasao\'s algorithm produces pn/2 products. This upper bound on the number of products is the best possible.',117351,'IEEE Transactions on Computers',1),(27202,NULL,'1987',NULL,'Multilevel Logical Networks','In this correspondence we present a design technique for implementation of systems of Boolean functions in the form of multilevel AND-OR networks. We show that for a given system of Boolean functions, the transition from the traditional two-level AND-OR implementation to multilevel AND-OR implementations results in considerable savings in gate counts and delays. We discuss gate-array implementations of these multilevel networks and their space and time complexities. Experimental data for 11 different components of peripheral control units for VAX computers indicate that the transition from the two-level implementations to multilevel implementations results in average savings of about 40 percent in gate counts, of about 25 percent in required silicon areas and of about 25 percent in delays, which illustrate a good potential of the proposed techniques for design of cost-efficient gate arrays.',117351,'IEEE Transactions on Computers',10),(27203,NULL,'1987',NULL,'Inverter-Minimum Networks','Let Fm= (f1,...,fm) be a vector of m logical functions. Let Inv (Fm), the inversion complexity of Fm, be the minimum number of inverters required to realize Fm by a feed-forward network using AND gates, OR gates, and inverters.',117351,'IEEE Transactions on Computers',1),(27204,NULL,'1987',NULL,'Algorithmic Phase Diagrams','Algorithmic phase diagrams are a neat and compact representation of the results of comparing the execution time of several algorithms for the solution of the same problem. As an example we show the recent results of Gannon and Van Rosendale on the solution of multiple tridiagonal systems of equations in the form of such diagrams. The act of preparing these diagrams has revealed an unexpectedly complex relationship between the best algorithm and the number and size of the tridiagonal systems, which was not evident from the algebraic formulae in the original paper. Even so, for a particular computer, one diagram suffices to predict the best algorithm for all problems that are likely to be encountered-the prediction being read directly from the diagram without complex calculation.',117351,'IEEE Transactions on Computers',2),(27205,NULL,'1987',NULL,'On Linear Skewing Schemes and d-Ordered Vectors','Linear skewing schemes were introduced by Kuck et al. in the nineteen sixties, to provide a simple class of storage mappings for N 脳 N matrices for use in vector processors with a large number of memory banks. Conditions on linear skewing schemes that guarantee conflict-free access to rows, columns, and/or (anti-) diagonals are usually presented in terms of conditions on so-called d-ordered vectors. We shall argue that these formulations are mathematically imprecise, and revise and extend the existing theory. Several claims are proved to bound the minimum number of memory banks needed for successful linear skewing by, e.g., the smallest prime number = N.',117351,'IEEE Transactions on Computers',9),(27206,NULL,'1987',NULL,'On the Time-Bandwidth Proof in VLSI Complexity','A subtle fallacy in the original proof [1] that the computation time T is lowerbounded by a factor inversely proportional to the minimum bisection width of a VLSI chip is pointed out. A corrected version of the proof using the idea of conditionally self-delimiting messages is given.',117351,'IEEE Transactions on Computers',9),(27207,NULL,'1987',NULL,'A VLSI Implementation of the Simplex Algorithm','The use of a special-purpose VLSI chip for solving a linear programming problem is presented. The chip is structured as a mesh of trees and is designed to implement the well-known simplex algorithm. A high degree of parallelism is introduced in each pivot step, which can be carried out in O (log n) time using an m 脳 n mesh of trees having an O(mn log m log3 n) area where m - 1 and n - 1 are the number of constraints and variables, respectively. Two variants of the simplex algorithm are also considered: the two-phase method and the revised one. The proposed chip is intended as being a possible basic block for a VLSI operations research machine.',117351,'IEEE Transactions on Computers',8),(27208,NULL,'1987',NULL,'A Computer Algorithm for Minimizing Reed-Muller Canonical Forms','A computer algorithm is presented that uses geometrical operations to minimize multioutput Reed-Muller expansions of up to ten variables.',117351,'IEEE Transactions on Computers',8),(27209,NULL,'1987',NULL,'Rate 1/2 and 2/3 Majority Logic Decodable Binary Burst Error-Correcting Codes','A new design procedure is described for constructing rate 1/2 and rate 2/3 majority logical decodable burst error-correcting codes. The rate 1/2 codes are closely related to the codes of Srinivasan [1].',117351,'IEEE Transactions on Computers',8),(27210,NULL,'1987',NULL,'Test Length for Pseudorandom Testing','The process of determining the required test length for a desired level of confidence for pseudorandom testing using a random sampling without replacement model is examined. The differences between random and pseudorandom testing are discussed and developed. The strictly random testing model is shown to be inaccurate for high confidence testing of combinational circuits. A method of calculating the required test length for pseudorandom testing based upon fault detectabilities is described. The result provides a very accurate prediction of required test length applicable to self-test using pseudorandom inputs.',117351,'IEEE Transactions on Computers',11),(27211,NULL,'1987',NULL,'Distributing Hot-Spot Addressing in Large-Scale Multiprocessors','When a large number of processors try to access a common variable, referred to as hot-spot accesses in [6], not only can the resulting memory contention seriously degrade performance, but it can also cause tree saturation in the interconnection network which blocks both hot and regular requests alike. It is shown in [6] that even if only a small percentage of all requests are to a hot-spot, these requests can cause very serious performances problems, and networks that do the necessary combining of requests are suggested to keep the interconnection network and memory contention from becoming a bottleneck.',117351,'IEEE Transactions on Computers',3),(27212,NULL,'1987',NULL,'Interprocessor Traffic Scheduling Algorithm for Multiple-Processor Networks','Recent research on parallel systems has shown that the most difficult problem for system designers and users is interprocessor connection and communication. A methodology for the automated design and implementation of interprocessor communication for certain multiple-processor systems has been developed and is presented in this paper. For many application- specific and mission-oriented systems, the interprocessor communication is deterministic and can be specified at system inception. This specification can then be automatically mapped or complied onto a physical multiple-processor system using a network traffic scheduler. An algorithm for such a scheduler, which is capable of obtaining optimal network traffic patterns, has been developed. It is shown that the order of complexity of network scheduler components is polynomial, rather than expopential as in classical solutions.',117351,'IEEE Transactions on Computers',3),(27213,NULL,'1987',NULL,'Processor Allocation for Horizontal and Vertical Parallelism and Related Speedup Bounds','The main aim of the paper is to study allocation of processors to, parallel programs executing on a multiprocessor system, and the resulting speedups. First, we consider a parallel program as a sequence of steps where each step consists of a set of parallel operations. General bounds on the speedup on a p- processor system are derived based on this model. Measurements of code parallelism for the, LINPACK numerical package are presented to support the belief that typical numerical programs contain much potential parallelism that can be discovered by a good restructuring compiler. Next, a parallel program is represented as a task graph whose nodes are do across loops (i.e., loops whose iterations can be partially, overlapped). It is shown how processors can be allocated to exploit horizontal and vertical parallelism in such graphs. Two processor allocation heuristic algorithms (WP and PA) are presented. PA is the heart of the WP and is used to obtain efficient processor allocations for a set of independent parallel tasks. WP allocates processors to general task graphs. Finally, a general formula for the speedup of a DO across loop is given that is more accurate than the known formula.',117351,'IEEE Transactions on Computers',0),(27214,NULL,'1987',NULL,'The Effects of Problem Partitioning, Allocation, and Granularity on the Performance of Multiple-Processor Systems','In this paper we analyze the effects of the problem decomposition, the allocation of subproblems to processors, and the grain size of subproblems on the performance of a multiple- processor shared-memory architecture. Our results indicate that for algorithms where both the computation and the communication overhead can be fully decomposed among N processors, the speedup is a nondecreasing function of the level of granularity for arbitrary interconnection structure and allocation of subproblems to processors. For these algorithms, the speedup is an increasing function of the level of granularity provided that the interconnection bandwidth is greater than unity. If the bandwidth is equal to unity, then the speedup converges to the value equal to the ratio of processing time to communication time. For algorithms where the computation is decomposable but the communication overhead cannot be decomposed, the speedup is a nondecreasing function of the level of granularity for the best case bandwidth only. If the bandwidth is less than N, the speedup reaches its maximum and then decreases approaching zero as the level of granularity grows. For algorithms where the computation consists of parallel and serial sections of code and the communication overhead is fully decomposable, the speedup converges to a value inversely proportional to the fraction of time spent in the serial code even for the best case interconnection bandwidth.',117351,'IEEE Transactions on Computers',4),(27215,NULL,'1987',NULL,'A Mapping Strategy for Parallel Processing','This paper presents a mapping strategy for parallel processing using an accurate characterization of the communication overhead. A set of objective functions is formulated to evaluate the optimality of mapping a problem graph onto a system graph. One of them is especially suitable for real-time applications of parallel processing. These objective functions are different from the conventional objective functions in that the edges in the problem graph are weighted and the actual distance rather than the nominal distance for the edges in the system graph is employed. This facilitates a more accurate quantification of the communication overhead. An efficient mapping scheme has been developed for the objective functions, where two levels of assignment optimization procedures are employed: initial assignment and pairwise exchange. The mapping scheme has been tested using the hypercube as a system graph.',117351,'IEEE Transactions on Computers',9),(27216,NULL,'1987',NULL,'Extending Multiversion Time-Stamping Protocols to Exploit Type Information','Atomic transactions are a widely accepted approach to implementing and reasoning about fault-tolerant distributed programs. This paper shows how multiversion time-stamping protocols for atomicity can be extended to induce fewer delays and restarts by exploiting semantic information about objects such as queues, directories, or counters. This technique relies on static preanalysis of conflicts between operations, and incurs no additioiwal runtime overhead. This technique is deadlock-free, and it is applicable to objects of arbitrary type.',117351,'IEEE Transactions on Computers',2),(27217,NULL,'1987',NULL,'Timing Issues in the Distributed Execution of Ada Programs','This paper examines, in the context of distributed execution, the meaning of Ada constructs involving time. In the process, unresolved questions of interpretation and problems with the implementation of a consistent notion of time across a network are uncovered. It is observed that there are two Ada mechanisms that can involve a distributed sense of time: the conditional entry call, and the timed entry call. It is shown that a recent interpretation by the Language Maintenance Committee resolves the questions for the conditional entry calls but results in an anomaly for timed entry calls. A detailed discussion of alternative implementations for the timed entry call is made, and it is argued that: 1) timed entry calls imply a common sense of time between the machines holding the calling and called tasks; and 2) the measurement of time for the expiration of the delay and the decision of whether or not to perform the rendezvous should be made on the machine holding the called task. The need to distinguish the unreadiness of the called task from timeouts caused by network failure is pointed out. Finally, techniques for realizing a single sense of time across the distributed system (at least to within an acceptable degree of uncertainty) are also discussed.',117351,'IEEE Transactions on Computers',0),(27218,NULL,'1987',NULL,'Optimal Graph Algorithms on a Fixed-Size Linear Array','Parallel algorithms for computing the minimum spanning tree of a weighted undirected graph, and the bridges and articulation points of an undirected graphs on a fixed-size linear array of processors are presented. For a graph of n vertices, the algorithms operate on a linear array of p processors and require O(n2/p) time for all p, 1 = p = n. In particular, using n processors the algorithms require O(n) time which is optimal on this model. The paper describes two approaches to limit the communication requirements for solving the problems. The first is a divide-and-conquer strategy applied to Sollin\'s algorithm for finding the minimum spanning tree of a graph. The second uses a novel data-reduction technique that constructs an auxiliary graph with no more than 2n - 2 edges, whose bridges and articulation points are the bridges and articulation points of the original graph.',117351,'IEEE Transactions on Computers',9),(27219,NULL,'1987',NULL,'Debugging Parallel Programs with Instant Replay','The debugging cycle is the most common methodology for finding and correcting errors in sequential programs. Cyclic debugging is effective because sequential programs are usually deterministic. Debugging parallel programs is considerably more difficult because successive executions of the same program often do not produce the same results. In this paper we present a general solution for reproducing the execution behavior of parallel programs, termed Instant Replay. During program execution we save the relative order of significant events as they occur, not the data associated with such events. As a result, our approach requires less time and space to save the information needed for program replay than other methods. Our technique is not dependent on any particular form of interprocess communication. It provides for replay of an entire program, rather than individual processes in isolation. No centralized bottlenecks are introduced and there is no need for synchronized clocks or a globally consistent logical time. We describe a prototype implementation of Instant Replay on the BBN Butterfly Parallel Processor, and discuss how it can be incorporated into the debugging cycle for parallel programs.',117351,'IEEE Transactions on Computers',2),(27220,NULL,'1987',NULL,'Star Local Area Networks: A Performance Study','In this paper we study local area networks based on the star topology. We consider different access protocols used for communication over star networks. The study is concerned with network performance. We present models for the analysis of existing star network protocols. We also propose a new access protocol for star networks. The protocol has a performance that is very close to perfect scheduling. It is based on using the semaphore mechanism for bandwidth sharing. We also present an exact performance model for this protocol.',117351,'IEEE Transactions on Computers',7),(27221,NULL,'1987',NULL,'Modeling of Concurrent Task Execution in a Distributed System for Real-Time Control','In a distributed system that implements real-time control, computational tasks are distributed over different nodes for execution to improve response time and system reliability. To model system behavior, tasks in each node are first decomposed into activities. The activities and precedence constraints among them are then modeled by a generalized stochastic Petri net (GSPN). Finally, a sequence of homogeneous continuous-time Markov chains (CTMC\'s) is built from the GSPN to model the concurrent task execution in the system.',117351,'IEEE Transactions on Computers',0),(27222,NULL,'1987',NULL,'Optimal Partitioning and Redundancy Removal in Computing Partial Sums','Two novel algorithms for simultaneous computation of a large number of partial sums are introduced, their performance assessed, and architectures for their implementation suggested. The direct computation of D operations are replaced by O(D/log D). The new approach is based on a new concept of optimal partitioning and redundancy removal in arithmetic intensive, high throughput computing that is expected to be the basis of a new class of algorithms which represent a, departure from brute force parallel computation where inherent redundancy is not detected or removed.',117351,'IEEE Transactions on Computers',8),(27223,NULL,'1987',NULL,'A Way to Build Efficient Carry-Skip Adders','In this paper, we present a way to obtain efficient carry-skip adders, built with blocks of different sizes in VLSI technologies. We give some results about two-level carry-skip adders. We reduce our optimization problem to a geometrical problem, solved by means of an algorithm easily implemented on a microcomputer. Then we present an example of the realization of such an adder.',117351,'IEEE Transactions on Computers',8),(27224,NULL,'1987',NULL,'Algorithms to Process Distributed Queries in Fast Local Networks','We propose a scheme to make use of semantic information to process distributed queries locally without data transfer with respect to the join clauses of the query. Since not all queries can be processed without data transfer, we give an algorithm to recognize the \"locally processable queries.\" For nonlocally processable queries, a simple \"fragment and replicate\" algorithm is used. The algorithm chooses a relation to remain fragmented at the sites where they are situated while replicating the other relations at those sites. Our algorithm determines the chosen relation and the chosen copy of every fragment of the chosen relation such that the minimum response time is obtained. The algorithm runs in linear time. If the fragments of the relation are allowed to be processed in other sites, then the problem is NP hard. Two heuristics are given for that situation. They are compared to the optimal situation. Experimental results show that the strategies produced by the heuristics have small errors relative to the optimal strategy.',117351,'IEEE Transactions on Computers',9),(27225,NULL,'1987',NULL,'A Construction Method of High-Speed Decoders Using ROM\'s for Bose-Chaudhuri-Hocquenghem and Reed-Solomon Codes','In this paper, some efficient methods of solving equations over Galois field GF(2m) are proposed. Using these algorithms, decoders for triple-and quadruple-error-correcting Bose-Chaudhuri-Hocquenghem (BCH) codes are shown. More- over, we propose a new method of making high-speed decoders for double-error-correcting/triple-error-detecting BCH or Reed- Solomon (RS) codes by adding a simple error-identifying circuit to a decoder for double-error-correcting codes. By incorporating ROM\'s (read only memory) in a decoder, the complex logic circuits are eliminated and then we can easily construct a high- speed decoder. We evaluate the complexity of the decoders and show that each of them can be accommodated in a single chip LSI.',117351,'IEEE Transactions on Computers',8),(27226,NULL,'1987',NULL,'Reconfigurable Tree Architectures Using Subtree Oriented Fault Tolerance','An approach to the design of reconfigurable tree architectures is presented in which spare processors are allocated at the leaves. The approach is unique in that spares are associated with subtrees and sharing of spares between these subtrees can occur. The Subtree Oriented Fault Tolerance (SOFT) approach is more reliable than previous approaches capable of tolerating link and switch failures for both single-chip and multichip tree implementations while reducing redundancy in terms of both spare processors and links. VLSI layout is O(n) for binary trees and is directly extensible to N-ary trees and fault tolerance through performance degradation.',117351,'IEEE Transactions on Computers',6),(27227,NULL,'1987',NULL,'Traffic-Specific Interconnection Networks for Multicomputers','Special-purpose networks of processors and intelligent switching devices can be programmed to solve problems with inherent parallelism. The target algorithm is coded into a number of asynchronously executing parallel tasks, and assigned to specific processors. For well-known algorithms, information about the data communicated between these tasks (traffic) can be characterized and used by a heuristic algorithm to produce a specialized interconnection network of switching devices at a lower cost and increased performance over the use of a general purpose structure. A program was developed which uses intertask communications to automatically generate interconnection structures of switch chips (SC\'s). Simulation results were used to compare cost/performance measures for the program-generated networks with some well-known structures, using both statistically generated traffic patterns and the simulation of real applications.',117351,'IEEE Transactions on Computers',3),(27228,NULL,'1987',NULL,'The Reliability of Voting Mechanisms','In a faulty distributed system, voting is commonly used to achieve mutual exclusion among groups of isolated nodes. Each node is assigned a number of votes, and any group with a majority of votes can perform the critical operations. Vote assignments can have a significant impact on system reliability. In this paper we address the problem of selecting vote assignments in order to maximize the probability that the critical operations can be performed at a given time by some group of nodes. We suggest simple heuristics to assign votes, and show that they give good results in most cases. We also study three particular homogeneous topologies (fully connected, Ethernet, and ring networks), and derive analytical expressions for system reliability. These expressions provide useful insights into the reliability provided by voting mechanisms.',117351,'IEEE Transactions on Computers',7),(27229,NULL,'1987',NULL,'Tree-Based Broadcasting in Multihop Radio Networks','This paper considers the issue of broadcasting protocols in multihop radio networks. The objective of a broadcasting protocol is to deliver the broadcasted message to all network nodes. To efficiently achieve this objective the broad- casting protocol in this paper utilizes two basic properties of the multihop radio network. One is the broadcast nature of the radio which allows every single trasmission to reach all nodes that are in line of sight and within range of the transmitting node. The other, spatial reuse of the radio channel, which due to the multihop nature of the network allows multiple simultaneous transmissions to be received correctly. The proposed protocol incorporates these properties to obtain a collision free forwarding of the broadcasted message on a tree. Centralized and distributed algorithms for the tree construction are presented. The obtained trees are unique in incorporating radio oriented time ordering as part of their definition. In this way multiple copies of one or more broadcasted messages can be transmitted simultaneously without collision, requiring only a small number of message transmissions. Consequently, the protocol not only guarantees that the broadcasted message reaches all network nodes in bounded time, but also ensures that the broadcasting activity will use only limited channel bandwidth and node memory. The proposed broadcast protocol thus possesses the advantages of TDM solutions while allowing the channel bandwidth to be shared, concurrently with the broadcast, with other transmission activities as dictated, for instance, by data link protocols. Some NP-completeness proofs are also given.',117351,'IEEE Transactions on Computers',7),(27230,NULL,'1987',NULL,'SYREL: A Symbolic Reliability Algorithm Based on Path and Cutset Methods','Symbolic terminal reliability algorithms are important for analysis and synthesis of computer networks. In this paper, we present a simple and efficient algorithm, SYREL, to obtain compact terminal reliability expressions between a terminal pair of computers of complex networks. This algorithm incorporates conditional probability,, set theory, and Boolean algebra in a distinct approach in which most of the computations performed are directly executable Boolean operations. The conditibnal probability is used to avoid applying at each iteration the most time consuming step in reliability algorithms, which is making a set of events mutually exclusive. The algorithm has been implemented on a VAX 11/750 and can analyze fairly large networks with modest memory and time requirements.',117351,'IEEE Transactions on Computers',2),(27231,NULL,'1987',NULL,'On the Complexity of Table Lookup for Iterative Division','We show that except for a few special cases allowing smaller tables, the lookup table used for achieving k digits of convergence after the initial multiplication (or for obtaining the approximate reciprocal of the divisor with k - 1 digits of accuracy) in iterative division methods must have at least (r--l) rk words of k + I digits, r being the number representation base. In the important special case of r = 2 with k =5, a 2k-word table with k-bit entries can be used, since the initial digit is always 1. It is also shown that a table of this optimal size can always be constructed. The special cases corresponding to r = 3 with k = 1, and r = 2 with k = 4, allow smaller tables than the general case and are thus handled separately.',117351,'IEEE Transactions on Computers',8),(27232,NULL,'1987',NULL,'Finite Field Fault-Tolerant Digital Filtering Architectures','Digital filtering architectures that simultaneously offer advantages for VLSI fabrication and contain distributed error control are presented. Such structures require parallelism as well as inherent error- control capabilities because VLSI implementations are susceptible to temporary and intermittent hardware errors. The filtering convolution operation is similar to the formation of cyclicerror-correcting codes so that fault-tolerant systems employing finite field arithmetic may be designed containing such codes imbedded directly in the architecture. The interconnection of such systems produces a fault-tolerant system. In addition, the subsystems possess a common design structure which is easily customized to the particular field required, an attractive feature for yield enhancement. Straightforward realizations depending on parallel algebraic decompositions are studied, introducing the locations for fault tolerance and the role of cyclic codes.',117351,'IEEE Transactions on Computers',6),(27233,NULL,'1987',NULL,'A Fast 1-D Serial-Parallel Systolic Multiplier','Based on the modified Booth\'s algorithm, a fast 1-D serial- parallel systolic multiplier is designed for multiplying two\'s complement numbers. The circuit with countercurrent data flow pattern accepts the multiplicand serially, the multiplier in parallel, and outputs the product serially. It requires a complementer and N/2 cells, each of which contains a ripple-carry adder and some gates, where N is restricted to even. The number of clocks required to multiply an n-bit (n = N) multiplier and an m-bit multiplicand is equal to n + m - 1, and independent of the circuit size N.',117351,'IEEE Transactions on Computers',8),(27234,NULL,'1987',NULL,'Bounding Signal Probabilities in Combinational Circuits','In [2] Savir, Ditlow, and Bardell presented an algorithm for estimating the signal probability of a line in combinational circuits, but were unable to show that the algorithm always produced correct results. This paper shows that their algorithm for cutting reconvergent fan-out lines in a circuit eventually produces a circuit without reconvergent fan- out that can be used to estimate signal probabilities in all lines of the original circuit.',117351,'IEEE Transactions on Computers',11),(27235,NULL,'1987',NULL,'Reliable High-Speed Arbitration and Synchronization','Numerous papers have discussed the behavior of flip-flops in synchrronization and arbitration circuits. Here, a nonconventional machine, which avoids completely synchronization failures by using metastability detectors in conjunction with a stretchable clock, is evaluated. The core of the paper focuses on the quantitative evaluation of the performance and reliability of this unconventional kind of machine. Only synchronization and arbitration failures are considered here, so when these machines are compared to conventional ones, all other factors affecting reliability and performance (e.g., technology, fabrication, etc.) are kept invariant. The MTBF\'s and a new normalized throughput measure show they can run substantially faster and more reliably than functionally equivalent, conventional machines with fixed clocks. Integrrated circuit implementations have been built and successfully tested.',117351,'IEEE Transactions on Computers',10),(27236,NULL,'1987',NULL,'New Connectivity and MSF Algorithms for Shuffle-Exchange Network and PRAM','Parallel algorithms for finding the connected components (CC) and a minimum spanning FOREST (MSF) of an undirected graph are presented. The primary model of computation considered is that called \"shuffle-exchange network\" in which each processor has its own local memory, no memory is shared, and communication among processors is done via a fixed degree network. This model is very convenient for actual realization. Both algorithms have depth of O(log2 n) while using n2 processors. Here n is the number of vertices in the graph. The algorithms are first presented for the PRAM (parallel RAM) model, which is not realizable, but much more convenient for the design and presentation of algorithms. The CC and MSF algorithms are no exceptions. The CC PRAM algorithm is a simplification of the one appearing in [17]. A modification of this algorithm yields a simple and efficient MSF algorithm. Both have depth of O(log m) and they use m processors, where m is the number of edges in the graph.',117351,'IEEE Transactions on Computers',9),(27240,NULL,'1987',NULL,'Adding time to synchronous process communications','In distributed real-time systems, communicating processes cannot be delayed for arbitrary amounts of time while waiting for messages. Thus, communication primitives used for real-time programming usually allow the inclusion of a deadline or timeout to limit potential delays due to synchronization. This paper interprets timed synchronous communication as having absolute deadlines. Various ways of implementing deadlines are discussed, and two useful timed synchronous communication problems are identified which differ in the number of participating senders and receivers and type of synchronous communication. For each problem, a simple algorithm is presented and shown to be correct. The algorithms are shown to guarantee maximal success and to require the smallest delay intervals during which processes wait for synchronous communication. We also evaluate the number of messages used to reach agreement.',117363,'IEEE Transactions on Computers - Special Issue on Real-Time Systems',0),(27242,NULL,'1987',NULL,'A graph-theoretic approach for timing analysis and its implementation','This paper presents a graph-theoretic algorithm for safety analysis of a class of timing properties in real-time systems which are expressible in a subset of real time logic (RTL) formulas. Our procedure is in three parts: the first part constructs a graph representing the system specification and the negation of the safety assertion. The second part detects positive cycles in the graph using a node removal operation. The third part determines the consistency of the safety assertion with respect to the system specification based on the positive cycles detected. The implementation and an application of this procedure will also be described.',117363,'IEEE Transactions on Computers - Special Issue on Real-Time Systems',2),(27786,NULL,'1987',NULL,'On Distributed Computations with Limited Resources','We consider two styles of executing a single job or an algorithm: either the job is subdivided into tasks, each of which is executed. on a separate processor, or the entire job is executed on a single processor, that has the same capacity as the sum of the processors in the earlier case. The algorithm is abstracted as consisting of a number of tasks with dependencies among them. Our model of dependencies among tasks allows sequential execution, parallel execution, synchronization, and spawning of tasks. The model assumes that the dependencies are known before the job begins, and a task in not preempted after its execution begins. With the usual assumptions such as exponential distribution of task execution times, and Poisson arrival of input data, we are able to show that the centralized execution completes the job faster than the decentralized execution only for a certain range of parameters of algorithms. We also give counterexamples that show that, contrary to popular belief, the reverse is true for some values of parameters of algorithms.',117351,'IEEE Transactions on Computers',0),(27787,NULL,'1987',NULL,'Measurement-Based Analysis of Error Latency','This paper demonstrates a practical methodology for the study of error latency under a real workload. The method is illustrated with sampled data on the physical memory activity, gathered by hardware instrumentation on a VAX 11/780 during the normal workload cycle of the installation. These data are used to simulate fault occurrence and to reconstruct the error discovery process in the system. The technique provides a means to study the system under different workloads and for multiple days. An approach to determine the percentage of undiscovered errors is also developed and a verification of the entire methodology is performed. This study finds that the mean error latency, in the memory containing the operating system, varies by a factor of 10 to 1 (in hours) between the low and high workloads. It is found that of all errors occurring within a day, 70 percent are detected in the same day, 82 percent within the following day, and 91 percent within the third day. The increase in failure rate due to latency is not so much a function of remaining errors but is dependent on whether or not there is a latent error.',117351,'IEEE Transactions on Computers',6),(27788,NULL,'1987',NULL,'A Generalized Theory for System Level Diagnosis','System-level diagnosis appears to be a viable alternative to circuit-level testing in complex multiprocessor systems. A completely new generalization of the characterization problem in the system-level diagnosis area is developed in this paper. This generalized characterization theorem provides necessary and sufficient conditions for any fault-pattern of any size to be uniquely diagnosable, under the symmetric, and asymmetric invalidation models with or without the intermittent faults. Moreover, it is also shown that the well known t-characterization theorems under these models can be derived as special cases. In addition to the generalization provided by these results, it is hoped that these results will also have a great impact on the diagnosis of faulty units in uniform structures based on the system-level diagnosis concepts and would be particularly useful in the diagnosis of WSI-oriented multiprocessor systems.',117351,'IEEE Transactions on Computers',6),(27789,NULL,'1987',NULL,'Deadlock-Free Message Routing in Multiprocessor Interconnection Networks','A deadlock-free routing algorithm can be generated for arbitrary interconnection networks using the concept of virtual channels. A necessary and sufficient condition for deadlock-free routing is the absence of cycles in a channel dependency graph. Given an arbitrary network and a routing function, the cycles of the channel dependency graph can be removed by splitting physical channels into groups of virtual channels. This method is used to develop deadlock-free routing algorithms for k-ary n-cubes, for cube-connected cycles, and for shuffle-exchange networks.',117351,'IEEE Transactions on Computers',7),(27790,NULL,'1987',NULL,'Modeling a Slotted Ring Local Area Network','Models for local area networks of the slotted ring style of architecture are developed and evaluated. The hardware protocol is modeled using a BCMP network. The Basic Block protocol of the Cambridge ring is modeled using an approximate solution method of the fixed-point type. A limited comparison between the Cambridge Ring and another ring architecture the token ring is carried out.',117351,'IEEE Transactions on Computers',7),(27791,NULL,'1987',NULL,'A Scheduling-Function-Based Distributed Access Protocol that Uses CDM to Relay Control Information in a Network with Hidden Nodes','We introduce a method for broadcasting control information (such as the information essential for correct operation of SOSAM and other scheduling-function-based access protocols) in stationary networks with \"hidden\" nodes (multihop networks). Control information is transmitted as short bit- parallel control messages on a separate control channel whose capacity is shared among the bits of a control message using code division multiplexing (CDM). The CDM method takes advantage of spread-spectrum signal properties that allow, in particular, high accuracy of time-of-arrival measurement and relatively easy separation of multipath copies of a control message.',117351,'IEEE Transactions on Computers',3),(27792,NULL,'1987',NULL,'A Partitioning Strategy for Nonuniform Problems on Multiprocessors','We consider the partitioning of a problem on a domain with unequal work estimates in different subdomains in a way that balances the workload across multiple processors. Such a problem arises for example in solving partial differential equations using an adaptive method that places extra grid points in certain subregions of the domain. We use a binary decomposition of the domain to partition it into rectangles requiring equal computational effort. We then study the communication costs of mapping this partitioning onto different multiprocessors: a mesh- connected array, a tree machine, and a hypercube. The communication cost expressions can be used to determine the optimal depth of the above partitioning.',117351,'IEEE Transactions on Computers',9),(27793,NULL,'1987',NULL,'Parallelization and Performance Analysis of the Cooley-Tukey FFT Algorithm for Shared-Memory Architectures','We present here a study of parallelization of the Cooley-Tukey radix two FFT algorithm for MIMD (nonvector) architectures. Parallel algorithms are presented for one and multidimensional Fourier transforms. From instruction traces obtained by executing Fortran kernels derived from our algorithms, we determined the precise instructions to be executed by each processor in the parallel system. We used these instruction races to predict the performance of the IBM Research Parallel Processing Prototype, RP3, as a computer of FFT\'s. Our performance results are depicted in graphs included in this paper.',117351,'IEEE Transactions on Computers',4),(27794,NULL,'1987',NULL,'Fault Propagation Through Embedded Multiport Memories','An analytical method is described for determining the random pattern testability of permanent faults in the prelogic driving the data-in and the address lines of a multiport random access memory whose outputs are directly observable. The results can be used with minimal extensions to existing detection probability tools such as the cutting algorithm.',117351,'IEEE Transactions on Computers',11),(27795,NULL,'1987',NULL,'Optimal Systolic Design for the Transitive Closure and the Shortest Path Problems','Due to VLSI technological progress, algorithm- oriented array architectures, such as systolic arrays, appear to be very effective, feasible, and economic. This paper discusses how to design systolic arrays for the transitive closure and the shortest path problems. We shall focus on the Warshall algorithm for the transitive closure problem and the Floyd algorithm for the shortest path problem. These two algorithms share exactly the same structural formulation; therefore, they lead to the same systolic array design. In this paper, we first present a general method for mapping algorithms to systolic arrays. Using this methodology, two new systolic designs for the Warshall-Floyd algorithm will be derived. The first one is a spiral array, which is easy to derive and can be further simplified to a hexagonal array. The other is an orthogonal systolic array which is optimal in terms of pipelining rate, block pipelining rate, and the number of input/output connections.',117351,'IEEE Transactions on Computers',9),(27796,NULL,'1987',NULL,'Complexity of Matrix Product on a Class of Orthogonally Connected Systolic Arrays','This correspondence studies the time complexity of the parallel computation of the product C = A.B of two dense square matrices A, B of order n, on a class of rectangular orthogonally connected systolic arrays, which are the two-dimensional extensions of the classical pipeline scheme. Such arrays are composed of multiply-add cells without local memory, and, as C is computed, the coefficients cij m',117351,'IEEE Transactions on Computers',8),(27797,NULL,'1987',NULL,'On an Optimally Fault-Tolerant Multiprocessor Network Architecture','This correspondence presents a class of optimally fault tolerant multiprocessor network architecture, based on the networks proposed earlier by Pradhan [71, where the networks are represented by regular digraphs. Because of optimal fault tolerapce, the number of connections per node is precisely related to the degree of fault tolerance the network is designed to provide. The routing of messgges in presence Qf faults is adaptive and unless the number of faults is equal to the degree of fault tolerance the increase in routing delay in presence of faults is minimal.',117351,'IEEE Transactions on Computers',7),(27798,NULL,'1987',NULL,'General Criterion for Essential Nonfault Locatability of Logical Functions','This correspondence presents a solution of a well-known essential problem of diagnostics open till now. The method of solution is based on a straight application of mathematical structures theory 1121, [11]and on a topological representation of Boolean algebras [ 1]l[1] [ 41] The principle idea of this approach is as follows. The distribution of diagnostic information is controlled in Boolean combinational circuits (CC) by two relations generally, the first is a congruence relation and the other is a tolerance relation. This fact is given by a real construction of CC. The Boolean calculus is evidently a formal interpretation of one of these relations only. Hence, the Boolean calculus cannot be used to solve entirely such problems which are related to this distribution. If we want to disclose the essence, we have to use a more general mathematical apparatus to interpret both relations mathematically. The outline of mathematical model of CC is presented and a trace of model on its underlying set is employed to solve the problem.',117351,'IEEE Transactions on Computers',2),(27799,NULL,'1987',NULL,'Design of Fast Self-Testing Checkers for a Class of Berger Codes','The Berger codes are optimal separable codes that detect all undirectional errors. In this correspondence a new procedure of designing self-testing checkers (STC\'s) for codes with I information bits, where I = {2K-2, 2K-l} and I = 3, is proposed. I = 3. The new checker is basically composed of u = ?(I + 1)/2? STC\'s for m-out-of-n codes with n = I + 1 and m = 2p + 1, O = p = u',117351,'IEEE Transactions on Computers',11),(27800,NULL,'1987',NULL,'A Solution to the Polynomial Hensel Code Conversion Problem','The polynomial Hensel code of a rational function a(x)/ b(x) ? F(x), F is a field, is the pair (c(x) d-1(x) mod Xr, n); r is a positive integer and a(x)/ b(x) = (c(x))xn such that c(x) and d(x) have nonzero constant terms. Such a representation scheme was proposed, in analogy with the Hensel code representations of rational numbers, to facilitate arithmetic operations on rational functions and control intermediate expressions well. The difficulty with this scheme was the conversion of such a code to rational function form. In this correspondence, we have given sufficient conditions under which this can be done and have described an algorithm for effecting the conversion. We have also discussed an application, namely, the reduction of a rational function to its simplest form.',117351,'IEEE Transactions on Computers',8),(27801,NULL,'1987',NULL,'Fault-Tolerant Single-Stage Interconnectiohl Networks','Single-stage Beta interconnection networks have been proposed for connecting processing elements in multiprocessing systems. An efficient data routing strategy has been designed. Faulty switching elements in the network can be automatically diagnosed. Its fault-tolerant capability is achieved by allowing data to recirculate the network several more passes with the presence of faults. Two parameters are taken into account to evaluate the network, i.e., communication delay d and degree of fault tolerance k. It has been shown elsewhere that k + 1 = d. We have derived, a class of single-stage Beta networks which have been shown to possess the optimal fault tolerance property, i.e., k = d -1.',117351,'IEEE Transactions on Computers',7),(27802,NULL,'1987',NULL,'Integer Division in Linear Time with Bounded Fan-In','A binary algorithm for division of an (M + N)-bit integer by an N-bit integer is presented. The algorithm produces the (M + 1)-bit quotient and the N-bit remainder in time O(M + N). Two hardware implementations, one using combinational logic in cellular arrays, and one employing systolic arrays, are given. These implementations are designed for modularity and regularity, and thus are suitable for VLSI systems. An important property of these implementations is that decisions are based on only one bit of the operands. Thus, fan-in and length of connecting wires are bounded independently of operand size. In addition, the systolic implementation has area O + N), which is the best possible.',117351,'IEEE Transactions on Computers',8),(30570,NULL,'1987',NULL,'Hardware architectures for programming languages and programming languages for hardware architectures','Programming Languages and Operating Systems introduce abstractions which allow the programmer to ignore details of an implementation. Support of an abstraction must not only concentrate on promoting the efficiency of an implementation, but also on providing the necessary guards against violations of the abstractions. In the frantic drive for efficiency the second goal has been neglected. There are indications that recent designs which are claimed to be both simple and powerful, achieve efficiency by shifting the complex issues of code generation and of appropriate guards onto compilers.Complexity has become the common hallmark of software as well as hardware designs. It cannot be mastered by the common practices of testing and simulation. Hardware design may profit from developments in programming methodology by adopting proof techniques similar to those used in programming.',34933,'ASPLOS II Proceedings of the second international conference on Architectual support for programming languages and operating systems',5),(30571,NULL,'1987',NULL,'VLSI assist for a multiprocessor','Multiprocessors have long been of interest to computer community. They provide the potential for accelerating applications through parallelism and increased throughput for large multi-user system. Three factors have limited the commercial success of multiprocessor systems; entry cost, range of performance, and ease of application. Advances in very large scale integration (VLSI) and in computer aided design (CAD) have removed these limitations, making possible a new class of multiprocessor systems based on VLSI components. A set of requirements for building an efficient shared multiprocessor system are discussed, including: low-level mutual exclusion, interrupt distribution, inter-processor signaling, process dispatching, caching, and system configuration. A system that meets these requirements is described and evaluated.',34933,'ASPLOS II Proceedings of the second international conference on Architectual support for programming languages and operating systems',5),(30576,NULL,'1987',NULL,'The effect of instruction set complexity on program size and memory performance','One potential disadvantage of a machine with a reduced instruction set is that object programs may be substantially larger than those for a machine with a richer, more complex instruction set. The main reason is that a small instruction set will require more instructions to implement the same function. In addition, the tendency of RISC machines to use fixed length instructions with a few instruction formats also increases object program size. It has been conjectured that the resulting larger programs could adversely affect memory performance and bus traffic. In this paper we report the results of a set of experiments to isolate and determine the effect of instruction set complexity on cache memory performance and bus traffic. Three high-level language compilers were constructed for machines with instruction sets of varying degrees of complexity. Using a set of benchmark programs, we evaluated the effect of instruction set complexity had on program size. Five of the programs were used to perform a set of trace-driven simulations to study each machine\'s cache and bus performance. While we found that the miss ratio is affected by object program size, it appears that this can be corrected by simplying increasing the size of the cache. Our measurements of bus traffic, however, show that even with large caches, machines with simple instruction sets can expect substantially more main memory reads than machines with dense object programs.',34933,'ASPLOS II Proceedings of the second international conference on Architectual support for programming languages and operating systems',4),(30579,NULL,'1987',NULL,'Cheap hardware support for software debugging and profiling','We wish to determine the effectiveness of some simple hardware for debugging and profiling compiled programs on a conventional processor. The hardware cost is small -- a counter decremented on each instruction that raises an exception when its value becomes zero. With the counter a debugger can provide data watchpoints and reverse execution: a profiler can measure the total instruction cost of a code segment and sample the program counter accurately. Such a counter has been included on a single-board MC68020 workstation, for which system software is currently being written. We will report our progress at the symposium.',34933,'ASPLOS II Proceedings of the second international conference on Architectual support for programming languages and operating systems',4),(30581,NULL,'1987',NULL,'Integer multiplication and division on the HP precision architecture','In recent years, many architectural design efforts have focused on maximizing performance for frequently executed, simple instructions. Although these efforts have resulted in machines with better average price/performance ratios, certain complex instructions and, thus, certain classes of programs which heavily depend on these instructions may suffer by comparison. Integer multiplication and division are one such set of complex instructions. This paper describes how a small set of primitive instructions combined with careful frequency analysis and clever programming allows the Hewlett-Packard Precision Architecture integer multiplication and division implementation to provide adequate performance at little or no hardware cost.',34933,'ASPLOS II Proceedings of the second international conference on Architectual support for programming languages and operating systems',4),(30582,NULL,'1987',NULL,'The Mahler experience: using an intermediate language as the machine description','Division of a compiler into a front end and a back end that communicate via an intermediate language is a well-known technique. We go farther and use the intermediate language as the official description of a family of machines with simple instruction sets and addressing capabilities, hiding some of the inconvenient details of the real machine from the users and the front end compilers.To do this credibly, we have had to hide not only the existence of the details but also the performance consequences of hiding them. The back end that compiles and links the intermediate language tries to produce code that does not suffer a performance penalty because of the details that were hidden from the front end compiler. To accomplish this, we have used a number of link-time optimizations, including instruction scheduling and interprocedural register allocation, to hide the existence of such idiosyncracies as delayed branches and non-infinite register sets. For the most part we have been sucessful.',34933,'ASPLOS II Proceedings of the second international conference on Architectual support for programming languages and operating systems',4),(30583,NULL,'1987',NULL,'A study of scalar compilation techniques for pipelined supercomputers','This paper studies two compilation techniques for enhancing scalar performance in high-speed scientific processors: software pipelining and loop unrolling. We study the impact of the architecture (size of the register file) and of the hardware (size of instruction buffer) on the efficiency of loop unrolling. We also develop a methodology for classifying software pipelining techniques. For loop unrolling, a straightforward scheduling algorithm is shown to produce near-optimal results when not inhibited by recurrences or memory hazards. Software pipelining requires less hardware but also achieves less speedup. Finally, we show that the performance produced with a modified CRAY-1S scalar architecture and a code scheduler utilizing loop unrolling is comparable to the performance achieved by the CRAY-1S with a vector unit and the CFT vectorizing compiler.',34933,'ASPLOS II Proceedings of the second international conference on Architectual support for programming languages and operating systems',4),(30592,NULL,'1987',NULL,'Pipelining and performance in the VAX 8800 processor','The VAX 8800 family (models 8800, 8700, 8550), currently the fastest computers in the VAX product line, achieve their speed through a combination of fast cycle time and deep pipelining. Rather than pipeline highly variable VAX instructions as such, the 8800 design pipelines uniform microinstructions whose addresses are generated by instruction unit hardware. This design approach helps achieve a fast cycle time, which is the prime determinan of performance. Some preliminary measurements of cycles per average instruction are reported.',34933,'ASPLOS II Proceedings of the second international conference on Architectual support for programming languages and operating systems',4),(31022,NULL,'1987',NULL,'Structure in the S-boxes of the DES','The S-boxes used in the DES are the major cryptographic component of the system. Any structure which they possess can have far reaching implications for the security of the algorithm. Structure may exist as a result of design principles intended to strengthen security. Structure could also exist as a \"trapdoor\" for breaking the system. This paper examines some properties which the S-boxes satisfy and attempts to determine a reason for such structure to exist.',195359,'Proceedings on Advances in cryptology---CRYPTO \'86',2),(31033,NULL,'1987',NULL,'How to prove yourself: practical solutions to identification and signature problems','In this paper we describe simple identification and signature schemes which enable any user to prove his identity and the authenticity of his messages to any other user without shared or public keys. The schemes are provably secure against any known or chosen message attack if factoring is difficult, and typical implementations require only 1% to 4% of the number of modular multiplications required by the RSA scheme. Due to their simplicity, security and speed, these schemes are ideally suited for microprocessor-based devices such as smart cards, personal computers, and remote control systems.',195359,'Proceedings on Advances in cryptology---CRYPTO \'86',3),(31045,NULL,'1987',NULL,'Implementing the Rivest Shamir and Adleman public key encryption algorithm on a standard digital signal processor','A description of the techniques employed at Oxford University to obtain a high speed implementation of the RSA encryption algorithm on an \"off-the-shelf\" digital signal processing chip. Using these techniques a two and a half second (average) encrypt time (for 512 bit exponent and modulus) was achieved on a first generation DSP (The Texas Instruments TMS 32010) and times below one second are achievable on second generation parts. Furthermore the techniques of algorithm development employed lead to a provably correct implementation.',195359,'Proceedings on Advances in cryptology---CRYPTO \'86',10),(31701,NULL,'1987',NULL,'Marching cubes: A high resolution 3D surface construction algorithm','We present a new algorithm, called marching cubes, that creates triangle models of constant density surfaces from 3D medical data. Using a divide-and-conquer approach to generate inter-slice connectivity, we create a case table that defines triangle topology. The algorithm processes the 3D medical data in scan-line order and calculates triangle vertices using linear interpolation. We find the gradient of the original data, normalize it, and use it as a basis for shading the models. The detail in images produced from the generated surface models is the result of maintaining the inter-slice connectivity, surface data, and gradient information present in the original 3D data. Results from computed tomography (CT), magnetic resonance (MR), and single-photon emission computed tomography (SPECT) illustrate the quality and functionality of marching cubes. We also discuss improvements that decrease processing time and add solid modeling capabilities.',216223,'SIGGRAPH \'87 Proceedings of the 14th annual conference on Computer graphics and interactive techniques',2),(31776,NULL,'1987',NULL,'Using idle workstations in a shared computing environment','The Butler system is a set of programs running on Andrew workstations at CMU that give users access to idle workstations. Current Andrew users use the system over 300 times per day. This paper describes the implementation of the Butler system and tells of our experience in using it. In addition, it describes an application of the system known as gypsy servers, which allow network server programs to be run on idle workstations instead of using dedicated server machines.',221234,'SOSP \'87 Proceedings of the eleventh ACM Symposium on Operating systems principles',5),(31790,NULL,'1987',NULL,'Log files: an extended file service exploiting write-once storage','A log service provides efficient storage and retrieval of data that is written sequentially (append-only) and not subsequently modified. Application programs and subsystems use log services for recovery, to record security audit trails, and for performance monitoring. Ideally, a log service should accommodate very large, long-lived logs, and provide efficient retrieval and low space overhead.In this paper, we describe the design and implementation of the Clio log service. Clio provides the abstraction of log files: readable, append-only files that are accessed in the same way as conventional files. The underlying storage medium is required only to be append-only; more general types of write access are not necessary. We show how log files can be implemented efficiently and robustly on top of such storage media—in particular, write-once optical disk.In addition, we describe a general application software storage architecture that makes use of log files.This work was supported in part by the Defense Advanced Research Projects Agency under contracts N00039-84-C-0211 and N00039-86-K-0431, by National Science Foundation grant DCR-83-52048, and by Digital Equipment Corporation, Bell-Northern Research and AT&T Information Systems.',221234,'SOSP \'87 Proceedings of the eleventh ACM Symposium on Operating systems principles',3),(32140,NULL,'1987',NULL,'COSMOS: a compiled simulator for MOS circuits','The COSMOS simulator provides fast and accurate switch-level modeling of MOS digital circuits. It attains high performance by preprocessing the transistor network into a functionally equivalent Boolean representation. This description, produced by the symbolic analyzer ANAMOS, captures all aspects of switch-level networks including bidirectional transistors, stored charge, different signal strengths, and indeterminate (X) logic values. The LGCC program translates the Boolean representation into a set of machine language evaluation procedures and initialized data structures. These procedures and data structures are compiled along with code implementing the simulation kernel and user interface to produce the simulation program. The simulation program runs an order of magnitude faster than our previous simulator MOSSIM II.',67540,'DAC \'87 Proceedings of the 24th ACM/IEEE Design Automation Conference',10),(32162,NULL,'1987',NULL,'Via minimization for gridless layouts','This paper describes a graph theoretic algorithm which, given a particular layout, finds a layer assignment that requires the minimum number of vias. The time complexity of the algorithm is &Ogr;(n3) where n is the number of routing segments in the given layout. Unlike previous algorithms, this algorithm does not require the layout to be grid based and places no constraints on the location of vias or the number of wires that may be joined at a single junction. The algorithm yields globally optimum results when the maximum junction degree is limited to three and has been fully implemented.',67540,'DAC \'87 Proceedings of the 24th ACM/IEEE Design Automation Conference',9),(32165,NULL,'1987',NULL,'Demand driven simulation: BACKSIM','A new digital simulation algorithm is presented based on the concept of demand driven simulation. Where traditional event driven simulation propagates signal values forward through a circuit in response to input pin events, demand driven simulation propagates requests for simulation values backwards both through the circuit and through time. In this manner, only those evaluations required to obtain “watched” signal values are performed. BACKSIM, the simulator based on this algorithm, has proven to be faster and more efficient than event driven simulation for every test case tried to date.',67540,'DAC \'87 Proceedings of the 24th ACM/IEEE Design Automation Conference',2),(32171,NULL,'1987',NULL,'A practical moat router','The final step in the layout of integrated circuits involves connecting a central module to a surrounding ring of pads. Hence the region to be routed is in the shape of a moat. This paper presents a practical approach to the moat routing problem. The approach is based on an efficient channel routing algorithm with additional features addressing the characteristics of the moat configuration. While signal nets are similar to those of a channel router, power nets are routed in a single layer of metal. The geometry of the moat imposes some restrictions, but often allows additional compaction of the routes. Each side of the moat requires a different amount of space to complete the routing, and each side of the pad ring may be moved independently. This produces an asymmetrical moat, which minimizes chip area and guarantees 100 percent routing completion.',67540,'DAC \'87 Proceedings of the 24th ACM/IEEE Design Automation Conference',7),(32173,NULL,'1987',NULL,'Accelerated transition fault simulation','This paper presents a new and an effective approach to fault simulation of transition faults in combinational or scan - based logic. An experiment with a set of benchmark circuits demonstrates the efficiency of the approach, achieved by combining a very fast single stuck - at fault simulation algorithm with a quasi - static definition of a transition fault. Tests that cover transition faults are becoming increasingly important as they also provide a cover for most typical transistor stuck - open faults in CMOS.',67540,'DAC \'87 Proceedings of the 24th ACM/IEEE Design Automation Conference',11),(32174,NULL,'1987',NULL,'On accuracy of switch-level modeling of bridging faults in complex gates','Bridging faults have been shown to be a major failure mode in VLSI devices. This study examines nMOS and CMOS complex gates in detail for bridging faults. Analysis is carried out using both switch and circuit level models for comparison. It is shown that in most cases, the switch level analysis predicts the correct behavior. A set of conditions are presented, under which the switch level analysis may fail to predict the correct behavior. These conditions can be used for accurate switch level test generation and simulation.',67540,'DAC \'87 Proceedings of the 24th ACM/IEEE Design Automation Conference',11),(32180,NULL,'1987',NULL,'Application of term rewriting techniques to hardware design verification','Term rewriting systems have been used in automatic theorem proving. A canonical term rewriting system for Boolean algebra recently discovered, and a refutation technique using Knuth-Bendix completion procedure can be used to prove Boolean formulas arising in logic verification. In this paper a design verification system based on term rewriting techniques is presented. It can prove total correctness of combinational circuits without exhaustive simulation. A prototype system implemented on a Motorola 68010 based workstation shows that the system performs favorably compared to a simulator.',67540,'DAC \'87 Proceedings of the 24th ACM/IEEE Design Automation Conference',2),(32181,NULL,'1987',NULL,'Logic verification algorithms and their parallel implementation','LOVER incorporates a novel approach to combinational logic verification and obtains good results when compared to existing techniques. In this paper we describe a new verification algorithm, LOVER-PODEM, whose enumeration phase is based on PODEM. A variant of LOVER-PODEM, called PLOVER, is presented. We have developed, for the first time, parallel logic verification schemes. Issues in efficiently parallelizing both general and specific LOVER-based approaches to logic verification over a large number of processors are addressed. We discuss parallelism inherent in the LOVER framework regardless of what enumeration and simulation algorithms are used. Since the enumeration phase is the efficiency bottleneck in parallelizing LOVER-based approaches, we have developed parallel versions of PODEM-based enumeration algorithms. Experimental results are presented to show that high processor utilization can be achieved when these parallelisms are exploited. Speed-up factors of over 7.8 have been achieved with 8 processor configurations.',67540,'DAC \'87 Proceedings of the 24th ACM/IEEE Design Automation Conference',10),(32191,NULL,'1987',NULL,'Finding the optimal variable ordering for binary decision diagrams','The ordered binary decision diagram is a canonical representation for Boolean functions, presented by Bryant as a compact representation for a broad class of interesting functions derived from circuits. However, the size of the diagram is very sensitive to the choice of ordering on the variables; hence for some applications, such as Differential Cascode Voltage Switch (DCVS) trees, it becomes extremely important to find the ordering leading to the most compact representation. We present an algorithm for this problem with time complexity O(n23n), an improvement over the previous best, which required O(n!2n).',67540,'DAC \'87 Proceedings of the 24th ACM/IEEE Design Automation Conference',1),(32199,NULL,'1987',NULL,'Circular self-test path: a low-cost BIST technique','A new technique for designing self-testing VLSI circuits, referred to as Circular Self-Test Path, is presented The Circular Self-Test Path is a feedback shift register (output of the last flip-flop is supplied to the first flip-flop) with a data compaction capability. A distinguishing attribute of self-testing chips designed using this technique is a low silicon area overhead, slightly exceeding that of scan path designs. A theoretical analysis and comprehensive simulation experiments we performed to demonstrate that the effectiveness of test pattern generation for the circular self-test path is comparable to that of an ideal pseudorandom test generator.',67540,'DAC \'87 Proceedings of the 24th ACM/IEEE Design Automation Conference',11),(32215,NULL,'1987',NULL,'An overview of the Penn State design system','This paper overviews a CAD system under development at Penn State which will allow fast and near optimal implementation of a restricted class of VLSI architectures. Our target architectures are hierarchical mesh extensions of systolic meshes. Our target applications are primarily in the signal processing domain. The primitive components, at the lowest level in the mesh hierarchy, are one of the unique features of our target architectures. The CAD system under development includes: a tool for target architecture decomposition into primitive components, a tool for multi-level logic reduction for the primitive components; a tool for automatic gate placement within a primitive component; a tool for component placement within the target architecture; a high-level simulation tool; and a layout verification tool.',67540,'DAC \'87 Proceedings of the 24th ACM/IEEE Design Automation Conference',10),(32233,NULL,'1987',NULL,'A parallel PLA minimization program','In this paper we report on an implementation of a parallel algorithm to minimize PLA realizations of logic functions. The algorithm is derived from a widely available PLA minimization program called ESPRESSO-MV. The parallel algorithm was implemented on a shared memory multicomputer system. In the course of development of the parallel algorithm, some changes were made to ESPRESSO-MV which resulted in lower computing time. Experimental results using 105 PLAs are included.',67540,'DAC \'87 Proceedings of the 24th ACM/IEEE Design Automation Conference',2),(32235,NULL,'1987',NULL,'PALMINI—fast Boolean minimizer for personal computers','This paper describes a fast and efficient method for minimization of two level single output Boolean functions. The minimization problem is reduced to that of coloring of the graph of incompatibility of implicants. The program permits also to remove static hazards and allows inversion of output\'s polarity which proves to be very convenient when designing with PAL\'s. It gives solutions within a very reasonable amount of time. On small industrial examples its speed is slightly better than Espresso and it occupies 6 times less memory.',67540,'DAC \'87 Proceedings of the 24th ACM/IEEE Design Automation Conference',2),(32250,NULL,'1987',NULL,'A dynamic programming approach to the test point insertion problem','The test point insertion problem is that of selecting t nodes in a combinational network as candidates for inserting observable test points, so as to minimize the number of test vectors needed to detect all single stuck-at faults in the network. In this paper we describe a dynamic programming approach to selecting the test points and provide an algorithm that inserts the test points optimally for fanout-free networks. We further extend this algorithm to general combinational networks with reconvergent fanout. We also analyze the time complexity of the algorithm and show that it runs in &Ogr;(n-t) time, where n is the size of the network and t is the number of test points to be inserted.As a side result we show that we can compute minimal test sets for a restricted class of networks that includes fanout. This extends previous results which were limited to fanout-free networks.',67540,'DAC \'87 Proceedings of the 24th ACM/IEEE Design Automation Conference',11),(32884,NULL,'1987',NULL,'A recovery algorithm for a high-performance memory-resident database system','With memory prices dropping and memory sizes increasing accordingly, a number of researchers are addressing the problem of designing high-performance database systems for managing memory-resident data. In this paper we address the recovery problem in the context of such a system. We argue that existing database recovery schemes fall short of meeting the requirements of such a system, and we present a new recovery mechanism which is designed to overcome their shortcomings. The proposed mechanism takes advantage of a few megabytes of reliable memory in order to organize recovery information on a per “object” basis. As a result, it is able to amortize the cost of checkpoints over a controllable number of updates, and it is also able to separate post-crash recovery into two phases—high-speed recovery of data which is needed immediately by transactions, and background recovery of the remaining portions of the database. A simple performance analysis is undertaken, and the results suggest our mechanism should perform well in a high-performance, memory-resident database environment.',216392,'SIGMOD \'87 Proceedings of the 1987 ACM SIGMOD international conference on Management of data',4),(32914,NULL,'1987',NULL,'Logical modeling of temporal data','In this paper we examine the semantics and develop constructs for temporal data independent of any traditional data model, such as the relational or network data models. Unlike many other works which extend existing models to support temporal data, our purpose is to characterize the properties of temporal data and operators over them without being influenced by traditional models which were not specifically designed to model temporal data. We develop data constructs that represent sequences of temporal values, identify their semantic properties, and define operations over these structures.',216392,'SIGMOD \'87 Proceedings of the 1987 ACM SIGMOD international conference on Management of data',2),(34897,NULL,'1987',NULL,'VLSI Architectures for multidimensional fourier transform processing','It is often desirable in modern signal processing applications to perform two-dimensional or three-dimensional Fourier transforms. Until the advent of VLSI it was not possible to think about one chip implementation of such processes. In this paper several methods for implementing the multidimensional Fourier transform together with the VLSI computational model are reviewed and discussed. We show that the lower bound for the computation of the multidimensional transform is O(n2 log2 n). Existing nonoptimal architectures suitable for implementing the 2-D transform, the RAM array transposer, mesh connected systolic array, and the linear systolic matrix vector multiplier are discussed for area time tradeoff. For achieving a higher degree of concurrency we suggest the use of rotators for permutation of data. With ``hybrid designs\'\' comprised of a rotator and one-dimensional arrays which compute the one-dimensional Fourier transform we propose two methods for implementation of multidimensional Fourier transform. One design uses the perfect shuffle for rotations and achieves an AT2p of O(n2 log2 n路 log2 N). An optimal architecture for calculation of multidimensional Fourier transform is proposed in this paper. It is based on arrays of processors computing one-dimensional Fourier transforms and a rotation network or rotation array. This architecture realizes the AT2p lower bound for the multidimensional FT processing.',117351,'IEEE Transactions on Computers',8),(34898,NULL,'1987',NULL,'Coherent cooperation among communicating problem solvers','When two or more computing agents work on interacting tasks, their activities should be coordinated so that they cooperate coherently. Coherence is particularly problematic in domains where each agent has only a limited view of the overall task, where communication between agents is limited, and where there is no ``controller\'\' to coordinate the agents. Our approach to coherent cooperation in such domains is developed in the context of a distributed problem-solving network where agents cooperate to solve a single problem. The approach stresses the importance of sophisticated local control by which each problem-solving node integrates knowledge of the problem domain with (meta-level) knowledge about network coordination. This allows nodes to make rapid, intelligent local decisions based on changing problem characteristics with only a limited amount of intercommunication to coordinate these decisions. We describe three mechanisms that improve network coherence: 1) an organizational structure that provides a long-term framework for network coordination to guide each node\'s local control decisions; 2) a planner at each node that develops sequences of problem-solving activities based on the current situation; and 3) meta-level communication about the current state of local problem solving that enables nodes to dynamically refine the organization. We present a variety of problem-solving situations to show the benefits and limitations of these mechanisms, and we provide simulation results showing the mechanisms to be particularly cost effective in more complex problem-solving situations. We also discuss how these mechanisms might be of more general use in other distributed computing applications.',117351,'IEEE Transactions on Computers',3),(34899,NULL,'1987',NULL,'Applications considerations in the system design of highly concurrent multiprocessors','A five-year series of studies, which ended in 1982 and which was supported in part by NASA and in part by Burroughs Corporation, led to the system design of a very large, very high-speed multiprocessor. This system was intended to solve large scientific problems, especially modeling problems such as those in computational aerodynamics. The performance objective was to sustain execution rates up to one billion floating-point operations per second with problems requiring 40 million words of main memory. The viability of this design depended on an in-depth understanding of the projected applications of the system. An overview of the project objectives and the resulting 128 processor design will be presented showing the local private memories available to each processor, the 64 million word shared memory, the dual-omega interconnection network, and the important programming concepts. During the design of the system, studies were conducted which determined the number of processors (a tradeoff with individual processor speed), the memory organization (program and data, private and shared), and the structure of the networks used to interconnect the processor and memory resources. These studies and the important application-related considerations are presented. Although this system was never constructed and tested, it was extensively simulated and the design was completed to sufficient detail to develop a reasonably accurate parts list and implementation plan.',117351,'IEEE Transactions on Computers',5),(34900,NULL,'1987',NULL,'On-line error-detectable high-speed multiplier using redundant binary representation and three-rail logic','An on-line error-detectable high-speed multiplier is described. It is based on the multiplication algorithm which we have previously proposed. In the algorithm, the redundant binary representation each of whose digits is 0, 1, or 驴1 is used. The multiplier consists of an input encoder, a multiplication block, and an error checker. The input encoder encodes each primary input bit into the 1-out-of-2 code. The multiplication block is designed by means of the three-rail logic. The three-rail logic is a logic design technique in which three mutually exclusive conditions calculated in a circuit are encoded in 1-out-of-3 code and the circuit is designed to be inverter-free. The error checker is a totally self-checking two-rail checker and produces a bit pair as an error indicator. The multiplier can perform n-bit multiplication in a time proportional to log2 n and has a regular cellular array structure suitable for VLSI implementation. Furthermore, we can detect any error caused by unidirectional stuck-at faults on gate output lines in normal operation by observing the error indicator. Many errors caused by other faults can be also detected. We can develop various on-line error-detectable high-speed arithmetic circuits using the redundant binary representation and the three-rail logic.',117351,'IEEE Transactions on Computers',8),(34901,NULL,'1987',NULL,'A characterization of ternary simulation of gate networks','Ternary simulation techniques provide efficient methods for the analysis of the behavior of VLSI circuits. However, the results of ternary simulation have not been completely characterized. In this paper we prove a somewhat modified version of the Brzozowski-Yoeli conjecture (stated in 1976) that the results of the ternary simulation of a gate network N correspond to the results of the binary race analysis of in the \"multiple-winner\" model, where - is the network N in which a delay has been inserted in each wire.',117351,'IEEE Transactions on Computers',6),(34902,NULL,'1987',NULL,'Optimal checkpointing of real-time tasks','Analytical models for the design and evaluation of checkpointing of real-time tasks are developed. First, the execution of a real-time task is modeled under a common assumption of perfect coverage of on-line detection mechanisms (which is termed a basic model). Then, the model is generalized (to an extended model) to include more realistic cases, i.e., imperfect coverages of on-line detection mechanisms and acceptance tests. Finally, we determine an optimal placement of checkpoints to minimize the mean task execution time while the probability of an unreliable result (or lack of confidence) is kept below a specified level. In the basic model, it is shown that equidistant intercheckpoint intervals are optimal, whereas this is not necessarily true in the extended model. An algorithm for calculating the optimal number of checkpoints and intercheckpoint intervals is presented with some numerical examples for the extended model.',117351,'IEEE Transactions on Computers',0),(34903,NULL,'1987',NULL,'The arithmetic cube','We present the design of a VLSI processor which can be programmed to compute the discrete Fourier transform of a sequence of n points and which achieves the theoretical AT2 lower bound of 驴(n2) for n 驴 n where n is an infinite set. Furthermore, since the set n is also sufficiently dense, the processor achieves for any n the theoretical AT2 lower bound of 驴(n2) for computing the cyclic convolution of two sequences of n points. Uniquely, our design achieves this bound without the use of data shuffling or long wires. Also, the processor uses only approximately 驴n multipliers, while many other designs need 驴(n) multipliers to achieve the same time bounds. Since multipliers are usually much larger than adders, the processor presented in this paper should be smaller. The design also features layout regularity, minimal control, and nearest neighbor interconnect of arithmetic cells of a few different types. These characteristics make it an ideal candidate for VLSI implementation.',117351,'IEEE Transactions on Computers',8),(34904,NULL,'1987',NULL,'An improved algorithm for constructing kth-order voronoi diagrams','The kth-order Voronoi diagram of a finite set of sites in the Euclidean plane E2 subdivides E2 into maximal regions such that all points within a given region have the same k nearest sites. Two versions of an algorithm are developed for constructing the kth-order Voronoi diagram of a set of n sites in O(n2 log n + k(n - k) log2 n) time, O(k(n - k)) storage, and in O(n2 + k(n - k) log2 n) time, O(n2) storage, respectively.',117351,'IEEE Transactions on Computers',9),(34905,NULL,'1987',NULL,'From determinacy to systaltic arrays','In this paper we extend a model of Karp and Miller for parallel computation. We show that the extended model is deterministic, in the sense that under different scheduling regimes each process in the computation consumes the same input and generates the same output. Moreover, if the computation halts, the final state is independent of scheduling. The model is applied to the generation of precedence graphs, from which lower time bounds may be deduced, and to the synchronization of systolic arrays by local rather than global control.',117351,'IEEE Transactions on Computers',9),(34906,NULL,'1987',NULL,'Decoding of DBEC-TBED Reed-Solomon codes','A problem in designing semiconductor memories is to provide some measure of error control without requiring excessive coding overhead or decoding time. In LSI and VLSI technology, memories are often organized on a multiple bit (or byte) per chip basis. For example, some 256K bit DRAM\'s are organized in 32K - 8 bit-bytes. Byte-oriented codes such as Reed-Solomon (RS) codes can provide efficient low overhead error control for such memories. However, the standard iterative algorithm for decoding RS codes is too slow for these applications. In this correspondence we present a special decoding technique for double-byte-error-correcting (DBEC), triple-byte-error-detecting (TBED) RS codes which is capable of high-speed operation. This technique is designed to find the error locations and the error values directly from the syndrome without having to use the iterative algorithm to find the error locator polynomial.',117351,'IEEE Transactions on Computers',8),(34907,NULL,'1987',NULL,'A hardwired generalized algorithm for generating the logarithm base-k by iteration','A number of previous works of computing the binary logarithm have been developed by a series of line approximations with moderate errors [1]-[3]. In this paper, a generalized iterative method for the logarithm of base-k evalution is proposed. We suggest that an integral constant k is used as a comparative index in each iteration. No table lookup is required. It can yield a more accurate and rapidly convergent value and can be easily implemented either by software or a hardwired device. A numerical example is illustrated for the process of calculation. The accuracy is analyzed and plotted by using two schemes, in which eight iteration cycle and 16 iteration cycle length are used, respectively.',117351,'IEEE Transactions on Computers',8),(34908,NULL,'1987',NULL,'Optimal parallel merging and sorting without memory conflicts','A parallel algorithm is described for merging two sorted vectors of total length N. The algorithm runs on a shared-memory model of parallel computation that disallows more than one processor to simultaneously read from or write into the same memory location. It uses k processors where l - k - N and requires O(N/k + log k - log N) time. The proposed approach for merging leads to a parallel sorting algorithm that sorts a vector of length N in O(log2 k + N/k) log N) time. Because they modify their behavior and hence their running time according to the number of available processors, the two new algorithms are said to be self-reconfiguring. In addition, both algorithms are optimal, for k - N/log2 N, in view of the (N) and (N log N) lower bounds on merging and sorting, respectively.',117351,'IEEE Transactions on Computers',9),(34909,NULL,'1987',NULL,'A generalization of hybrid fault diagnosability','A hybrid fault situation in a PMC system is a (bounded) combination of permanently and intermittently faulty units. Mallela and Masson [8] have given a general characterization of PMC systems for the diagnosis of hybrid fault situations. For this so-called th/thi diagnosability, when a syndrome takes on a form that is compatible with an allowable permanent fault situation, diagnosis can always be performed that is correct but perhaps incomplete. However, for general hybrid fault situations, syndromes that are compatible with permanent fault situations are exceedingly rare. Hence, th/thi diagnosability makes very limited use of the set of all syndromes that can result from application(s) of the test set. In this paper, a new, broader type of diagnosability for hybrid fault situations is defined and fully characterized. With this new type of diagnosability, at least all the permanently faulty units in a hybrid fault situation can be diagnosed from any syndrome that can result from an application of the test set. Thus, the usefulness of the syndrome space is dramatically increased. Special forms of this diagnosability are presented. Finally, relationships to other diagnosabilities are described.',117351,'IEEE Transactions on Computers',6),(34910,NULL,'1987',NULL,'An analytical model for a class of processor-memory interconnection networks','The performance of aa delta interconnection network for multiprocessors is evaluated in a circuit switching environment An error is pointed out in previous literature and an exact analytical model is given for regeneration systems, where a connection request is considered lost if not immediately granted. An approximated numerical method is suggested for the correction of the analytical results, which gave outputs in very good agreement with the simulation of real systems where requests are maintained.',117351,'IEEE Transactions on Computers',6),(34911,NULL,'1987',NULL,'Distributed fault-tolerance of tree structures','Tree structures, as the interconnection structure in networks of many processing elements, have interesting features such as regularity ease of expansion, simple routing, simple addressing, suitability for VLSI/WSI implementation, etc. Distributed fault tolerance of these networks is considered. It is assumed that in these structures, there does not exist any central failure-free entity for providing services such as diagnosis of faulty components, system reconfiguration after failure, control, or coordination among the processing elements. Every processing element is able to diagnose the condition of every other node or internode communication paths via a truly distributed scheme.',117351,'IEEE Transactions on Computers',7),(34912,NULL,'1987',NULL,'End-to-end flow control in computer networks with noisy channels and quasi-cut-through switching','Quasi-cut-through is a hybrid switching technique that has been recently proposed for computer networks. This paper deals with the end-to-end static flow control for computer networks using this hybrid switching technique. Two algorithms to handle the retransmissions of erroneous packets over noisy channels are analyzed and compared. Results are presented in terms of maximum user throughput, corresponding network delay, and power.',117351,'IEEE Transactions on Computers',7),(34913,NULL,'1987',NULL,'Time redundant fault-location in bit-sliced ALU\'s','A method of fault location in arithmetic and logic units (ALU\'s) is proposed. When the failures are confined to adjacent bit slices of the ALU\'s, the RESO (recomputing with shifted operands) based method can isolate the faulty bit slices by specifying a larger set of ``suspicious\'\' faulty bit slices, and, therefore, identify the definitely fault-free bit slices in ALU\'s. The method is applicable to both arithmetic and logic operations.',117351,'IEEE Transactions on Computers',8),(34914,NULL,'1987',NULL,'On error indication for totally self-checking systems','Different ways of defining a totally self-checking system are discussed. Based on the discussion, a self-testing error indicator is defined and shown to provide a useful means to ensure concurrent error detection for fault-tolerant systems. A simple design for the self-testing error indicator is presented.',117351,'IEEE Transactions on Computers',6),(34915,NULL,'1987',NULL,'Processor allocation in an N-cube multiprocessor using gray codes','The processor allocation problem in an n-dimensional hypercube (or an n-cube) multiprocessor is similar to the conventional memory allocation problem. The main objective in both problems is to maximize the utilization of available resources as well as minimize the inherent system fragmentation. A processor allocation strategy using the buddy system, called the buddy strategy, is discussed first and then a new allocation strategy using a Gray code (GC), called the GC strategy, is proposed. When processor relinquishment is not considered (i.e., static allocation), both of these strategies are proved to be optimal in the sense that each incoming request sequence is always assigned to a minimal subcube. It is also shown that the GC strategy outperforms the buddy strategy in detecting the availability of subcubes. Our results are extended further to implement an allocation strategy using more than one GC and derive the relationship between the GC\'s used and the corresponding ability of detecting the availability of various subcubes. The minimal number of GC\'s required for complete subcube recognition in a Qn is proved to be less than or equal to C[n/2]n. Several processor allocation strategies in a Q5 are implemented on the NCUBE/six multiprocessor at the University of Michigan, and their performance is experimentally measured.',117351,'IEEE Transactions on Computers',0),(34916,NULL,'1987',NULL,'Nearest-neighbor mapping of finite element graphs onto processor meshes','The processor allocation problem is addressed in the context of the parallelization of a finite element modeling program on a processor mesh. A heuristic two-step, graph-based mapping scheme with polynomial-time complexity is developed: 1) initial generation of a graph partition for nearest-neighbor mapping of the finite element graph onto the processor graph, and, 2) a heuristic boundary refinement procedure to incrementally alter the initial partition for improved load balancing among the processors. The effectiveness of the approach is gaged both by estimation using a model with empirically determined parameters, as well as implementation and experimental measurement on a 16 node hypercube parallel computer.',117351,'IEEE Transactions on Computers',9),(34917,NULL,'1987',NULL,'Guided self-scheduling: A practical scheduling scheme for parallel supercomputers','This paper proposes guided self-scheduling, a new approach for scheduling arbitrarily nested parallel program loops on shared memory multiprocessor systems. Utilizing loop parallelism is clearly most crucial in achieving high system and program performance. Because of its simplicity, guided self-scheduling is particularly suited for implementation on real parallel machines. This method achieves simultaneously the two most important objectives: load balancing and very low synchronization overhead. For certain types of loops we show analytically that guided self-scheduling uses minimal overhead and achieves optimal schedules. Two other interesting properties of this method are its insensitivity to the initial processor configuration (in time) and its parameterized nature which allows us to tune it for different systems. Finally we discuss experimental results that clearly show the advantage of guided self-scheduling over the most widely known dynamic methods.',117351,'IEEE Transactions on Computers',0),(34918,NULL,'1987',NULL,'Vector access performance in parallel memories using skewed storage scheme','The degree to which high-speed vector processors approach their peak performance levels is closely tied to the amount of interference they encounter while accessing vectors in memory. In this paper we present an evaluation of a storage scheme that reduces the average memory access time in a vector-oriented architecture. A skewing scheme is used to map vector components into parallel memory modules such that, for most vector access patterns, the number of memory conflicts is reduced over that observed in interleaved parallel memory systems. Address and data buffers are used locally in each module so that transient nonuniformities which occur in some access patterns do not degrade performance. Previous investigations into skewing techniques have attempted to provide conflict-free access for a limited subset of access patterns. The goal of this investigation is different. The skewing scheme evaluated here does not eliminate all memory conflicts but it does improve the average performance of vector access over interleaved systems for a wide range of strides. It is shown that little extra hardware is required to implement the skewing scheme. Also, far fewer restrictions are placed on the number of memory modules in the system than are present in other proposed schemes.',117351,'IEEE Transactions on Computers',4),(34919,NULL,'1987',NULL,'Hypernet: A communication-efficient architecture for constructing massively parallel computers','A new class of modular networks is proposed for hierarchically constructing massively parallel computer systems for distributed supercomputing and AI applications. These networks are called hypernets. They are constructed incrementally with identical cubelets, treelets, or buslets that are well suited for VLSI implementation. Hypernets integrate positive features of both hypercubes and tree-based topologies, and maintain a constant node degree when the network size increases. This paper presents the principles of constructing hypernets and analyzes their architectural potentials in terms of message routing complexity, cost-effective support for global as well as localized communication, I/O capabilities, and fault tolerance. Several algorithms are mapped onto hypernets to illustrate their ability to support parallel processing in a hierarchically structured or data-dependent environment. The emulation of hypercube connections using less hardware is shown. The potential of hypernets for efficient support of connectionist models of computation is also explored.',117351,'IEEE Transactions on Computers',3),(34920,NULL,'1987',NULL,'Matrix operations on a multicomputer system with switchable main memory modules and dynamic control','This paper presents an analysis and evaluation of the performance of a multicomputer system (SM3) in supporting two basic matrix operations, namely multiplication and inversion. The system supports the efficient execution of the above mentioned operations by 1) achieving a high-bandwidth data transfer among computers by switching main memory modules, 2) supporting network partitioning, 3) employing a hardware communication and synchronization scheme, 4) using a distributed control technique, and 5) providing means to dynamically transfer control. Timing equations are derived and evaluated in an attempt to analyze the performance. Different cases which arise due to the relative sizes of memory modules and matrices during matrix multiplication are analyzed. The cases of partial and maximal pivoting during inversion are also analyzed. The SM3 system is compared quantitatively and qualitatively to a hypercube architecture.',117351,'IEEE Transactions on Computers',4),(34921,NULL,'1987',NULL,'Compiler algorithms for synchronization','Translating program loops into a parallel form is one of the most important transformations performed by concurrentizing compilers. This transformation often requires the insertion of synchronization instructions within the body of the concurrent loop. Several loop synchronization techniques are presented first. Compiler algorithms to generate synchronization instructions for singly-nested loops are then discussed. Finally, a technique for the elimination of redundant synchronization instructions is presented.',117351,'IEEE Transactions on Computers',2),(34922,NULL,'1987',NULL,'Checkpoint repair for high-performance out-of-order execution machines','Out-or-order execution and branch prediction are two mechanisms that can be used profitably in the design of supercomputers to increase performance. Proper exception handling and branch prediction miss handling in an out-of-order execution machine do require some kind of repair mechanism which can restore the machine to a known previous state. In this paper we present a class of repair mechanisms using the concept of checkpointing. We derive several properties of checkpoint repair mechanisms. In addition, we provide algorithms for performing checkpoint repair that incur little overhead in time and modest cost in hardware. We also note that our algorithms require no additional complexity or time for use with write-back cache memory systems than they do with write-through cache memory systems, contrary to statements made by previous researchers.',117351,'IEEE Transactions on Computers',4),(34923,NULL,'1987',NULL,'Incorporating data flow ideas into von neumann processors for parallel execution','The issues of memory latency, synchronization, and distribution costs in multiprocessors are reviewed. The approaches taken by conventional and data flow architectures are contrasted in relation to these issues. It is pointed out that each approach fits well for a certain situation and that it is possible to have a common framework in which the two execution models can be mixed to suit the situation. An architecture is sketched by describing a few extensions to a conventional processor. While existing programs run without much change, it is shown that improvements could be made by using the new features to tolerate memory latency and to exploit more parallelism. It is shown that data flow graphs can be executed on this to exploit as much parallelism as a data flow architecture could. It is argued that such a testbed will provide for a selective translation of program segments into the appropriate execution model. A fast context switching hardware is presumed for this architecture.',117351,'IEEE Transactions on Computers',4),(34924,NULL,'1987',NULL,'The warp computer: Architecture, implementation, and performance','The Warp machine is a systolic array computer of linearly connected cells, each of which is a programmable processor capable of performing 10 million floating-point operations per second (10 MFLOPS). A typical Warp array includes ten cells, thus having a peak computation rate of 100 MFLOPS. The Warp array can be extended to include more cells to accommodate applications capable of using the increased computational bandwidth. Warp is integrated as an attached processor into a Unix host system. Programs for Warp are written in a high-level language supported by an optimizing compiler. The first ten-cell prototype was completed in February 1986; delivery of production machines started in April 1987. Extensive experimentation with both the prototype and production machines has demonstrated that the Warp architecture is effective in the application domain of robot navigation as well as in other fields such as signal processing, scientific computation, and computer vision research. For these applications, Warp is typically several hundred times faster than a VAX 11/780 class computer. This paper describes the architecture, implementation, and performance of the Warp machine. Each major architectural decision is discussed and evaluated with system, software, and application considerations. The programming model and tools developed for the machine are also described. The paper concludes with performance data for a large number of applications.',117351,'IEEE Transactions on Computers',5),(35447,NULL,'1987',NULL,'Design of a Functionally Distributed, Multiprocessor Database Machine Using Data Flow Analysis','We propose a design methodology based on data flow analysis for a functionally distributed, multiprocessor database machine. We define a cost model of database processing with the objective cost being response time of a set of query strategies. Heuristic optimization techniques are proposed using the operations of grouping, decomposition, and replication. We apply the new optimization techniques in several realistic multiprocessor environments. The resulting configurations of multiprocessors demonstrate significant performance improvements over more traditional designs.',117351,'IEEE Transactions on Computers',5),(35448,NULL,'1987',NULL,'Task Allocation and Precedence Relations for Distributed Real-Time Systems','In a distributed processing system with the application software partitioned into a set of program modules, allocation of those modules to the processors is an important problem. This paper presents a method for optimal module allocation that satisfies certain performance constraints. An objective function that includes the intermodule communication (IMC) and accumulative execution time (AET) of each module is proposed. It minimizes the bottleneck-processor utilization a good principle for task allocation. Next, the effects of precedence relationship (PR) among program modules on response time are studied. Both simulation and analytical results reveal that the program-size ratio between two consecutive modules plays an important role in task response time. Finally, an algorithm based on PR, AET, and IMC and on the proposed objective function is presented. This algorithm generates better module assignments than those that do not consider the PR effects.',117351,'IEEE Transactions on Computers',0),(35449,NULL,'1987',NULL,'A Characterization and Analysis of Parallel Processor Interconnection Networks','The permuting properties of various interconnection networks have been extensively studied. However, not too much attention has been focused on how the permuting properties interact with the mapping of tasks to processors in realizing the communication requirements between tasks. In this paper we focus on characterizing the abilities of some interconnection networks in realizing intertask communication that can be specified as permutations of the task names. From the point of view of the intertask communications requirements, the perceived permuting capabilities may depend upon the specific assignment of tasks to processors. Distinct network permutations may actually result in equivalent intertask communication patterns depending upon the mapping of tasks to processors. Characterizations of networks are developed based upon the theory of permutation groups. A number of properties as well as limitations of these networks become evident from this characterization. Finally, a class of switching networks is identified, that possess many useful properties that make them preferable to multistage interconnection networks in specific applications.',117351,'IEEE Transactions on Computers',7),(35450,NULL,'1987',NULL,'Analysis of a New Retransmission Control Algorithm for Slotted CSMA/CD LAN\'s','Algorithms for the control of the retransmission procedure in random multiple access schemes are needed to ensure stability of the system operation under high traffic conditions. Optimal retransmission control policies cannot be applied in practice since they are based on global information about the system state. In the case of the most well-known implementation of the CSMA/CD protocol, ANSI/IEEE Std 802.3-1985, a heuristic approach, known as the \"truncated binary exponential backoff\" algorithm, is employed. Such schemes are not amenable to theoretical analysis because of the state space. explosion problem of the underlying Markovian model. In this paper, a new retransmission control algorithm, suitable for CSMA/CD protocols, based on information acquired by monitoring the channel transmissions is proposed. A Markovian model is presented and the algorithm is analyzed in detail. The performance of the algorithm is evaluated, several numerical and simulation results are presented and comparisons to other protocols are made.',117351,'IEEE Transactions on Computers',2),(35451,NULL,'1987',NULL,'Discrete Optimization Problem in Local Networks and Data Alignment','This paper presents the solution of the following optimization problem that appears in the design of double-loop structures for local networks and also in data memory, allocation and data alignment in SIMD processors.',117351,'IEEE Transactions on Computers',3),(35453,NULL,'1987',NULL,'Distributed Nodes Organization Algorithm for Channel Access in a Multihop Dynamic Radio Network','This paper proposes a solution to providing a collision free channel allocation in a multihop mobile radio network. An efficient solution to this problem provides spatial reuse of the bandwidth whenever possible. A robust solution maintains the collision free property of the allocation under any combination of topological changes. The node organization algorithm presented in this paper provides a completely distributed, maximally localized execution of collision free channel allocation. It allows for parallel channel allocation in stationary and mobile networks with provable spatial reuse properties. A simpler version of the algorithm provides also a highly localized distributed coloring algorithm of dynamic graphs.',117351,'IEEE Transactions on Computers',3),(35454,NULL,'1987',NULL,'Evaluation of Performability for Degradable Computer Systems','The performability of degradable heterogeneous computer systems containing k 1 types of components is considered. Previous analyses of such systems have been numerical in nature and yielded algorithms with either exponential complexity in the number of system states n, or polynomial in n with approximate truncations of infinite series. In this paper, a closed form expression for the performability of degradable heterogeneous systems is derived. Furthermore, an algorithm with polynomial complexity, O(kn3), is presented and applied to study the performability of a multiprocessor computer system.',117351,'IEEE Transactions on Computers',2),(35455,NULL,'1987',NULL,'Minimum-Area Wiring for Slicing Structures','In this paper we consider the problem of optimal wiring of VLSI circuits. The topological placement of the circuit elements (macros) on the chip is assumed to have a special hierarchical structure, i.e., to be a slicing floorplan, represented by a binary (slicing) tree. Instead of the usual objective of minimum wire length, we consider the problem of minimizing the overall area of the wired floorplan. For the case of a single multiterminal net connecting n macros, we obtain a wiring algorithm of complexity O(nd), where d is the depth of the slicing tree. The case of several multiterminal nets is still under investigation.',117351,'IEEE Transactions on Computers',9),(35456,NULL,'1987',NULL,'Effective Memory Bandwidth and Processor Blocking Probability in Multiple-Bus Systems','This correspondence presents two expressions in calculating effective memory bandwidth for a wide range of multiple-bus configurations. Also presented is an analytical solution for determining each processor\'s blocking probability in a multiple-bus system where different priorities are assigned to the processors.',117351,'IEEE Transactions on Computers',4),(35457,NULL,'1987',NULL,'Implementing Exact Calculations in Hardware','A technique for performing exact calculations it discussed. The technique uses single-modulus P arithmetic to perform calculations over the finite field of integers and the finite ring of integers. It is shown that the arithmetic operations modulo P (which obviously can be impleinented in microprocessor configurations, VLSI, and/or software) can easily be extended from the range of values of the finite field of integers, modulo P, to the finite ring of integers, modulo pN where N is afny positive integer. This technique can be used for exact calculations over the rational numbers as well as complex numbers. Examples, block diagrams, And processor arrays are presented illustrating the simplicity of these operations.',117351,'IEEE Transactions on Computers',8),(35458,NULL,'1987',NULL,'A New Benes Network Control Algorithm','A new Benes network control algorithm is presented. Unlike the original looping algorithm, the new algorithm is not recursive. In this algorithm (N x N) Benes network is viewed as a concatenation of two subnetworks SN1 and SN2. The first (log N - 1) stages of a Benes network correspond to SN1, and the remaining log N stages correspond to SN2. SN1 is controlled by a full binary tree of set partitioning functions, called a Complete Residue Partition Tree, and SN2 is bit controlled. The new control algorithm sets switches one stage at a time, stage by stage.',117351,'IEEE Transactions on Computers',9),(35885,NULL,'1987',NULL,'Optimal shortest path queries in a simple polygon','Let P be a simple polygon with n sides. This paper shows how to preprocess the polygon so that, given two query points p and q inside P, the length of the shortest path inside the polygon from p to q can be found in time &Ogr;(log n). The path itself must be polygonal and can be extracted in additional time proportional to the number of turns it makes. The preprocessing consists of triangulation plus a linear amount of additional work.',211171,'SCG \'87 Proceedings of the third annual symposium on Computational geometry',9),(35903,NULL,'1987',NULL,'An optimal algorithm for constructing the Delaunay triangulation of a set of line segments','In this paper, we first define a new Voronoi diagram for the endpoints of a set of line segments in the plane which do not intersect (except possibly at their endpoints), which is called a bounded Voronoi diagram. In this Voronoi diagram, the line segments themselves are regarded as obstacles. We present an optimal &THgr;(n log n) algorithm to construct it, where n is the number of input line segments.We then show that the straight-line dual of the bounded Voronoi diagram of a set of non-intersecting line segments is the Delaunay triangulation of that set. And the straight-line dual can be obtained in time proportional to the number of input line segments when the corresponding bounded Voronoi diagram is available. Consequently, we obtain an optimal &THgr;(n log n) algorithm to construct the Delaunay triangulation of a set of n non-intersecting line segments in the plane. Our algorithm improves the time bound &Ogr;(n2) of the previous best algorithm.',211171,'SCG \'87 Proceedings of the third annual symposium on Computational geometry',9),(35909,NULL,'1987',NULL,'Fast algorithms for computing the largest empty rectangle','We provide two algorithms for solving the following problem: Given a rectangle containing n points, compute the largest-area and the largest-perimeter subrectangles with sides parallel to the given rectangle that lie within this rectangle and that do not contain any points in their interior. For finding the largest-area empty rectangle, the first algorithm takes &Ogr;(n log3 n) time and &Ogr;(n) memory space and it simplifies the algorithm given by Chazelle, Drysdale and Lee which takes &Ogr;(n log3 n) time but &Ogr;(n log n) storage. The second algorithm for computing the largest-area empty rectangle is more complicated but it only takes &Ogr;(n log2 n) time and &Ogr;(n) memory space. The two algorithms for computing the largest-area rectangle can be modified to compute the largest-perimeter rectangle in &Ogr;(n log2 n) and &Ogr;(n log n) time, respectively. Since &OHgr;(n log n) is a lower bound on time for computing the largest-perimeter empty rectangle, the second algorithm for computing such a rectangle is optimal within a multiplicative constant.',211171,'SCG \'87 Proceedings of the third annual symposium on Computational geometry',9),(35938,NULL,'1987',NULL,'Fast object partitioning using Stochastic learning automata','Let &OHgr; = {A1, …, AW} be a set of W objects to be partitioned into R classes {P1, …, PR}. The objects are accessed in groups of unknown size and the size of these groups need not be equal. Additionally, the joint access probabilities of the objects are unknown. The intention is that the objects accessed more frequently together are located in the same class. This problem has been shown to be NP-hard [15, 16]. In this paper, we propose two stochastic learning automata solutions to the problem. Although the first one is relatively fast, its accuracy is not so remarkable in some environments. The second solution, which uses a new variable structure stochastic automation, demonstrates an excellent partitioning capability. Experimentally, this solution converges an order of magnitude faster than the best known algorithm in the literature [15, 16].',216304,'SIGIR \'87 Proceedings of the 10th annual international ACM SIGIR conference on Research and development in information retrieval',2),(36101,NULL,'1988',NULL,'Fine-grained mobility in the Emerald system','Emerald is an object-based language and system designed for the construction of distributed programs. An explicit goal of Emerald is support for object mobility; objects in Emerald can freely move within the system to take advantage of distribution and dynamically changing environments. We say that Emerald has fine-grained mobility because Emerald objects can be small data objects as well as process objects. Fine-grained mobility allows us to apply mobility in new ways but presents implementation problems as well. This paper discusses the benefits of tine-grained mobility, the Emerald language and run-time mechanisms that support mobility, and techniques for implementing mobility that do not degrade the performance of local operations. Performance measurements of the current implementation are included.',16295,'ACM Transactions on Computer Systems (TOCS)',5),(36136,NULL,'1987',NULL,'Randomized parallel communications on an extension of the omega network','Parallel communication algorithms and networks are central to large-scale parallel computing and, also, data communications. This paper identifies adverse source-destination traffic patterns and proposes a scheme for obtaining relief by means of randomized routing of packets on simple extensions of the well-known omega networks. Valiant and Aleliunas have demonstrated randomized algorithms, for a certain context which we call nonrenewal, that complete the communication task in time O(log N) with overwhelming probability, where N is the number of sources and destinations. Our scheme has advantages because it uses switches of fixed degree, requires no scheduling, and, for the nonrenewal context, is as good in proven performance. The main advantage of our scheme comes when we consider the renewal context in which packets are generated at the sources continually and asynchronously. Our algorithm extends naturally from the nonrenewal context. In the analysis in the renewal context we, first, explicitly identify the maximum traffic intensities in the internal links of the extended omega networks over all source-destination traffic specifications that satisfy loose bounds. Second, the benefits of randomization on the stability of the network are identified. Third, exact results, for certain restricted models for sources and transmission, and approximate analytic results, for quite general models, are derived for the mean delays. These results show that, in the stable regime, the maximum mean time from source to destination is asymptotically proportional to log N. Numerical results are presented.',135870,'Journal of the ACM (JACM)',7),(36137,NULL,'1987',NULL,'Design and analysis of dynamic Huffman codes','A new one-pass algorithm for constructing dynamic Huffman codes is introduced and analyzed. We also analyze the one-pass algorithm due to Faller, Gallager, and Knuth. In each algorithm, both the sender and the receiver maintain equivalent dynamically varying Huffman trees, and the coding is done in real time. We show that the number of bits used by the new algorithm to encode a message containing t letters is t bits more than that used by the conventional two-pass Huffman scheme, independent of the alphabet size. This is best possible in the worst case, for any one-pass Huffman method. Tight upper and lower bounds are derived. Empirical tests show that the encodings produced by the new algorithm are shorter than those of the other one-pass algorithm and, except for long messages, are shorter than those of the two-pass method. The new algorithm is well suited for on-line encoding/decoding in data networks and for tile compression.',135870,'Journal of the ACM (JACM)',9),(36179,NULL,'1988',NULL,'A theory of reliability in database systems','Reliable concurrent processing of transactions in a database system is examined. Since serializability, the conventional concurrency control correctness criterion, is not adequate in the presence of common failures, another theory of correctness is proposed, involving the concepts of commit serializability, recoverability, and resiliency.',135870,'Journal of the ACM (JACM)',5),(36195,NULL,'1988',NULL,'An extended set of FORTRAN basic linear algebra subprograms','This paper describes an extension to the set of Basic Linear Algebra Subprograms. The extensions are targeted at matrix-vector operations that should provide for efficient and portable implementations of algorithms for high-performance computers.',16407,'ACM Transactions on Mathematical Software (TOMS)',2),(36246,NULL,'1988',NULL,'ACE: an automatic complexity evaluator','There has been a great deal of research done on the evaluation of the complexity of particular algorithms; little effort, however, has been devoted to the mechanization of this evaluation. The ACE (Automatic Complexity Evaluator) system is able to analyze reasonably large programs, like sorting programs, in a fully mechanical way. A time-complexity function is derived from the initial functional program. This function is transformed into its nonrecursive equivalent according to MacCarthy\'s recursion induction principle, using a predefined library of recursive definitions. As the complexity is not a decidable property, this transformation will not be possible in all cases. The richer the predefined library is, the more likely the system is to succeed. The operations performed by ACE are described and the use of the system is illustrated with the analysis of a sorting algorithm. Related works and further improvements are discussed in the conclusion.',16444,'ACM Transactions on Programming Languages and Systems (TOPLAS)',2),(36295,NULL,'1988',NULL,'Distributed programming in Argus','Argus—a programming language and system developed to support the implementation and execution of distributed programs—provides mechanisms that help programmers cope with the special problems that arise in distributed programs, such as network partitions and crashes of remote nodes.',52621,'Communications of the ACM',5),(36296,NULL,'1988',NULL,'The V distributed system','The V distributed System was developed at Stanford University as part of a research project to explore issues in distributed systems. Aspects of the design suggest important directions for the design of future operating systems and communication systems.',52621,'Communications of the ACM',5),(36299,NULL,'1988',NULL,'Practical in-place merging','We present a novel, yet straightforward linear-time algorithm for merging two sorted lists in a fixed amount of additional space. Constant of proportionality estimates and empirical testing reveal that this procedure is reasonably competitive with merge routines free to squander unbounded additional memory, making it particularly attractive whenever space is a critical resource.',52621,'Communications of the ACM',9),(36304,NULL,'1988',NULL,'Computing Poisson probabilities','We propose an algorithm to compute the set of individual (nonnegligible) Poisson probabilities, rigorously bound truncation error, and guarantee no overflow or underflow. Work and space requirements are modest, both proportional to the square root of the Poisson parameter. Our algorithm appears numerically stable. We know no other algorithm with all these (good) features. Our algorithm speeds generation of truncated Poisson variates and the computation of expected terminal reward in continuous-time, uniformizable Markov chains. More generally, our algorithm can be used to evaluate formulas involving Poisson probabilities.',52621,'Communications of the ACM',9),(37967,NULL,'1988',NULL,'On real-time transactions','Next generation real-time systems will require greater flexibility and predictability than is commonly found in today\'s systems. These future systems include the space station, integrated vision/robotics/AI systems, collections of humans/robots coordinating to achieve common objectives (usually in hazardous environments such as undersea exploration or chemical plants), and various command and control applications. The complexity of such systems due to timing constraints, concurrency, and distribution is high. It is accepted that the synchronization, failure atomicity, and permanence properties of transactions aid in the development of distributed systems. However, little work has been done in exploiting transactions in a real-time context. We have been attempting to categorize real-time data into classes depending on their time, synchronization, atomicity, and permanence properties. Then, using the semantics of the data and the applications, we are developing special, tailored, real-time transactions that only supply the minimal properties necessary for that class. This reduces the system overhead in supporting access to various types of data. The eventual goal is to verify that timing requirements can be met.',16097,'ACM SIGMOD Record - Special Issue on Real-Time Database Systems',0),(37972,NULL,'1988',NULL,'Scheduling real-time transactions','Scheduling transactions with real-time requirements presents many new problems. In this paper we discuss solutions for two of these problems: what is a reasonable method for modeling real-time constraints for database transactions? Traditional hard real-time constraints (e.g., deadlines) may be too limited. May transactions have soft deadlines and a more flexible model is needed to capture these soft time constraints. The second problem we address is scheduling. Time constraints add a new dimension to concurrency control. Not only must a schedule be serializable but it also should meet the time constraints of all the transactions in the schedule.',16097,'ACM SIGMOD Record - Special Issue on Real-Time Database Systems',0),(38223,NULL,'1988',NULL,'The reduction of perturbed Markov generators: an algorithm exposing the role of transient states','A new algorithm for the hierarchical aggregation of singularly perturbed finite-state Markov processes is derived. The approach taken bridges the gap between conceptually simple results for a relatively restricted class of processes and the significantly more complex results for the general case. The critical role played by (almost) transient states is exposed, resulting in a straightforward algorithm for the construction of a sequence of aggregate generators associated with various time scales. These generators together provide a uniform asymptotic approximation of the original probability transition function.',135870,'Journal of the ACM (JACM)',2),(38293,NULL,'1988',NULL,'Performance of various computers using standard linear equations software in a FORTRAN environment','This note compares the performance of different computer systems while solving dense systems of linear equations using the LINPACK software in a Fortran environment. About 100 computers, ranging from a CRAY X-MP to the 68000 based systems such as the Apollo and SUN Workstations to IBM PC\'s, are compared.',15762,'ACM SIGARCH Computer Architecture News',5),(38519,NULL,'1988',NULL,'Synchronization, Coherence, and Event Ordering in Multiprocessors','The problems addressed apply to both throughput-oriented and speedup-oriented multiprocessor systems, either at the user level or the operating-system level. basic definitions are provided. Communication and synchronization are briefly explained, and hardware-level and software-level synchronization mechanisms are discussed. The cache coherence problem is examined, and solutions are described. Strong and weak ordering of events is considered. The user interface is discussed.',56357,'Computer',5),(38520,NULL,'1988',NULL,'The Sprite Network Operating System','A description is given of Sprite, an experimental network operating system under development at the University of California at Berkeley. It is part of a larger research project, SPUR, for the design and construction of a high-performance multiprocessor workstation with special hardware support of Lisp applications. Sprite implements a set of kernel calls that provide sharing, flexibility, and high performance to networked workstations. The discussion covers: the application interface: the basic kernel structure; management of the file name space and file data, virtual memory; and process migration.',56357,'Computer',5),(38521,NULL,'1988',NULL,'Sequoia: A Fault-Tolerant Tightly Coupled Multiprocessor for Transaction Processing','The Sequoia computer is a tightly coupled multiprocessor that avoids most of the fault-tolerance disadvantages of tight coupling by using a fault-tolerant hardware-design approach. An overview is give of how the hardware architecture and operating system (OS) work together to provide a high degree of fault tolerance with good system performance. A description of hardware is followed by a discussion of the multiprocessor synchronization problem. Kernel support for fault recovery and the recovery process itself are examined. It is shown the kernel, through a combination of locking, shadowed memory, and controlled flushing of non-write-through cache, maintains a consistent main memory state recoverable from any single-point failure. The user shared memory is also discussed.',56357,'Computer',6),(38525,NULL,'1988',NULL,'A Multiple Valued Logic: A Tutorial and Appreciation','This tutorial places the developments and potential of multiple-valued signals and logic in the relevant context of binary and two-valued signals. It covers: the role of multivalued logic (MVL) in the binary world; multivalued representation; binary-related radices; multivalued functions; storage techniques in MVL; and implementation issues. An overview of applications is included.',56357,'Computer',1),(38527,NULL,'1988',NULL,'A Multiplier Chip with Multiple-Valued Bidirectional Current-Mode Logic Circuits','A description is given of a 32*32-bit signed digit multiplier implemented with multiple-valued, bidirectional, current-mode circuits and based on two-microcomputer complementary metal-oxide-semiconductor technology. The multiplier can perform 32-bit two\'s-complement multiplication with three-stage SD full adders using a binary-tree addition scheme The effective multiplier size in the chip and the power dissipation are almost half that of the corresponding binary CMOS multiplier. The multiply time is comparable to that of the fastest binary multiplier. These results establish the effectiveness of the technology for future very large scale integration.',56357,'Computer',8),(38731,NULL,'1988',NULL,'Deterministic Learning Automata Solutions to the Equipartitioning Problem','Three deterministic learning automata solutions to the problem of equipartitioning are presented. Although the first two are epsilon -optimal, they seem to be practically feasible only when a set of W objects is small. The last solution, which uses a novel learning automaton, demonstrates an excellent partitioning capability. Experimentally, this solution converges an order of magnitude faster than the best known algorithm in the literature.',117351,'IEEE Transactions on Computers',9),(38732,NULL,'1988',NULL,'Error Secure/Propagating Concept and its Application to the Design of Strongly Fault-Secure Processors','A concept of the error-secure and the error-propagating interfaces of the subsystems in a digital system is introduced, and shown to be useful for practical design and verification for a strongly fault-secure system which is known to achieve the totally self-checking (TSC) goal. A sufficient condition is shown for subsystem interfaces to meet for it to be possible to construct a strongly fault-secure system with no checkers used to monitor the embedded interfaces. On the basis of the error-secure/propagating concept, a design is presented for a strongly fault-secure microprocessor which implements the instruction set of Intel\'s i8080 8-b microprocessor. In the design, a complete set of building blocks is defined and all the partial interfaces are verified for the error secure/propagating property. Only four checkers are used at the embedded interfaces in the resulting strongly fault-secure processor.',117351,'IEEE Transactions on Computers',6),(38733,NULL,'1988',NULL,'A Measure of Guaranteed Availability and its Numerical Evaluation','A success (risk) measure of guaranteed availability is proposed. Using a genetic system model, the authors describe the measure and study the effects of the guaranteed level and the observation period on it. Furthermore, they introduce a numerical approach for continuous-time Markov chain models which allows component-level modeling, Coxian failure and repair distributions, time-dependent failure and repair rates and deferred repair and nondeferred repair strategies to be handled. An example of a fault-tolerant database computer system is considered and the measure of guaranteed availability is evaluated for various guaranteed levels and observation periods.',117351,'IEEE Transactions on Computers',6),(38734,NULL,'1988',NULL,'Multipipeline Networking for Compound Vector Processing','An efficient vector-processing technique is proposed; it is based on a novel concept of multipipeline networking, which is generalized from the techniques of pipeline chaining and systolization. The authors also present the design principles of pipeline nets and provide programming, compiling and run-time techniques for converting scientific programs into pipeline net implementations. Performance analysis of the pipeline net is provided with projected performance of various Livermore loops implemented with pipeline nets of various sizes.',117351,'IEEE Transactions on Computers',5),(38735,NULL,'1988',NULL,'Partitioning Problems in Parallel, Pipeline, and Distributed Computing','The problem of optimally assigning the modules of a parallel program over the processors of a multiple-computer system is addressed. A sum-bottleneck path algorithm is developed that permits the efficient solution of many variants of this problem under some constraints on the structure of the partitions. In particular, the following problems are solved optimally for a single-host, multiple-satellite system: partitioning multiple chain-structures parallel programs, multiple arbitrarily structured serial programs, and single-tree structured parallel programs. In addition, the problem of partitioning chain-structured parallel programs across chain-connected systems is solved under certain constraints. All solutions for parallel programs are equally applicable to pipelined programs.',117351,'IEEE Transactions on Computers',2),(38736,NULL,'1988',NULL,'Throughput Analysis of Cache-Based Multiprocessors with Multiple Buses','The performance of cache-based multiprocessors for general-purpose computing and for multitasking is analyzed with simple throughput models. A private cache is associated with each processor, and multiple buses connect the processors to the shared, interleaved memory. Simple models based on dynamic instruction mix statistics are introduced to evaluate upper bounds on the throughput when independent tasks are run on each processor. With these models, one can obtain a first estimate of the MIPS (millions of instructions per second) rate of a multiprocessor.',117351,'IEEE Transactions on Computers',4),(38737,NULL,'1988',NULL,'Distributed Diagnosis and the System User','The problem of how a user incapable of performing tests can diagnose a system, given the results of the Kuhl and Reddy algorithm, (1980 (3 paper), 1981), is addressed. In particular, the authors provide optimal or near-optimal algorithms for this purpose under a variety of assumptions.',117351,'IEEE Transactions on Computers',0),(38738,NULL,'1988',NULL,'Optimized Layout of MOS Cells','A design method using both logical optimization and optimized topological arrangements is described. Starting from a minimized Boolean function, a synthesis of an optimized well-structured network is obtained. The most original aspect of this approach is a transistor merging procedure leading to a nonseries-parallel network while maintaining a systematic layout. An extension to the synthesis of several functions relies on transistor mergings between functions and allows comparisons with a PLA implementation. Gains in both area and performance are obtained.',117351,'IEEE Transactions on Computers',10),(38739,NULL,'1988',NULL,'Architectural Yield Optimization for WSI','A novel methodology for investigating wafer-scale integration (WSI) designs is proposed. This methodology combines the results of work on integrated circuit yield modeling with a study of the effects of system architecture in large-area integrated circuit yield. This work provides a hierarchical framework in which computing structures may be analyzed to determine functionality on a wafer scale and develops methods by which this functionality can be optimized.',117351,'IEEE Transactions on Computers',10),(38740,NULL,'1988',NULL,'Functional Description of Connector-Switch-Attenuator Networks','The switch-level abstraction of digital MOS circuits has been used primarily in simulators. In formal verification, a functional description must be first extracted from the switch network. It is shown here how the theory of characteristic functions can be applied to analyze such networks and to extract their functional description.',117351,'IEEE Transactions on Computers',10),(38741,NULL,'1988',NULL,'The Reliability of Single-Error Protected Computer Memories','The lifetimes of computer memories which are protected with single-error-correcting-double-error-detecting (SEC-DED) codes are studies. The authors assume that there are five possible types of memory chip failure (single-cell, row, column, row-column and whole chip), and, after making a simplifying assumption (the Poisson assumption), have substantiated that experimentally. A simple closed-form expression is derived for the system reliability function. Using this formula and chip reliability data taken from published tables, it is possible to compute the mean time to failure for realistic memory systems.',117351,'IEEE Transactions on Computers',6),(38742,NULL,'1988',NULL,'FISHNET: A Distributed Architecture for High-Performance Local Computer Networks','FISHNET (facilities integrated in a shared habitat network) addresses the problem of effectively integrating a wide variety of computers, terminals, memory devices and computer peripherals in a local environment. High performance is achieved by effectively separating the high volume node-to-node data communications and the low-volume network control information. Data messages travel through point-to-point data links. Control messages, which set up data paths and coordinate network activities, use an independent multidrop control link which connects all devices. The fully distributed control mechanism allows a high degree of concurrent data transmission.',117351,'IEEE Transactions on Computers',3),(38743,NULL,'1988',NULL,'A Solution to a Special Case of the Synchronization Problem','A synchronizer that exhibits an arbitrarily low failure rate and a short propagation delay for the special case of synchronizing a signal that is synchronous with some periodic signal is described.',117351,'IEEE Transactions on Computers',0),(38744,NULL,'1988',NULL,'Modified Faddeeva Algorithm for Concurrent Execution of Linear Algebraic Operations','An algorithm is described that provides an architectural framework for systematic execution of a wide class of linear algebraic operations using a single systolic array and simple data flow. The algorithm has been modified to use numerically stable Given\'s rotations and is therefore suited to any matrix problem of full rank. When the problem size exceeds that of the hardware array, it can be partitioned in a straightforward, numerically stable way. Numerous simulations have verified the algorithm\'s correctness.',117351,'IEEE Transactions on Computers',2),(38745,NULL,'1988',NULL,'Embedding Computation in One-Dimensional Automata by Phase Coding Solitons','It is shown that some kind of meaningful computation can be embedded in very simple, microscopically homogeneous, one-dimensional automata, and in particular filter automata with a parity next-state rule. A systematic procedure is given for generating moving, periodic structures (particles). These particles exhibit soliton-like properties; that is, they often pass through one another with phase shifts. Ways to encode information in the phase of these particles are discussed. The search for useful logical operations is reduced to a search for paths in certain graphs. As a demonstration of principle, the details of implementing a carry-ripple adder are given',117351,'IEEE Transactions on Computers',1),(38787,NULL,'1988',NULL,'The IBM System/370 Vector Architecture: Design Considerations','The considerations that shaped the architecture of the IBM System/370 Vector Facility are reviewed. The architectural requirements, decisions, and innovations are summarized, and the rationale for the choices that were made is given. Issues related to vector function, performance, compatibility, migration, and integration with the rest of the System/370 architecture are covered.',117351,'IEEE Transactions on Computers',5),(38788,NULL,'1988',NULL,'Optimal Assignments in Broadcast Networks','A program whose execution is distributed among several processors in a broadcast system has a total execution cost equal to the sum of processor costs and communication costs, which are functions of the amount of data transmitted and the average transmission delays. A critical delay x is a value of average transmission delay such that no assignment is minimum-cost for average delays both smaller and larger than x. An algorithm is presented for finding the set of all q critical delays of a program that requires computing O(q) optimal assignments at fixed values of average delay. For p=2 processors, H.S. Stone\'s (1977) assignment graph approach can be used to find an optimal assignment, while for p',117351,'IEEE Transactions on Computers',9),(38789,NULL,'1988',NULL,'Product-Form Solution Techniques for the Performance Analysis of Multiple-Bus Multiprocessor Systems with Nonuniform Memory References','Recursive relations are derived for the exact computation of the steady-state probability distribution of some queuing models with passive resources that can be used to analyze the performance of multiple-bus multiprocessor system architectures. The most general case that can be shown to admit a product-form solution is described, and a recursive solution is obtained taking into account, considering different processor access rates, different memory selection probabilities, and a first-come-first-served bus scheduling policy. Several simpler cases allowing easier model solutions are also considered. Numerical evaluations for large computing systems with nonuniform memory references show the usefulness of the results.',117351,'IEEE Transactions on Computers',0),(38790,NULL,'1988',NULL,'Synchronizing Transactions on Objects','A method is discussed for synchronizing operations on objects when the operations are invoked by transactions. The technique, which is motivated by a desire to make use of possible concurrency in accessing objects, takes into consideration the granularity at which operations affect an object. A dynamic method is presented for determining the compatibility of an invoked operation with respect to operations in progress. In making decisions, it utilizes the state of the object, the semantics of the uncommitted operations, the actual parameters of the invoked operation, and the effect of the operations on the objects. One of the attractive features of this technique is that a single framework can be used to deal with the problem of synchronizing access to simple objects as well as compound objects, i.e. objects in which some components are themselves objects.',117351,'IEEE Transactions on Computers',2),(38791,NULL,'1988',NULL,'Fault-Tolerant FFT Networks','Two concurrent error detection (CED) schemes are proposed for N-point fast Fourier transform (FFT) networks that consists of log/sub 2/N stages with N/2 two-point butterfly modules for each stage. The method assumes that failures are confined to a single complex multiplier or adder or to one input or output set of lines. Such a fault model covers a broad class of faults. It is shown that only a small overhead ratio, O(2/log/sub 2/N) of hardware, is required for the networks to obtain fault-secure results in the first scheme. A novel data retry technique is used to locate the faulty modules. Large roundoff errors can be detected and treated in the same manner as functional errors. The retry technique can also distinguish between the roundoff errors and functional errors that are caused by some physical failures. In the second scheme, a time-redundancy method is used to achieve both error detection and location. It is sown that only negligible hardware overhead is required. However, the throughput is reduced to half that of the original system, without both error detection and location, because of the nature of time-redundancy methods.',117351,'IEEE Transactions on Computers',6),(38792,NULL,'1988',NULL,'Implementing Precise Interrupts in Pipelined Processors','Five solutions to the precise interrupt problem in pipelined processors are described and evaluated. An interrupt is precise if the saved process state corresponds to a sequential model of program execution in which one instruction completes before the next begins. In a pipelined processor, precise interrupts are difficult to implement because an instruction may be initiated before its predecessors have completed. The first solution forces instructions to complete and modify the process state in architectural order. The other four solutions allow instructions to complete in any order, but additional hardware is used, so that a precise state can be restored when an interrupt occurs. All the methods are discussed in the context of a parallel pipeline structure. Simulation results for the Cray-1S scalar architecture are used to show that the first solution results in a performance degradation of at least 16%. The remaining four solutions offer better performance, and three of them result in as little as a 3% performance loss. Several extensions, including vector architectures, virtual memory, and linear pipeline structures, are briefly discussed.',117351,'IEEE Transactions on Computers',4),(38793,NULL,'1988',NULL,'On the Augmented Data Manipulator Network in SIMD Environments','Formulas for the number of the augmented-data-manipulator (ADM)-passable permutations were given previously as cross-recurrence relations for the cardinalities of three specific subsets of such permutations. More concise, transparent recurrence formulas are derived utilizing a novel and conceptually simple model of the ADM. As a byproduct, a global control algorithm for the inverse ADM (IADM) is obtained that can set paths for all the IADM-passable permutations. This algorithm can be adapted for the ADM. Also included are two local control algorithms for the IADM/ADM: the signed bit difference tag control and the destination tag control.',117351,'IEEE Transactions on Computers',2),(38794,NULL,'1988',NULL,'Equilibrium Point Analysis of Memory Interference in Multiprocessor Systems','An approximate analytic tool called equilibrium point analysis is applied to the problem of memory interference in multiprocessor systems. It is a simple and powerful analytic tool based on the fluid approximation and has been widely used for packet broadcast systems. It is shown that quite general multiprocessor systems can be studied quite simply with this technique, these systems include those made up of many classes of processors and memory modules with arbitrary static memory reference patterns, and systems with bus connections between processors and memories. In most cases, the approximation is shown to be sufficiently good. One of the advantages of this technique is that the error is smaller for larger systems for which no appropriate analytic tools have existed until now.',117351,'IEEE Transactions on Computers',5),(38795,NULL,'1988',NULL,'Processor Utilization in a Linearly Connected Parallel Processing System','The authors study the problem of assigning program fragments to a system of processing elements in which low-level operations are performed in parallel. Such a system is said to be linearly connected if each processing element can only communicate directly with its two nearest neighbors. They show that the problem of determining whether a perfect assignment exists is NP-complete but can be solved in linear time if the number of processing elements is fixed. They demonstrate that the related problem of determining whether any assignment exists which can be performed in a given number of machine cycles is NP-complete. For this problem, the objective of which corresponds to minimizing the program fragment\'s execution time, the authors also investigate the behavior of classes of near-optimal heuristic algorithms. This present evidence to indicate that guaranteeing acceptable worst-case performance is a very difficult problem as well.',117351,'IEEE Transactions on Computers',9),(38796,NULL,'1988',NULL,'Incomplete Hypercubes','Since a k-dimensional hypercube has 2/sup k/ vertices, these systems are restricted to having exactly 2/sup k/ computing nodes. Because system sizes must be a power of two, there are large gaps in the sizes of systems that can be built with hypercubes. Routing and broadcast algorithms are presented for hypercubes that are missing certain of their nodes, called incomplete hypercubes. Unlike hypercubes, incomplete hypercubes can be used to interconnect systems with any number of processors. The routing and broadcast algorithms for incomplete hypercubes are shown also to be simple and deadlock-free.',117351,'IEEE Transactions on Computers',7),(38797,NULL,'1988',NULL,'Modulo 3 Residue Checker: New Results on Performance and Cost','The performance and cost of a modulo-3 residue code checker that has been attached to a pipelined serial multiplier to provide a concurrent self-test capability are considered. Analytical results are derived for error detection coverage and minimum error latency; these quantities are observed to be in agreement with simulation results obtained by using ISPS, a register-transfer language. The residue checker error detection coverage and minimum error latency are observed to be dependent on the statistical properties of the multiplier input operands. The checker and serial multiplier were implemented in 4- mu m NMOS, using a standard cell design. The residue code checker required approximately half of the total silicon area.',117351,'IEEE Transactions on Computers',8),(38798,NULL,'1988',NULL,'The Kappa Network with Fault-Tolerant Destination Tag Algorithm','The design of the Gamma network is analyzed in terms of block structure. The analysis reveals the asymmetry of its duplicate links, and an alternate design in the form of the Kappa network is proposed. Its novel feature is the symmetry of duplicate links at the block level. This symmetry results in a simple control algorithm and enhanced fault tolerance. The relationship between the Kappa network and other existing fault-tolerant networks is briefly discussed.',117351,'IEEE Transactions on Computers',7),(38799,NULL,'1988',NULL,'A Fault-Tolerant FFT Processor','A method is proposed for achieving fault tolerance by introducing a redundant stage for a special-purpose fast Fourier transform (FFT) processor. A concurrent error-detection technique, called recomputing by alternate path, is used to detect errors during normal operation. Once an error is detected, a faulty butterfly can be located with log (N+5) additional cycles. The method has 100% detection and location capability, regardless of the magnitude of the roundoff errors. A gracefully degraded reconfiguration using a redundant stage is introduced. This technique ensures a high improvement in reliability and availability. Hardware overhead is O(1/log N) with some additional comparators and switches. The method can be applied to other algorithms implementable on the butterfly structure.',117351,'IEEE Transactions on Computers',6),(38800,NULL,'1988',NULL,'A Fault-Tolerant Systolic Sorter','A fault-tolerant systolic sorter design is proposed. An algorithm-based fault tolerance is achieved by testing the invariants of a systolic sorter during normal operation. Transient and permanent computation errors can be detected by using error-checking code and some redundant cells. A block with a single faulty cell can be located. Small hardware overhead and negligible time overhead are shown to be the major advantages of the method. A hierarchical structure is suggested as an efficient architecture for realizing the method. An offline fault-testing method for permanent stuck-at faults is presented.',117351,'IEEE Transactions on Computers',6),(38801,NULL,'1988',NULL,'Layer Assignment Problem for Three-Layer Routing','The layer assignment problem for interconnect is the problem of determining which layers should be used for wiring the signal nets so that the number of vias is minimized. The problem is often referred to as the via minimization problem. The problem is considered for three-layer routing, concentrating on one version called the constrained via minimization (CVM3) problem. It is shown that the CVM3 problem is NP-complete and a heuristic algorithm is proposed. The experimental results show that the proposed algorithm is efficient and generates fairly good solutions.',117351,'IEEE Transactions on Computers',9),(38802,NULL,'1988',NULL,'The Cubical Ring Connected Cycles: A Fault Tolerant Parallel Computation Network','The cube-connected cycles network is suitable for realization in VLSI, since it satisfies the properties of degree boundedness of the nodes (=3), and regularity of layout. Another network called the cubical ring-connected cycles (CRCC) is proposed that has all the desirable features of the cube-connected cycle (CCC) and is single-cycle fault tolerant as well. The degree of each processor is less than or equal to four, the number of processors increases from 2/sup r+s/ to 2/sup r/(2/sup 2/+1), for integers r and s, and the number of links increases by a factor of one-third over the corresponding CCC. Reliability improvements of the CRCC network over the CCC are studied. A regular layout scheme suitable for VLSI implementation of the CRCC is presented. Reconfiguration techniques under failures of processors in the CRCC are discussed.',117351,'IEEE Transactions on Computers',7),(39367,NULL,'1988',NULL,'Benchmark Synthesis Using the LRU Cache Hit Function','The LRU cache hit function is used as a general characterization of locality of reference to address the synthesis question of whether benchmarks can be created that have a required locality of reference. Several results are given that show circumstances under which this synthesis can or cannot be achieved. An additional characterization called the warm-start cache hit function is introduced and shown to be efficiently computable. The operations of repetition and replication are used to form new programs, and their characteristics are derived. Using these operations, a general benchmark synthesis technique is obtained and demonstrated with an example.',117351,'IEEE Transactions on Computers',2),(39368,NULL,'1988',NULL,'A Generalized Message-Passing Mechanism for Communicating Sequential Processes','Bidirectional message-passing (bi-io), a novel symmetric communication mechanism for concurrent processes, is introduced and developed. The mechanism is symmetric in the sense that, in one atomic action, a message is transmitted in each direction between two processes. For some applications (tree structure, systolic arrays) this method is shown to have several advantages over conventional synchronization and communication primitives (mainly conciseness of programs, absence of certain types of deadlock). The mechanism is rigorously defined with a CSP-like syntax and a weakest-precondition semantics. Two systolic arrays are developed using bidirectional message-passing: a matrix-vector multiplier and a palindrome recognizer.',117351,'IEEE Transactions on Computers',2),(39369,NULL,'1988',NULL,'Continuous Models for Communication Density Constraints on Multiprocessor Performance','Fundamental limits on the communication capabilities of massively parallel multiprocessors are investigated. It is shown that in the limit of machines of infinite extent in which the number of processors per unit volume is constant and in which the communication bandwidth from each processor to its neighbors depends only on their separation distance, interprocessor communication must fall off faster than the fourth power of distance. For machines of finite size, communication energy density is used as a metric to compare various machine sizes and packaging densities. For instance, for machines with spherical symmetry and uniform communication requirements, the peak density depends on the number of processors to the 4/3 power and the number of processors per unit volume to the 2/3 power.',117351,'IEEE Transactions on Computers',3),(39370,NULL,'1988',NULL,'Systolic Super Summation','A principal limitation in accuracy for scientific computation performed with floating-point arithmetic is due to the computation of repeated sums, such as those that arise in inner products. A systolic super summer of cellular design is proposed for the high-throughput performance of repeated sums of floating-point numbers. The apparatus receives pipelined inputs of streams of summands from one or many sources. The floating-point summands are converted into a fixed-point form by a sieve-like pipelined cellular packet-switching device with signal combining. The emerging fixed-point numbers are then summed in a corresponding network of extremely long accumulators (i.e., super accumulators). At the cell level, the design uses a synchronous model of VLSI. The amount of time the apparatus needs to compute an entire sum depends on the values of summands; at this architectural level, the design is asynchronous. The throughput per unit area of hardware approaches that of a tree network, but without the long wire and signal propagation delay that are intrinsic to tree networks.',117351,'IEEE Transactions on Computers',10),(39371,NULL,'1988',NULL,'Theory of Clocking for Maximum Execution Overlap of High-Speed Digital Systems','The effect of clocking schemes on overlapped execution performance in a digital system is described and quantified. Effects of branching, data dependencies, and resource conflicts between consecutive tasks are considered. Some problems of clocking scheme synthesis for the design of digital systems with maximum execution overlap are examined. Effects of performance of the choice of clocking scheme, partitioning of functions into the time steps, the number of clock phases, the length of each phase (i.e., how to pipeline), and the assignment of functions to clock phases are treated.',117351,'IEEE Transactions on Computers',0),(39372,NULL,'1988',NULL,'A Synthesis Algorithm for Reconfigurable Interconnection Networks','The performance of a parallel algorithm depends in part on the interconnection topology of the target parallel system. An interconnection network is called reconfigurable if its topology can be changed between different algorithm executions. Since communication patterns vary from one parallel algorithm to another, a reconfigurable network can effectively support algorithms with different communication requirements. It is shown how to generate a network topology that is optimized with respect to the communication patterns of a given task. The algorithm presented takes as input a task graph and generates as output a topology that closely matches the given input graph. The topologies generated by the algorithm are analyzed with respect to optimum interconnection topologies for the best, worst, and average cases. Simulation results verify the average-case performance prediction and confirm that, on the average, the optimum topologies are generated.',117351,'IEEE Transactions on Computers',7),(39373,NULL,'1988',NULL,'Cache Operations by MRU Change','The performance of set associative caches is analyzed. The method used is to group the cache lines into regions according to their positions in the replacement stacks of a cache, and then to observe how the memory access of a CPU is distributed over these regions. Results from the preserved CPU traces show that the memory accesses are heavily concentrated on the most recently used (MRU) region in the cache. The concept of MRU change is introduced; the idea is to use the event that the CPU accesses a non-MRU line to approximate the time the CPU is changing its working set. The concept is shown to be useful in many aspects of cache design and performance evaluation, such as comparison of various replacement algorithms, improvement of prefetch algorithms, and speedup of cache simulation.',117351,'IEEE Transactions on Computers',4),(39374,NULL,'1988',NULL,'Abstract pecification of Synchronous Data Types for VLSI and Proving the Correctness of Systolic Network Implementations','A combined methodology is presented for specifying abstract synchronous data types and proving the correctness of systolic network implementations. It is shown that an extension of the Parnas trace method of specifying software modules containing distinct access programs yields a natural method of specifying abstract synchronous data types that possess distinct access operators and are intended for implementation in VLSI. Associated systematic proof techniques are presented, and the correctness of several novel systolic network implementations of familiar data types is established. The methodology appears to be naturally suited to systolic network implementations with their associated rippling of control flow and data flow. The important distinction between systolic control-flow networks and systolic data-flow networks is presented.',117351,'IEEE Transactions on Computers',2),(39375,NULL,'1988',NULL,'On Two-Dimensional Via Assignment for Single-Row Routing','The authors study the via assignment problem when vias are allowed to appear rowwise as well as columnwise. Previously they proved that the problem belongs to the class of NP-hard problems and therefore it is unlikely that polynomial-time algorithms exist for solving the problem. Two heuristics (HEU1 and HEU2) to solve the problem were proposed. HEU1 splits the nets before any routing is done while HEU2 assigns the nets alternately to via rows and via columns. Here they modify HEU2 so that the side of the board to which the nets are assigned first for connection is selected according to a desired ratio of board width to height.',117351,'IEEE Transactions on Computers',9),(39376,NULL,'1988',NULL,'Systolic Tree Implementation of Data Structures','Systolic tree architectures are presented for data structures such as stacks, queues, dequeues, priority queues, and dictionary machines. The stack, queue, and dequeue have a unit response time and a unit pipeline interval. The priority queue also has a unit response time, but the pipeline interval is 2. The response time and pipeline interval for the dictionary machine are O(log n) and O(1), respectively, where n is the number of data elements currently residing in the tree. In each node of the tree, the mechanism for controlling the transmission and distribution of data is finite state. This feature makes the designs presented here suitable for VLSI. If there are n data elements in the data structure, the depth of the tree is O(log n).',117351,'IEEE Transactions on Computers',9),(39377,NULL,'1988',NULL,'A Comparison of VLSI Architecture of Finite Field Multipliers Using Dual, Normal, or Standard Bases','Three different finite-field multipliers are presented: (1) a dual-basis multiplier due to E.R. Berlekamp (1982); the Massey-Omura normal basis multiplier; and (3) the Scott-Tavares-Peppard standard basis multiplier. These algorithms are chosen because each has its own distinct features that apply most suitably in particular areas. They are implemented on silicon chips with NMOS technology so that the multiplier most desirable for VLSI implementation can readily be ascertained.',117351,'IEEE Transactions on Computers',8),(39378,NULL,'1988',NULL,'Approximate Analysis of Fork/Join Synchronization in Parallel Queues','An approximation technique, called scaling approximation, is introduced and applied to the analysis of homogeneous fork/join queuing systems consisting of Kor=32.',117351,'IEEE Transactions on Computers',2),(39379,NULL,'1988',NULL,'A Simple Method for Determining Hadamard Sequency Vectors','A simple method for determining the sequency ordering of any row in any Hadamard matrix directly from its binary representation is developed. This proposed method is proved to be much simpler than the well-known bit-reverse inverse Gray code method.',117351,'IEEE Transactions on Computers',8),(39380,NULL,'1988',NULL,'Definition and Design of Strongly Language Disjoint Checkers','Strongly language-disjoint (SLD) checkers are to sequential systems what strongly code-disjoint checkers are to combinatorial systems. SLD checkers are the largest class of checkers with which a functional system can achieve the totally self-checking goal. Self-checking sequential systems are first addressed, and formal definitions of SLD checkers are given. The design of SLD checkers based on regular combinatorial self-checking components is then considered.',117351,'IEEE Transactions on Computers',6),(39381,NULL,'1988',NULL,'A New Bit-Serial Systolic Multiplier Over GF(2/sup m/)','A bit-serial systolic array has been developed to computer multiplications over GF(2/sup m/). In contrast to a previously designed systolic multiplier, this algorithm allows the input elements to center a linear systolic array in the same order, and the system only requires one control signal.',117351,'IEEE Transactions on Computers',8),(39382,NULL,'1988',NULL,'Strongly Code Disjoint Checkers','Strongly code-disjoint (SCD) checkers are defined and shown to include totally self-checking (TSC) code-disjoint checkers. This type of checker is the natural companion of strongly fault-secure (SFS) networks. SCD checkers are the largest class of checkers with which a combinational system may achieve the TSC goal. Some examples are given to illustrate the design of SCD checkers.',117351,'IEEE Transactions on Computers',11),(39383,NULL,'1988',NULL,'Functional Test Generation Based on Unate Function Theory','The generation of a universal test set (UTS) for unate functions is used as a starting point. This test set is complete and minimal for the set of all unateness-preserving faults. However, for functions that are not unate in any variable, the UTS generated by this algorithm is the exhaustive set. An algorithm is presented that computes a good functional test set (GFTS) of reasonable size even for such functions. The algorithm does this by breaking up functions into more unate components, recursively computing GFTS for them, and combining the test sets in an appropriate way. The GFTS generated by the algorithm is compared to random test sets of the same size for gate-level fault coverage in typical implementations.',117351,'IEEE Transactions on Computers',11),(39384,NULL,'1988',NULL,'Minimum Complexity FIR Filters and Sparse Systolic Arrays','The properties of B-spline approximation and the integral/derivative properties of convolution lead to efficient algorithms for the implementation of multidimensional FIR filters. The implementations are of minimum time complexity under the Nyquist criterion. The algorithm can easily be implemented using a sparse systolic array architecture. The resulting B-spline convolvers have much lower circuit complexity than systolic architectures based on conventional convolution algorithms. A two-dimensional hardware implementation based on simplifications of current architectures is presented.',117351,'IEEE Transactions on Computers',8),(39424,NULL,'1988',NULL,'The Optical File Cabinet: A Random-Access File System for Write-Once Optical Disks','The Optical File Cabinet (OFC) is patterned after a conventional office file cabinet where all versions of a stored item are retained, but the current version of each item is the easiest to find. The OFC retains the favorable aspects of write-once optical disks while preserving the existing relationship between the operating system and the file system. Alternate approaches to write-once storage and the characteristics of write-once optical disks are described. The salient features of the OFC are examined, namely, the file system tree, growing data structures, and the large memory requirement. The relationship between the OFC and the operating system is discussed. Also considered are reliability, the user-level software interface, long-term storage, simulating the OFC, and implementation of the OFC on a Tektronix 4404 engineering workstation.',56357,'Computer',4),(39624,NULL,'1988',NULL,'Lisp on a Reduced-Instruction-Set Processor: Characterization and Optimization','The factors that motivated the choice of a reduced-instruction-set computer (RISC) on which to implement Lisp are examined. Dynamic profiling measurements used to characterise Lisp are reported. The implementation of tags in Lisp and the cost of function calls are discussed. Interprocedural register allocation is examined. Execution results for various benchmarks are presented and discussed.',56357,'Computer',4),(39625,NULL,'1988',NULL,'Reducing the Branch Penalty in Pipelined Processors','A probabilistic model is developed to quantify the performance effects of the branch penalty in a typical pipeline. The branch penalty is analyzed as a function of the relative number of branch instructions executed and the probability that a branch is taken. The resulting model shows the fraction of maximum performance achievable under the given conditions. Techniques to reduce the branch penalty include static and dynamic branch prediction, the branch target buffer, the delayed branch, branch bypassing and multiple prefetching, branch folding, resolution of branch decision early in the pipeline, using multiple independent instruction streams in a shared pipeline, and the prepare-to-branch instruction.',56357,'Computer',4),(39631,NULL,'1988',NULL,'On the complexity of branching programs and decision trees for clique functions','Exponential lower bounds on the complexity of computing the clique functions in the Boolean decision-tree model are proved. For one-time-only branching programs, large polynomial lower bounds are proved for k-clique functions if k is fixed, and exponential lower bounds if k increases with n. Finally, the hierarchy of the classes BPd(P) of all sequences of Boolean functions that may be computed by d-times only branching programs of polynomial size is introduced. It is shown constructively that BP1(P) is a proper subset of BP2(P).',135870,'Journal of the ACM (JACM)',9),(40169,NULL,'1988',NULL,'Mean Value Analysis for Blocking Queueing Networks','Mean value analysis is an exact solution technique for infinite capacity queueing networks and enjoyed widespread popularity during recent years.It considers the behavior of the system by stepwise increasing the number of jobs in the entire network, thus it is well suited for the analysis of queueing networks with blocking.In this work, an approximation is introduced for the mean value analysis queueing networks with transfer blocking.The blocking occurs when a job, after service at a station, wants to join a station which is full.The job resides in the server of the source station until a place becomes available in the destination station.The approximation is based on the modification of mean residence times due to the blocking events that occur in the network.Several examples are executed in order to validate the approximate results.',117420,'IEEE Transactions on Software Engineering',3),(40180,NULL,'1988',NULL,'Performance Analysis of Parallel Processing Systems','A bulk arrival M^x/M/c queueing system is used to model a centralized parallel processing system with job splitting. In such a system, jobs wait in a central queue, which is accessible by all the processors, and are split into independent tasks that can be executed on separate processors. The job response time consists of three components: queueing delay, service time, and synchronization delay. An expression for the mean job response time is obtained for this centralized parallel processing system. Centralized and distributed parallel processing systems (with and without job splitting) are considered and their performances compared. Furthermore, the effects of parallelism and overheads due to job splitting are investigated.',117420,'IEEE Transactions on Software Engineering',0),(40181,NULL,'1988',NULL,'Parallel Discrete Event Simulation Using Shared Memory','With traditional event list techniques, evaluating a detailed discrete event simulation model can often require hours or even days of computation time. By eliminating the event list and maintaining only sufficient synchronization to ensure causality, parallel simulation can potentially provide speedups that are linear in the number of processors. We present a set of shared memory experiments using the Chandy-Misra distributed simulation algorithm to simulate networks of queues. Parameters of the study include queueing network topology and routing probabilities, number of processors, and assignment of network nodes to processors.',117420,'IEEE Transactions on Software Engineering',0),(40407,NULL,'1988',NULL,'Data Diversity: An Approach to Software Fault Tolerance','Data diversity is described, and the results of a pilot study are presented. The regions of the input space that cause failure for certain experimental programs are discussed, and data reexpression, the way in which alternate input data sets can be obtained, is examined. A description is given of the retry block which is the data-diverse equivalent of the recovery block, and a model of the retry block, together with some empirical results is presented. N-copy programming which is the data-diverse equivalent of N-version programming is considered, and a simple model and some empirical results are also given.',117352,'IEEE Transactions on Computers - Fault-Tolerant Computing',2),(40415,NULL,'1988',NULL,'On the Design of Pseudoexhaustive Testable PLAs','A method is presented to design pseudoexhaustive testable (PET) PLAs (programmable logic arrays) that are suitable for BIST (built-in self-test) environments. The key idea of the design is to partition inputs and product lines into groups. During testing, a group of inputs and a group of product lines are selected and tested exhaustively. The proposed design leads to small test sizes and relatively small area overhead. Experimental results on 30 PLAs, comparing test set sizes and area overhead of different BIST PLA designs, are reported.',117352,'IEEE Transactions on Computers - Fault-Tolerant Computing',11),(40420,NULL,'1988',NULL,'Pseudoexhaustive Test Pattern Generator with Enhanced Fault Coverage','A method of pseudoexhaustive test pattern generation is proposed that is suitable above all for circuits using random access scan. Two linear feedback shift registers are used to generate scan addresses and test patterns to be scanned into these addresses. It is shown that the method gives better results than random testing.',117352,'IEEE Transactions on Computers - Fault-Tolerant Computing',11),(40918,NULL,'1988',NULL,'Multicomputers: Message-Passing Concurrent Computers','A status report is provided on the architecture and programming of a family of concurrent computers that are organized as ensembles of small programmable computers called nodes, connected by a message-passing network, each with its own private memory. The architecture of the multicomputer is described and contrasted with that of the shared-memory multiprocessor, and the concept of grain size (which depends on the size of the individual memories) is explained. Medium-grain and fine-grain multicomputers, with nodes containing megabytes and tens of kilobytes of memory, respectively, are examined, and their programming is discussed.',56357,'Computer',3),(40919,NULL,'1988',NULL,'Architecture and Applications of the Connection Machine','The concept of data-parallel computers is explained, and their architecture of the Connection Machine (CM), which implements this approach, is described. It provides 64 K physical processing elements, millions of virtual processing elements with its virtual processor mechanism, and general-purpose, reconfigurable communications networks. The evolution of the CM architecture is examined, and the software environment, engineering and physical characteristics, and performance of the current embodiment (the CM-2) are discussed. Applications of the CM to molecular dynamics, VLSI design and circuit simulation, and computer vision are described.',56357,'Computer',5),(40934,NULL,'1988',NULL,'The Balance Multiprocessor System','A description is given of the architecture, operating system, and performance of Balance, a shared-memory, tightly coupled multiprocessor system. Balance can contain two to thirty 32-bit microprocessors with an aggregate performance of up to 21 million instructions per second (MIPS). Each processor has a private cache as well as a small local memory to hold frequently used kernel routines. The system features a high-bandwidth pipelined bus, up to 28 Mbytes of main memory, a diagnostic and console processor, up to four IEEE 769 (Multibus) adapters, an IEEE 802.3 (Ethernet) LAN interface, and an ANSI Small Computer System Interface (SCSI). Dynix, a multiprocessor operating system supporting both the 4.2 BSD and System V Unix environments, manages Balance, providing transparent support for multiprocessing as well as tools and libraries for developing parallel applications. The various subsystems and the Dynix operating system are examined. Applications and performance are discussed.',117256,'IEEE Micro',4),(41091,NULL,'1988',NULL,'Neural Nets for Adaptive Filtering and Adaptive Pattern Recognition','The adaptive linear combiner (ALC) is described, and practical applications of the ALC in signal processing and pattern recognition are presented. Six signal processing examples are given, which are system modeling, statistical prediction, noise canceling, echo canceling, universe modeling, and channel equalization. Adaptive pattern recognition using neural nets is then discussed. The concept involves the use of an invariance net followed by a trainable classifier. It makes use of a multilayer adaptation algorithm that descrambles output and reproduces original patterns.',56357,'Computer',2),(41220,NULL,'1988',NULL,'Optimal VLSI circuits for sorting','This work describes a large number of constructions for sorting N integers in the range [0, M - 1], for N ≤ M ≤ N2, for the standard VLSI bit model. Among other results, we attain:VLSI sorter constructions that are within a constant factor of optimal size, for all M and almost all running times T.a fundamentally new merging network for sorting numbers in a bit model.new organizational approaches for optimal tuning of merging networks and the proper management of data flow.',135870,'Journal of the ACM (JACM)',9),(41422,NULL,'1988',NULL,'Computing on an anonymous ring','The computational capabilities of a system of n indistinguishable (anonymous) processors arranged on a ring in the synchronous and asynchronous models of distributed computation are analyzed. A precise characterization of the functions that can be computed in this setting is given. It is shown that any of these functions can be computed in O(n2) messages in the asynchronous model. This is also proved to be a lower bound for such elementary functions as AND, SUM, and Orientation. In the synchronous model any computable function can be computed in O(n log n) messages. A ring can be oriented and start synchronized within the same bounds.The main contribution of this paper is a new technique for proving lower bounds in the synchronous model. With this technique tight lower bounds of &thgr;(n log n) (for particular n) are proved for XOR, SUM, Orientation, and Start Synchronization. The technique is based on a string-producing mechanism from formal language theory, first introduced by Thue to study square-free words. Two methods for generalizing the synchronous lower bounds to arbitrary ring sizes are presented.',135870,'Journal of the ACM (JACM)',9),(41683,NULL,'1988',NULL,'The input/output complexity of sorting and related problems','We provide tight upper and lower bounds, up to a constant factor, for the number of inputs and outputs (I/OS) between internal memory and secondary storage required for five sorting-related problems: sorting, the fast Fourier transform (FFT), permutation networks, permuting, and matrix transposition. The bounds hold both in the worst case and in the average case, and in several situations the constant factors match. Secondary storage is modeled as a magnetic disk capable of transferring P blocks each containing B records in a single time unit; the records in each block must be input from or output to B contiguous locations on the disk. We give two optimal algorithms for the problems, which are variants of merge sorting and distribution sorting. In particular we show for P = 1 that the standard merge sorting algorithm is an optimal external sorting method, up to a constant factor in the number of I/Os. Our sorting algorithms use the same number of I/Os as does the permutation phase of key sorting, except when the internal memory size is extremely small, thus affirming the popular adage that key sorting is not faster. We also give a simpler and more direct derivation of Hong and Kung\'s lower bound for the FFT for the special case B = P = O(1).',52621,'Communications of the ACM',9),(41823,NULL,'1988',NULL,'Sorting Large Files on a Backend Multiprocessor','The authors investigate the feasibility and efficiency of a parallel sort-merge algorithm by considering its implementation of the JASMIN prototype, a backend multiprocessor built around a fast packet bus. They describe the design and implementation of a parallel sort utility and present and analyze the results of measurements corresponding to a range of file sizes and processor configurations. The results show that using current, off-the-shelf technology coupled with a streamlined distributed operating system, three- and five-microprocessor configurations, provide a very cost-effective sort of large files. The three-processor configuration sorts a 100-Mb file in 1 hr which compares well to commercial sort packages available on high-performance mainframes. In additional experiments, the authors investigate a model to tune their sort software and scale their results to higher processor and network capabilities.',117351,'IEEE Transactions on Computers',4),(41824,NULL,'1988',NULL,'An Asynchronous, Distributed Flow Control Algorithm for Rate Allocation in Computer Networks','An asynchronous, distributed algorithm is presented that determines the optimal transmission rate allocation in computer networks with virtual circuit routing. The flow control problem is formulated as a gradient hill-climbing algorithm. It is distributed, since the entry node for each virtual circuit iteratively computes the rate allocation for that virtual circuit. The entry node communicates with the associated user during each interaction and obtains information about the rest of the network by sending control packets along the virtual circuit. It is shown that all of the necessary information to solve the optimization problem can be obtained in this fashion and that the algorithm will converge, even though there is no synchronization between nodes and some computations are made with outdated information.',117351,'IEEE Transactions on Computers',7),(41825,NULL,'1988',NULL,'Fault Tolerance Capabilities in Multistage Network-Based Multicomputer Systems','The inherent fault tolerances of systems based on nonredundant multistage interconnection networks (MINs) is investigated. Graph models are used to describe the system, indicate faults, study their effects, and aid in mathematical formulation of these effects. Methodical terminology for defining functionality of two-sided-MIN-based multicomputer systems and specifying their fault tolerance of such systems is analyzed. The effects of a single faulty vertex and a single faulty edge are studied, and single fault tolerance, with respect to various definitions of system functionality, is evaluated. Multiple faults are analyzed. A practical example of the banyan network used in the Texas reconfigurable array computer (TRAC) and its fault tolerance capabilities are given.',117351,'IEEE Transactions on Computers',6),(41826,NULL,'1988',NULL,'Meaningful Special Classes of Ternary Logic Functions-Regular Ternary Logic Functions and Ternary Majority Functions','Special ternary logic functions, namely, regular functions suitable for treating ambiguity and majority functions based on an extended majority principle are considered. The one-to-one correspondence between n-ary monotone regular ternary logic functions and (n+1)-ary monotone Boolean functions is investigated, as well as the one-to-one correspondence between n-ary monotone ternary majority functions and (n+1)-ary monotone binary threshold functions. The ternary majority functions are enumerated.',117351,'IEEE Transactions on Computers',1),(41827,NULL,'1988',NULL,'Efficient Design of Totally Self-Checking Checkers for all Low-Cost Arithmetic Codes','A method is proposed that is based on the partitioning of the input code variables into two sections, each section representing the binary form of a number Z/sub 1/ and Z/sub 2/, respectively. For a code with check base A=2/sup m/-1, two m-bit end-around carry adder trees calculate the modulo m residue of Z/sub 1/ and Z/sub 2/, while a totally self-checking (TSC) translator maps the output of the pair of trees onto m-variable two-rail code. A TSC two-rail checker maps the m-variable two-rail code onto one-out-of-two code. The checkers present significant improvement in the implementation cost, number of gate levels, and reliability over TSC checkers previously proposed in the literature.',117351,'IEEE Transactions on Computers',8),(41828,NULL,'1988',NULL,'Stochastic High-Level Petri Nets and Applications','A class of stochastic Petri nets called stochastic high-level Petri nets (SHLPNs) is proposed. SHLPNs are high-level Petri nets augmented with exponentially distributed firing times. SHLPNs generally lead to models with a smaller state space. A computer marking concept is introduced that allows a considerable reduction of the number of states and induces a correct grouping of states in the Markov-domain SHLPN models of multiprocessor systems. The main advantage of modeling homogeneous systems using SHLPNs is that the resulting models are simpler and more intuitive and have a smaller number of states, as shown by examples.',117351,'IEEE Transactions on Computers',2),(41829,NULL,'1988',NULL,'Performance of ARQ Schemes on Token Ring Networks','Token ring networks differ in the manner in which acknowledgements are handled. In Newhall rings, acknowledgements of data packets are either sent as independent packets or piggybacked on returned data packets. In acknowledgement rings, there is an acknowledgement field in each data packet. The authors present an empirical formula that predicts the average network access delay in networks where the sender is allowed to transmit only one packet each time it seizes the token and discuss its validity. The performance of the stop-and-wait ARQ (automatic-repeat-request) scheme in token ring networks is treated. The average access delay, optimum window size, and maximum achievable throughput as functions of network and protocol parameters in Newhall rings when the continuous ARW scheme is used are studied. Tradeoffs between average access delay and average buffer occupancy time are examined.',117351,'IEEE Transactions on Computers',7),(41830,NULL,'1988',NULL,'An Algebraic Model for Asynchronous Circuits Verification','An algebraic methodology for comparing switch-level circuits with higher-level specifications is presented. Switch-level networks, \'user\' behavior, and input constraints are modeled as asynchronous machines. The model is based on the algebraic theory of characteristic functions (CF). An asynchronous automation is represented by a pair of CFs, called a dynamic CF (DCF): the first CF describes the potential stable states, and the second CF describes the possible transitions. The set of DCFs is a Boolean algebra. Machine composition and internal variables abstraction correspond, respectively, to the product and sum operations of the algebra. Internal variables can be abstracted under the presence of a domain constraint. The constraint is validated by comparison to the outside behavior. The model is well suited for speed-independent circuits for which the specification is given as a collection of properties. Verification reduces to the validation of Boolean inequalities.',117351,'IEEE Transactions on Computers',1);
/*!40000 ALTER TABLE `fg_m_article` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2018-04-10 11:44:56
